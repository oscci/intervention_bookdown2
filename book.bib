
@article{simmons2011,
	title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976},
	shorttitle = {False-{Positive} {Psychology}},
	url = {https://doi.org/10.1177/0956797611417632},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2021-03-01},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	note = {Publisher: SAGE Publications Inc},
	keywords = {disclosure, methodology, motivated reasoning, publication},
	pages = {1359--1366},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/WAHA29FP/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf:application/pdf},
}

@article{saul2021,
	title = {A {Randomized} {Case} {Series} {Approach} to {Testing} {Efficacy} of {Interventions} for {Minimally} {Verbal} {Autistic} {Children}},
	volume = {12},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.621920/full},
	doi = {10.3389/fpsyg.2021.621920},
	abstract = {Background: Randomized Controlled Trials (RCTs) are the gold standard for assessing whether an intervention is effective; however, they require large sample sizes in order to detect small effects. For rare or complex populations, we advocate a case series approach as a more realistic and useful first step for intervention evaluation. We consider the importance of randomization to such designs, and advocate for the use of Randomization Tests and Between Case Effect Sizes to provide a robust and statistically powerful evaluation of outcomes. In this tutorial, we describe the method, procedures, and analysis code necessary to conduct robust single case series, using an empirical example with minimally verbal autistic children. Method: We applied a pre-registered (https://osf.io/9gvbs) randomized baseline design with between-case effect size to a case series (n=19), to test the efficacy of a novel, parent-mediated, app-based speech production intervention (BabbleBooster) for minimally verbal autistic children. Parent-rated probe scores were used to densely sample performance accuracy over time. Results: Parents were able to reliably code their children’s speech productions using BabbleBooster. A non-significant Randomization Test and small Between-Case Effect Size (d=0.267), suggested there was no evidence that BabbleBooster improved speech production in minimally verbal autistic children, relative to baseline scores, during this brief period of intervention. Conclusion: The current analyses exemplify a more robust approach to examining treatment effects in rare or complex populations, where RCT may be difficult or premature to implement. To facilitate adoption of this method by researchers and practitioners, we provide analysis code that can be adapted using open source R packages. Future studies could use this case series design to evaluate interventions aiming to improve speech and language outcomes for minimally verbal autistic children, and other heterogeneous and hard to reach populations.},
	language = {English},
	urldate = {2021-05-25},
	journal = {Frontiers in Psychology},
	author = {Saul, Jo and Norbury, Courtenay},
	year = {2021},
	note = {Publisher: Frontiers},
	keywords = {Speech, autism, intervention, minimally verbal, Parent-mediated, Randomization, Single case design},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/LVSWD8YD/Saul and Norbury - 2021 - A Randomized Case Series Approach to Testing Effic.pdf:application/pdf},
}

@book{wiig1992,
	title = {Celf - {Preschool}},
	isbn = {978-0-15-803380-8},
	language = {English},
	publisher = {Psychological Corporation},
	author = {Wiig, Elisabeth and Secord, Wayne and Semel, Eleanor},
	month = apr,
	year = {1992},
}

@misc{zotero-986,
	title = {Clinical {Evaluation} of {Language} {Fundamentals} - {Fifth} {Edition} ({CELF}-5 {UK}) {\textbar} {Pearson} {Assessment}},
	url = {https://www.pearsonclinical.co.uk/Psychology/ChildCognitionNeuropsychologyandLanguage/ChildLanguage/celf-5/clinical-evaluation-of-language-fundamentals-fifth-edition-celf-5.aspx?gclid=CjwKCAjwoZWHBhBgEiwAiMN66ZCgI2D45ubBirWCEKjtU6y87WyBi_4zgheGsgkBAQYfUkduPLMUdBoC2W8QAvD_BwE},
	urldate = {2021-07-07},
	file = {Clinical Evaluation of Language Fundamentals - Fifth Edition (CELF-5 UK) | Pearson Assessment:/Users/dorothybishop/Zotero/storage/JE369QRV/clinical-evaluation-of-language-fundamentals-fifth-edition-celf-5.html:text/html},
}

@book{wiig2006,
	address = {London},
	title = {{CELF}-{Preschool} 2 {UK}},
	url = {https://www.pearsonclinical.co.uk/Psychology/ChildCognitionNeuropsychologyandLanguage/ChildLanguage/CELF-Preschool2UK/CELF-Preschool2UK.aspx},
	urldate = {2021-07-07},
	publisher = {Pearson Assessment},
	author = {Wiig, Elisabeth H and Secord, Wayne and Semel, Eleanor},
	year = {2006},
	file = {CELF-Preschool 2 UK | Pearson Assessment:/Users/dorothybishop/Zotero/storage/5QTE3E8E/CELF-Preschool2UK.html:text/html},
}

@book{bricker1999,
	address = {Baltimore},
	title = {Ages and {Stages} {Questionnaires}: {A} parent-completed, child-monitoring system, 2nd ed.},
	publisher = {Paul H. Brookes},
	author = {Bricker, D and Squires, J},
	year = {1999},
}

@article{schmitt2017,
	title = {Establishing {Language} {Benchmarks} for {Children} {With} {Typically} {Developing} {Language} and {Children} {With} {Language} {Impairment}},
	volume = {60},
	issn = {1558-9102},
	doi = {10.1044/2016_JSLHR-L-15-0273},
	abstract = {Purpose: Practitioners, researchers, and policymakers (i.e., stakeholders) have vested interests in children's language growth yet currently do not have empirically driven methods for measuring such outcomes. The present study established language benchmarks for children with typically developing language (TDL) and children with language impairment (LI) from 3 to 9 years of age.
Method: Effect sizes for grammar, vocabulary, and overall language were calculated for children with TDL (n = 20,018) using raw score means and standard deviations from 8 norm-referenced measures of language. Effect sizes for children with LI were calculated using fall and spring norm-referenced language measures for 497 children with LI receiving business-as-usual therapy in the public schools.
Results: Considerable variability was found in expected change across both samples of children over time, with preschoolers exhibiting larger effect sizes (d = 0.82 and 0.70, respectively) compared with school-age children (d = 0.49 and 0.55, respectively).
Conclusions: This study provides a first step toward establishing empirically based language benchmarks for children. These data offer stakeholders an initial tool for setting goals based on expected growth (practitioners), making informed decisions on language-based curricula (policymakers), and measuring effectiveness of intervention research (researchers).},
	language = {eng},
	number = {2},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Schmitt, Mary Beth and Logan, Jessica A. R. and Tambyraja, Sherine R. and Farquharson, Kelly and Justice, Laura M.},
	month = feb,
	year = {2017},
	pmid = {28124066},
	keywords = {Humans, Child, Language Development Disorders, Language Tests, Child, Preschool, Language Therapy, Linguistics, Child Language, Cohort Studies, Reference Values},
	pages = {364--378},
}

@book{fielding1996,
	address = {London},
	title = {Bridget {Jones}' {Diary}},
	isbn = {0-670-88072-8},
	publisher = {Picador},
	author = {Fielding, Helen},
	year = {1996},
}

@book{lord1968,
	title = {Stastistical theories of mental test scores},
	publisher = {Addison-Wesley},
	author = {Lord, F. M. and Novick, M. R. and Birnbaum, Allan},
	year = {1968},
}

@article{ogieladianea.2021,
	title = {Norm-{Referenced} {Language} {Test} {Selection} {Practices} for {Elementary} {School} {Children} {With} {Suspected} {Developmental} {Language} {Disorder}},
	volume = {52},
	url = {https://pubs.asha.org/doi/full/10.1044/2020_LSHSS-19-00067},
	doi = {10.1044/2020_LSHSS-19-00067},
	abstract = {Purpose
      Standardized norm-referenced tests are an important aspect of language assessment
         for school-age children. This study explored the language test selection practices
         of school-based speech-language pathologists (SLPs) working with elementary school
         children suspected of having developmental language disorder. Specifically, we investigated
         which tests were most commonly selected as clinicians' first-choice and follow-up
         tests, which factors impacted their test selection decisions, and what sources of
         information they used to determine the psychometric quality of tests.
      
      Method
      School-based SLPs completed a web-based questionnaire regarding their use of norm-referenced
         language tests. A total of 370 elementary school SLPs completed the questionnaire.
      
      Results
      The vast majority of participants indicated that omnibus language tests are their
         first choice of test. For follow-up tests, participants selected semantics tests,
         especially single-word vocabulary tests, significantly more often than tests of pragmatics,
         processing skills, and morphology/syntax. Participants identified multiple factors
         as affecting test selection, including availability, familiarity, psychometric features,
         and others. Although more SLPs reported using data-based than subjective sources of
         information to judge the psychometric quality of tests, a substantial proportion reported
         that they relied on subjective sources.
      
      Conclusions
      Clinicians have a strong preference for using omnibus language tests. Follow-up test
         selection does not appear to align with the language difficulties most associated
         with developmental language disorder. The substantial use of subjective information
         about psychometric qualities of tests suggests that many SLPs may not attend to the
         technical meanings of terms such as validity, reliability, and diagnostic accuracy.
         These results indicate a need for improvement in evidence-based language assessment
         practices.
      
      Supplemental Material
      https://doi.org/10.23641/asha.13022471},
	number = {1},
	urldate = {2021-07-08},
	journal = {Language, Speech, and Hearing Services in Schools},
	author = {{Ogiela Diane A.} and {Montzka Jennifer L.}},
	month = jan,
	year = {2021},
	note = {Publisher: American Speech-Language-Hearing Association},
	pages = {288--303},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/G5MN3G7M/Ogiela Diane A. and Montzka Jennifer L. - 2021 - Norm-Referenced Language Test Selection Practices .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/LN9GZYGB/2020_LSHSS-19-00067.html:text/html},
}

@article{nitido2020,
	title = {Diagnosis of {Developmental} {Language} {Disorder} in {Research} {Studies}},
	volume = {63},
	copyright = {Copyright American Speech-Language-Hearing Association Aug 2020},
	url = {https://www.proquest.com/docview/2471511328/abstract/C7D557B8F82F441CPQ/1},
	doi = {http://dx.doi.org/10.1044/2020_JSLHR-20-00091},
	abstract = {Purpose: The aim of this study was to investigate the extent to which researchers in the field of developmental language disorder are utilizing validated methods to diagnose their research participants. Method: We examined 90 research articles published from 2015 to 2019 that included English-speaking participants from the United States who were identified as having a developmental language disorder or specific language impairment. From these articles, we identified the tests and measures used to identify participants and classify them as healthy or impaired. We then consulted the test manuals and the literature to find information on sensitivity and specificity of the test and the evidence-based cut score that maximized identification accuracy. Results: Of the 90 articles examined, 38 (42\%) were found to reflect validated diagnostic methods, and 51 (58\%) did not. Conclusion: Our results illustrate that validated methods are used less than half of the time even by those who should have a high level of expertise and despite calls for increasing scientific rigor in research practices.},
	language = {English},
	number = {8},
	urldate = {2021-07-08},
	journal = {Journal of Speech, Language and Hearing Research (Online)},
	author = {Nitido, Hallie and Plante, Elena},
	month = aug,
	year = {2020},
	note = {Num Pages: 2777-2788
Place: Rockville, United States
Publisher: American Speech-Language-Hearing Association
Section: Research Note},
	keywords = {Specific language impairment, Handicapped--Hearing Impaired, Language disorders, Medical Sciences--Otorhinolaryngology, Standard scores, Accuracy, Clinical medicine, Developmental disabilities, Quantitative psychology, Research},
	pages = {2777--2788},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/BWZ62FWR/Nitido and Plante - 2020 - Diagnosis of Developmental Language Disorder in Re.pdf:application/pdf},
}

@article{nitido2020a,
	title = {Diagnosis of {Developmental} {Language} {Disorder} in {Research} {Studies}},
	volume = {63},
	copyright = {Copyright American Speech-Language-Hearing Association Aug 2020},
	url = {https://www.proquest.com/docview/2471511328/abstract/9F4F7026B1F942EBPQ/1},
	doi = {http://dx.doi.org/10.1044/2020_JSLHR-20-00091},
	abstract = {Purpose: The aim of this study was to investigate the extent to which researchers in the field of developmental language disorder are utilizing validated methods to diagnose their research participants. Method: We examined 90 research articles published from 2015 to 2019 that included English-speaking participants from the United States who were identified as having a developmental language disorder or specific language impairment. From these articles, we identified the tests and measures used to identify participants and classify them as healthy or impaired. We then consulted the test manuals and the literature to find information on sensitivity and specificity of the test and the evidence-based cut score that maximized identification accuracy. Results: Of the 90 articles examined, 38 (42\%) were found to reflect validated diagnostic methods, and 51 (58\%) did not. Conclusion: Our results illustrate that validated methods are used less than half of the time even by those who should have a high level of expertise and despite calls for increasing scientific rigor in research practices.},
	language = {English},
	number = {8},
	urldate = {2021-07-08},
	journal = {Journal of Speech, Language and Hearing Research (Online)},
	author = {Nitido, Hallie and Plante, Elena},
	month = aug,
	year = {2020},
	note = {Num Pages: 2777-2788
Place: Rockville, United States
Publisher: American Speech-Language-Hearing Association
Section: Research Note},
	keywords = {Specific language impairment, Handicapped--Hearing Impaired, Language disorders, Medical Sciences--Otorhinolaryngology, Standard scores, Accuracy, Clinical medicine, Developmental disabilities, Quantitative psychology, Research},
	pages = {2777--2788},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/DN7QV9GV/Nitido and Plante - 2020 - Diagnosis of Developmental Language Disorder in Re.pdf:application/pdf},
}

@article{denman2017,
	title = {Psychometric {Properties} of {Language} {Assessments} for {Children} {Aged} 4–12 {Years}: {A} {Systematic} {Review}},
	volume = {8},
	issn = {1664-1078},
	shorttitle = {Psychometric {Properties} of {Language} {Assessments} for {Children} {Aged} 4–12 {Years}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01515/full},
	doi = {10.3389/fpsyg.2017.01515},
	abstract = {Abstract Introduction: Standardized assessments are widely used by speech pathologists in clinical and research settings to evaluate the language abilities of school-aged children and inform decisions about diagnosis, eligibility for services and intervention. Given the significance of these decisions, it is important that assessments have sound psychometric properties. Objective: The aim of this systematic review was to examine the psychometric quality of currently available comprehensive language assessments for school-aged children and identify assessments with the best evidence for use. Methods: Using the PRISMA framework as a guideline, a search of five databases and a review of websites and textbooks was undertaken to identify language assessments and published material on the reliability and validity of these assessments. The methodological quality of selected studies was evaluated using the COSMIN taxonomy and checklist. Results: Fifteen assessments were evaluated. For most assessments evidence of hypothesis testing (convergent and discriminant validity) was identified; with a smaller number of assessments having some evidence of reliability and content validity. No assessments presented with evidence of structural validity, internal consistency or error measurement. Overall, all assessments were identified as having limitations with regards to evidence of psychometric quality. Conclusions: Further research is required to provide good evidence of psychometric quality for currently available language assessments. Of the assessments evaluated, the Assessment of Literacy and Language, the Clinical Evaluation of Language Fundamentals- 5th Edition, the Clinical Evaluation of Language Fundamentals – Preschool: 2nd Edition and the Preschool Language Scales – 5th Edition presented with most evidence and are thus recommended for use.},
	language = {English},
	urldate = {2021-07-08},
	journal = {Frontiers in Psychology},
	author = {Denman, Deborah and Speyer, Renée and Munro, Natalie and Pearce, Wendy M. and Chen, Yu-Wei and Cordier, Reinie},
	year = {2017},
	note = {Publisher: Frontiers},
	keywords = {assessment reliability, assessment validity, Language assessment, Language impairment, psychometric properties},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/4Z74WMQS/Denman et al. - 2017 - Psychometric Properties of Language Assessments fo.pdf:application/pdf},
}

@article{mokkink2010,
	title = {The {COSMIN} study reached international consensus on taxonomy, terminology, and definitions of measurement properties for health-related patient-reported outcomes},
	volume = {63},
	issn = {0895-4356},
	url = {https://www.sciencedirect.com/science/article/pii/S0895435610000909},
	doi = {10.1016/j.jclinepi.2010.02.006},
	abstract = {Objective
Lack of consensus on taxonomy, terminology, and definitions has led to confusion about which measurement properties are relevant and which concepts they represent. The aim was to clarify and standardize terminology and definitions of measurement properties by reaching consensus among a group of experts and to develop a taxonomy of measurement properties relevant for evaluating health instruments.
Study Design and Setting
An international Delphi study with four written rounds was performed. Participating experts had a background in epidemiology, statistics, psychology, and clinical medicine. The panel was asked to rate their (dis)agreement about proposals on a five-point scale. Consensus was considered to be reached when at least 67\% of the panel agreed.
Results
Of 91 invited experts, 57 agreed to participate and 43 actually participated. Consensus was reached on positions of measurement properties in the taxonomy (68–84\%), terminology (74–88\%, except for structural validity [56\%]), and definitions of measurement properties (68–88\%). The panel extensively discussed the positions of internal consistency and responsiveness in the taxonomy, the terms “reliability” and “structural validity,” and the definitions of internal consistency and reliability.
Conclusions
Consensus on taxonomy, terminology, and definitions of measurement properties was reached. Hopefully, this will lead to a more uniform use of terms and definitions in the literature on measurement properties.},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {Journal of Clinical Epidemiology},
	author = {Mokkink, Lidwine B. and Terwee, Caroline B. and Patrick, Donald L. and Alonso, Jordi and Stratford, Paul W. and Knol, Dirk L. and Bouter, Lex M. and de Vet, Henrica C. W.},
	month = jul,
	year = {2010},
	keywords = {Classification, Psychometrics, Delphi technique, Outcome assessment, Quality of life, Questionnaire, Terminology},
	pages = {737--745},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/2FDX4ZX4/Mokkink et al. - 2010 - The COSMIN study reached international consensus o.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/SCEVHV4S/S0895435610000909.html:text/html},
}

@article{reise2005,
	title = {Item {Response} {Theory}: {Fundamentals}, {Applications}, and {Promise} in {Psychological} {Research}},
	volume = {14},
	issn = {0963-7214},
	shorttitle = {Item {Response} {Theory}},
	url = {https://doi.org/10.1111/j.0963-7214.2005.00342.x},
	doi = {10.1111/j.0963-7214.2005.00342.x},
	abstract = {Item response theory (IRT) is an increasingly popular approach to the development, evaluation, and administration of psychological measures. We introduce, first, three IRT fundamentals: (a) item response functions, (b) information functions, and (c) invariance. We next illustrate how IRT modeling can improve the quality of psychological measurement. Available evidence suggests that the differences between IRT and traditional psychometric methods are not trivial; IRT applications can improve the precision and validity of psychological research across a wide range of subjects.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Current Directions in Psychological Science},
	author = {Reise, Steven P. and Ainsworth, Andrew T. and Haviland, Mark G.},
	month = apr,
	year = {2005},
	note = {Publisher: SAGE Publications Inc},
	keywords = {classical test theory, item response theory, psychometrics, scaling},
	pages = {95--101},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/CH5GV4Q6/Reise et al. - 2005 - Item Response Theory Fundamentals, Applications, .pdf:application/pdf},
}

@book{torgesen1999,
	address = {Austin, TX},
	title = {Test of {Word} {Reading} {Efficiency}},
	url = {https://www.pearsonclinical.co.uk/Psychology/ChildCognitionNeuropsychologyandLanguage/ChildLanguage/TOWRE2/TestofWordReadingEfficiencySecondEdition.aspx},
	urldate = {2021-07-12},
	publisher = {Pro-Ed},
	author = {Torgesen, Joseph K and Wagner, Richard K and Rashotte, Carole A.},
	year = {1999},
	file = {Test of Word Reading Efficiency - Second Edition (TOWRE-2) | Pearson Assessment:/Users/dorothybishop/Zotero/storage/9BIVV5PR/TestofWordReadingEfficiencySecondEdition.html:text/html},
}

@article{bishop1987,
	title = {Language-{Impaired} 4-{Year}-{Olds}},
	volume = {52},
	url = {https://pubs.asha.org/doi/10.1044/jshd.5202.156},
	doi = {10.1044/jshd.5202.156},
	abstract = {In a prospective, longitudinal study, 87 language-impaired children were assessed
         at the ages of 4, 4½, and 5½ years on a battery of language measures. In 37\% of children,
         who were termed the "good outcome group," the language disorder had resolved by the
         age of 5½ years so that children were indistinguishable from a control group. If one
         restricted consideration only to those 68 children whose nonverbal ability was within
         normal limits, the figure rose to 44\%. Outcome for individual children (good or poor)
         could be predicted with 90\% accuracy on the basis of test measures obtained at 4 years.
         The best predictor was ability to tell back a simple story to pictures. The one language
         measure that did not relate to outcome was phonological competence.},
	number = {2},
	urldate = {2021-07-12},
	journal = {Journal of Speech and Hearing Disorders},
	author = {BIshop, D V M and Edmundson, A},
	month = may,
	year = {1987},
	note = {Publisher: American Speech-Language-Hearing Association},
	pages = {156--173},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/E2U8HVEX/jshd.5202.html:text/html},
}

@book{renfrew1967,
	address = {Oxford},
	title = {Action {Picture} {Test}},
	url = {https://www.routledge.com/Action-Picture-Test/peechmark-Renfrew/p/book/9781138586208},
	abstract = {*The Renfrew Action Picture Test cards are now available for free, to assist with online assessments and the ease of administrating the test, but in order to fully score the RAPT the pack will need to be purchased. You can find the downloadable cards under ‘Support Materials’ on the Routledge.com product page*

Since its first publication in 1967, the Renfrew Action Picture Test has been a reach-for assessment used by a range of professionals dedicated to the speech and language development},
	language = {en},
	urldate = {2021-07-12},
	publisher = {Catherine Renfrew},
	author = {Renfrew, Catherine},
	year = {1967},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/FUPVGH4D/9781138586208.html:text/html},
}

@book{renfrew2010,
	title = {Bus {Story} {Test}: {Revised} {Edition}},
	shorttitle = {Bus {Story} {Test}},
	url = {https://www.routledge.com/Bus-Story-Test-Revised-Edition/Renfrew/p/book/9780863888083},
	abstract = {The age level of consecutive speech used in retelling a story can be assessed from the information content, sentence length and grammatical usage of this revised test. The test includes a coloured picture story book, a scoring form to photocopy and a manual, but also requires the use of audio recording equipment. Catherine Renfrew's three tests have been used for many years and provide a means of assessing children's speech and language. All tests are suitable for use with 3-8 year olds are norm},
	language = {en},
	urldate = {2021-07-12},
	publisher = {Routledge},
	author = {Renfrew, Catherine},
	year = {2010},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/WXQ7ZTHE/9780863888083.html:text/html},
}

@book{crystal1977,
	address = {London},
	title = {The {Grammatical} {Analysis} of {Language} {Disability}: {A} {Procedure} for {Assessment} and {Remediation}},
	publisher = {Edward Arnold},
	author = {Crystal, David and Fletcher, Paul and Garman, Michael},
	year = {1977},
}

@article{loeb2001,
	title = {Language changes associated with {Fast} {ForWord}-language: {Evidence} from case studies},
	volume = {10},
	issn = {1558-9110(Electronic),1058-0360(Print)},
	shorttitle = {Language changes associated with {Fast} {ForWord}-language},
	doi = {10.1044/1058-0360(2001/020)},
	abstract = {The Scientific Learning Corporation claims that Fast ForWord-Language (FFW-L) yields 1-1/2 to 3 years language gain over a 6-week period. The authors evaluated various aspects of this claim by measuring the language changes of 4 children (aged 5 yrs 6 mo to 8 yrs 1 mo) who received FFW-L language intervention in their homes. Language change was assessed immediately following intervention and 3 months later, using standardized language measures, spontaneous measures of syntactic complexity, reading measures, pragmatic measures, and parent and teacher reports. Three of the 4 children successfully completed FFW-L, and all made gains on some of the same standardized measures used by P. Tallal et al (1996), although the improvements the authors observed were generally smaller than those previously reported. All children also made gains on measures of pragmatic performance. However, very few changes were observed in the children's Developmental Sentence Scores. Parents and teachers did not report many differences in performance after intervention; however, parental satisfaction with the program was generally high. 61\% of the gains observed at posttesting were maintained 3 months following intervention. Significant positive change occurred on 10\% of the items. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {American Journal of Speech-Language Pathology},
	author = {Loeb, Diane Frome and Stoke, Christene and Fey, Marc E.},
	year = {2001},
	note = {Place: US
Publisher: American Speech-Language-Hearing Assn},
	keywords = {Communication Disorders, Computer Applications, Computer Software, Language Disorders},
	pages = {216--230},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/AHF8NP79/2001-11320-003.html:text/html},
}

@article{bull2007,
	title = {Sunflower therapy for children with specific learning difficulties (dyslexia): a randomised, controlled trial},
	volume = {13},
	issn = {1744-3881},
	shorttitle = {Sunflower therapy for children with specific learning difficulties (dyslexia)},
	doi = {10.1016/j.ctcp.2006.07.003},
	abstract = {The aim of the study was to determine the clinical and perceived effectiveness of the Sunflower therapy in the treatment of childhood dyslexia. The Sunflower therapy includes applied kinesiology, physical manipulation, massage, homeopathy, herbal remedies and neuro-linguistic programming. A multi-centred, randomised controlled trial was undertaken with 70 dyslexic children aged 6-13 years. The research study aimed to test the research hypothesis that dyslexic children 'feel better' and 'perform better' as a result of treatment by the Sunflower therapy. Children in the treatment group and the control group were assessed using a battery of standardised cognitive, Literacy and self-esteem tests before and after the intervention. Parents of children in the treatment group gave feedback on their experience of the Sunflower therapy. Test scores were compared using the Mann Whitney, and Wilcoxon statistical tests. While both groups of children improved in some of their test scores over time, there were no statistically significant improvements in cognitive or Literacy test performance associated with the treatment. However, there were statistically significant improvements in academic self-esteem, and reading self-esteem, for the treatment group. The majority of parents (57.13\%) felt that the Sunflower therapy was effective in the treatment of learning difficulties. Further research is required to verify these findings, and should include a control group receiving a dummy treatment to exclude placebo effects.},
	language = {eng},
	number = {1},
	journal = {Complementary Therapies in Clinical Practice},
	author = {Bull, Leona},
	month = feb,
	year = {2007},
	pmid = {17210507},
	keywords = {Female, Humans, Male, Child, Dyslexia, Acupressure, Combined Modality Therapy, Complementary Therapies, Dietary Supplements, Kinesiology, Applied, Manipulation, Osteopathic, Neurolinguistic Programming, Phytotherapy},
	pages = {15--24},
}

@book{brown1973,
	address = {Cambridge, MA},
	title = {A {First} {Language} — {Roger} {Brown}},
	url = {https://www.hup.harvard.edu/catalog.php?isbn=9780674732469},
	abstract = {For many years, Brown and his colleagues have studied the developing language of pre-school children -- the language that ultimately will permit them to understand themselves and their world. This longitudinal research records the conversational performances of three children, studying semantic and grammatical aspects of their language development.},
	language = {en},
	urldate = {2021-07-12},
	publisher = {Harvard University Press},
	author = {Brown, Roger},
	year = {1973},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/BTWCCNJ6/catalog.html:text/html},
}

@article{aksayli2019,
	title = {The cognitive and academic benefits of {Cogmed}: {A} meta-analysis},
	volume = {27},
	issn = {1747-938X},
	shorttitle = {The cognitive and academic benefits of {Cogmed}},
	url = {https://www.sciencedirect.com/science/article/pii/S1747938X18303658},
	doi = {10.1016/j.edurev.2019.04.003},
	abstract = {Cogmed Working Memory Training (CWMT) is a commercial cognitive-training program designed to foster working-memory capacity. Enhanced working-memory capacity is then supposed to increase one's overall cognitive function and academic achievement. This meta-analysis investigates the effects of CWMT on cognitive and academic outcomes. The inclusion criteria were met by 50 studies (637 effect sizes). Highly consistent near-zero effects were estimated in far-transfer measures of cognitive ability (e.g., attention and intelligence) and academic achievement (language ability and mathematics). By contrast, slightly heterogeneous small to medium effects were observed in memory tasks (i.e., near transfer). Moderator analysis showed that these effects were weaker for near-transfer measures not directly related to the trained tasks. These results highlight that, while near transfer occurs regularly, far transfer is rare or, possibly, inexistent. Transfer thus appears to be a function of the degree of overlap between trained tasks and outcome tasks.},
	language = {en},
	urldate = {2021-07-12},
	journal = {Educational Research Review},
	author = {Aksayli, N. Deniz and Sala, Giovanni and Gobet, Fernand},
	month = jun,
	year = {2019},
	keywords = {Meta-analysis, Cogmed, Transfer, Working memory training},
	pages = {229--243},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/YILZ83YJ/Aksayli et al. - 2019 - The cognitive and academic benefits of Cogmed A m.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/R73D7Z7U/S1747938X18303658.html:text/html},
}

@article{ratner2016,
	title = {Your {Laptop} to the {Rescue}: {Using} the {Child} {Language} {Data} {Exchange} {System} {Archive} and {CLAN} {Utilities} to {Improve} {Child} {Language} {Sample} {Analysis}},
	volume = {37},
	issn = {1098-9056},
	shorttitle = {Your {Laptop} to the {Rescue}},
	doi = {10.1055/s-0036-1580742},
	abstract = {In this article, we review the advantages of language sample analysis (LSA) and explain how clinicians can make the process of LSA faster, easier, more accurate, and more insightful than LSA done "by hand" by using free, available software programs such as Computerized Language Analysis (CLAN). We demonstrate the utility of CLAN analysis in studying the expressive language of a very large cohort of 24-month-old toddlers tracked in a recent longitudinal study; toddlers in particular are the most likely group to receive LSA by clinicians, but existing reference "norms" for this population are based on fairly small cohorts of children. Finally, we demonstrate how a CLAN utility such as KidEval can now extract potential normative data from the very large number of corpora now available for English and other languages at the Child Language Data Exchange System project site. Most of the LSA measures that we studied appear to show developmental profiles suggesting that they may be of specifically higher value for children at certain ages, because they do not show an even developmental trajectory from 2 to 7 years of age.},
	language = {eng},
	number = {2},
	journal = {Seminars in Speech and Language},
	author = {Ratner, Nan Bernstein and MacWhinney, Brian},
	month = may,
	year = {2016},
	pmid = {27111268},
	keywords = {Humans, Language, Child, Child Language, Information Dissemination, Longitudinal Studies},
	pages = {74--84},
}

@article{forsythe2019,
	title = {Patient {Engagement} {In} {Research}: {Early} {Findings} {From} {The} {Patient}-{Centered} {Outcomes} {Research} {Institute}},
	volume = {38},
	issn = {0278-2715},
	shorttitle = {Patient {Engagement} {In} {Research}},
	url = {https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2018.05067},
	doi = {10.1377/hlthaff.2018.05067},
	abstract = {Charged with ensuring that research produces useful evidence to inform health decisions, the Patient-Centered Outcomes Research Institute (PCORI) requires investigators to engage patients and other health care stakeholders, such as clinicians and payers, in the research process. Many PCORI studies result in articles published in peer-reviewed journals that detail research findings and engagement’s role in research. To inform practices for engaging patients and others as research partners, we analyzed 126 articles that described engagement approaches and contributions to research. PCORI projects engaged patients and others as consultants and collaborators in determining the study design, selecting study outcomes, tailoring interventions to meet patients’ needs and preferences, and enrolling participants. Many articles reported that engagement provided valuable contributions to research feasibility, acceptability, rigor, and relevance, while a few noted trade-offs of engagement. The findings suggest that engagement can support more relevant research through better alignment with patients’ and clinicians’ real-world needs and concerns.},
	number = {3},
	urldate = {2021-07-26},
	journal = {Health Affairs},
	author = {Forsythe, Laura P. and Carman, Kristin L. and Szydlowski, Victoria and Fayish, Lauren and Davidson, Laurie and Hickam, David H. and Hall, Courtney and Bhat, Geeta and Neu, Denese and Stewart, Lisa and Jalowsky, Maggie and Aronson, Naomi and Anyanwu, Chinenye Ursla},
	month = mar,
	year = {2019},
	note = {Publisher: Health Affairs},
	pages = {359--367},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/2LQV6S87/Forsythe et al. - 2019 - Patient Engagement In Research Early Findings Fro.pdf:application/pdf},
}

@article{dockrell2015,
	title = {Measurement {Issues}: {Assessing} language skills in young children},
	volume = {20},
	issn = {1475-3588},
	shorttitle = {Measurement {Issues}},
	url = {https://acamh.onlinelibrary.wiley.com/doi/abs/10.1111/camh.12072},
	doi = {10.1111/camh.12072},
	abstract = {Background Language and communication skills are central to children's ability to engage in social relationships and access learning experiences. This paper identifies issues which practitioners and researchers should consider when assessing language skills. A range of current language assessments is reviewed. Key findings Current screening measures do not meet psychometric prerequisites to identify language problems. There are significant challenges in the interpretation of language assessments, where socioeconomic status, language status and dialect, hearing impairment and test characteristics impact results. Conclusions Psychometrically sound assessments of language are an essential component of developing effective and efficient interventions. The language trajectories of preschool children vary substantially; current screening measures have significant limitations. Composite measures of language performance are better indicators of language problems and disorders than single measures of component skills.},
	language = {en},
	number = {2},
	urldate = {2021-07-26},
	journal = {Child and Adolescent Mental Health},
	author = {Dockrell, Julie E. and Marshall, Chloë R.},
	year = {2015},
	note = {\_eprint: https://acamh.onlinelibrary.wiley.com/doi/pdf/10.1111/camh.12072},
	keywords = {assessment, dynamic, Language, preschool, psychometrics},
	pages = {116--125},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/AJDYINNM/Dockrell and Marshall - 2015 - Measurement Issues Assessing language skills in y.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/2MZNMZ3U/camh.html:text/html},
}

@article{ebbels2019,
	title = {Evidence-based pathways to intervention for children with language disorders},
	volume = {54},
	issn = {1368-2822},
	url = {https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcAuth=DOISource&SrcApp=WOS&KeyAID=10.1111%2F1460-6984.12387&DestApp=DOI&SrcAppSID=F5QzQ8a9YpOKqcBdgga&SrcJTitle=INTERNATIONAL+JOURNAL+OF+LANGUAGE+%26+COMMUNICATION+DISORDERS&DestDOIRegistrantName=Wiley+%28Blackwell+Publishing%29},
	doi = {10.1111/1460-6984.12387},
	abstract = {Background Paediatric speech and language therapist (SLT) roles often involve planning individualized intervention for specific children, working collaboratively with families and education staff, providing advice, training and coaching and raising awareness. A tiered approach to service delivery is currently recommended whereby services become increasingly specialized and individualized for children with greater needs. Aims To stimulate discussion regarding delivery of SLT services by examining evidence regarding the effectiveness of (1) intervention for children with language disorders at different tiers and (2) SLT roles within these tiers; and to propose an evidence-based model of SLT service delivery and a flowchart to aid clinical decision-making. Methods \& Procedures Meta-analyses and systematic reviews, together with controlled, peer-reviewed group studies where recent systematic reviews were not available, of interventions for children with language disorders are discussed, alongside the differing roles SLTs play in these interventions. Gaps in the evidence base are highlighted. Main Contribution The service-delivery model presented resembles the tiered model commonly used in education services, but divides individualized (Tier 3) services into Tier 3A: indirect intervention delivered by non-SLTs, and Tier 3B: direct intervention by an SLT. We report evidence for intervention effectiveness, which children might best be served by each tier, the role SLTs could take within each tier and the effectiveness of these roles. Regarding universal interventions provided to all children (Tier 1) and those targeted at children with language weaknesses or vulnerabilities (Tier 2), there is growing evidence that approaches led by education services can be effective when staff are highly trained and well supported. There is currently limited evidence regarding additional benefit of SLT-specific roles at Tiers 1 and 2. With regard to individualized intervention (Tier 3), children with complex or pervasive language disorders can progress following direct individualized intervention (Tier 3B), whereas children with milder or less pervasive difficulties can make progress when intervention is managed by an SLT, but delivered indirectly by others (Tier 3A), provided they are well trained and supported, and closely monitored. Conclusions \& Implications SLTs have a contribution to make at all tiers, but where prioritization for clinical services is a necessity, we need to establish the relative benefits and cost-effectiveness at each tier. Good evidence exists for SLTs delivering direct individualized intervention and we should ensure that this is available to children with pervasive and/or complex language disorders. In cases where service models are being provided which lack evidence, we strongly recommend that SLTs investigate the effectiveness of their approaches.},
	language = {English},
	number = {1},
	urldate = {2021-07-26},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Ebbels, Susan H. and McCartney, Elspeth and Slonims, Vicky and Dockrell, Julie E. and Norbury, Courtenay Frazier},
	month = feb,
	year = {2019},
	note = {Place: Hoboken
Publisher: Wiley
WOS:000454678800001},
	keywords = {clinical marker, communication outcomes, evidence based practice (EBP), intervention, joint attention intervention, language disorder, oral language, randomized controlled-trial, school-age-children, service   delivery models, vocabulary intervention, word   knowledge, young-children},
	pages = {3--19},
	file = {Accepted Version:/Users/dorothybishop/Zotero/storage/URTS9DXG/Ebbels et al. - 2019 - Evidence-based pathways to intervention for childr.pdf:application/pdf},
}

@article{levitt2011,
	title = {Was {There} {Really} a {Hawthorne} {Effect} at the {Hawthorne} {Plant}? {An} {Analysis} of the {Original} {Illumination} {Experiments}},
	volume = {3},
	issn = {1945-7782},
	shorttitle = {Was {There} {Really} a {Hawthorne} {Effect} at the {Hawthorne} {Plant}?},
	url = {https://www.aeaweb.org/articles?id=10.1257/app.3.1.224},
	doi = {10.1257/app.3.1.224},
	abstract = {The "Hawthorne effect" draws its name from a landmark set of studies conducted at the Hawthorne plant in the 1920s. The data from the first and most influential of these studies, the "Illumination Experiment," were never formally analyzed and were thought to have been destroyed. Our research has uncovered these data. Existing descriptions of supposedly remarkable data patterns prove to be entirely fictional. We do find more subtle manifestations of possible Hawthorne effects. We also propose a new means of testing for Hawthorne effects based on excess responsiveness to experimenter-
induced variations relative to naturally occurring variation. (JEL C90, J24, J28, M12, M54, N32)},
	language = {en},
	number = {1},
	urldate = {2021-07-27},
	journal = {American Economic Journal: Applied Economics},
	author = {Levitt, Steven D. and List, John A.},
	month = jan,
	year = {2011},
	keywords = {Canada: 1913-, Design of Experiments: General, Human Capital, Executive Compensation, Personnel Economics: Labor Management, Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S., Job Satisfaction, Labor Productivity, Safety, Occupational Choice, Related Public Policy, Personnel Management, Skills},
	pages = {224--238},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/25H6FQU2/Levitt and List - 2011 - Was There Really a Hawthorne Effect at the Hawthor.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/C5D8FVF7/articles.html:text/html},
}

@article{freedman1987,
	title = {Equipoise and the {Ethics} of {Clinical} {Research}},
	volume = {317},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJM198707163170304},
	doi = {10.1056/NEJM198707163170304},
	abstract = {THERE is widespread agreement that ethics requires that each clinical trial begin with an honest null hypothesis.1 , 2 In the simplest model, testing a new treatment B on a defined patient population P for which the current accepted treatment is A, it is necessary that the clinical investigator be in a state of genuine uncertainty regarding the comparative merits of treatments A and B for population P. If a physician knows that these treatments are not equivalent, ethics requires that the superior treatment be recommended. Following Fried, I call this state of uncertainty about the relative merits of A and B . . .},
	number = {3},
	urldate = {2021-07-27},
	journal = {New England Journal of Medicine},
	author = {Freedman, Benjamin},
	month = jul,
	year = {1987},
	pmid = {3600702},
	note = {Publisher: Massachusetts Medical Society
\_eprint: https://doi.org/10.1056/NEJM198707163170304},
	pages = {141--145},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/QEXBZQL4/Freedman - 1987 - Equipoise and the Ethics of Clinical Research.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/6DVI4Y3D/NEJM198707163170304.html:text/html},
}

@article{bishop2006,
	title = {Resistance of grammatical impairment to computerized comprehension training in children with specific and non-specific language impairments},
	volume = {41},
	issn = {1368-2822},
	doi = {10.1080/13682820500144000},
	abstract = {BACKGROUND: Receptive language impairments in school-age children have a poor prognosis, yet there is a dearth of research on effective interventions.
AIMS: Children's responses to a computerized grammatical training program were evaluated to consider whether repeated responding to spoken sentences with variable semantic content and the same syntactic structure would lead to consistent and fluent comprehension.
METHODS \& PROCEDURES: Children with receptive language impairments aged from 8 to 13 years were randomly assigned to three groups: Group S (n = 12) responded to reversible sentences in a computerized game, using speech stimuli with pauses before critical phrases. Group M (n = 12) had the same stimuli acoustically modified to lengthen and amplify dynamic portions of the signal. Group U (n = 9) was an untrained control group. On average, children in groups S and M completed over 1000 training trials, focusing on training comprehension of reversible sentences.
OUTCOMES \& RESULTS: Although responses speeded up over the course of training, and most children performed well above chance, accuracy typically remained below 95\% correct for constructions such as above/below and reversible active/passive. Trained groups did not differ from untrained children on language or auditory outcomes. There was no evidence that acoustically modified speech input enhanced comprehension.
CONCLUSIONS: Rote training of comprehension of reversible sentences does not seem to be an effective approach to remediating such problems. For most children, the pattern of performance suggested that the problem was not a lack of syntactic knowledge, bur rather limited processing capacity that led to failures of on-line computation of meaning.},
	language = {eng},
	number = {1},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Bishop, D. V. M. and Adams, C. V. and Rosen, S.},
	month = feb,
	year = {2006},
	pmid = {16272001},
	keywords = {Adolescent, Auditory Perception, Child, Cognition, Discrimination Learning, Humans, Language Development Disorders, Language Therapy, Reaction Time, Speech, Speech Acoustics, Speech Discrimination Tests, Therapy, Computer-Assisted, Treatment Outcome},
	pages = {19--40},
}

@article{bowen2020,
	title = {Independent research and the {Arrowsmith} {Program}},
	volume = {46},
	url = {http://www.onlinedigeditions.com/publication/?i=655062&p=54&pp=1&view=issueViewer},
	language = {en-US},
	number = {1},
	urldate = {2021-07-27},
	journal = {Perspectives on Language and Literacy},
	author = {Bowen, Caroline},
	year = {2020},
	pages = {47--54},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/WDRM8FH6/publication.html:text/html},
}

@article{steiner2012,
	title = {Issues and {Theoretical} {Constructs} {Regarding} {Parent} {Education} for {Autism} {Spectrum} {Disorders}},
	volume = {42},
	issn = {0162-3257},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3810158/},
	doi = {10.1007/s10803-011-1194-0},
	abstract = {Participation of parents of children with autism is commonplace in most comprehensive intervention programs, yet, there is limited research relating to the best practices in this area. This article provides an overview of parent education programs for young children with autism and details data-driven procedures which are associated with improved parent and child outcomes. In addition, we provide a troubleshooting guide based on the literature for professionals regarding a variety of complex issues which may arise during parent education.},
	number = {6},
	urldate = {2021-07-27},
	journal = {Journal of autism and developmental disorders},
	author = {Steiner, Amanda M. and Koegel, Lynn K. and Koegel, Robert L. and Ence, Whitney A.},
	month = jun,
	year = {2012},
	pmid = {21336525},
	pmcid = {PMC3810158},
	pages = {10.1007/s10803--011--1194--0},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/2DTFM2EX/Steiner et al. - 2012 - Issues and Theoretical Constructs Regarding Parent.pdf:application/pdf},
}

@article{weiss1991,
	title = {Stressors experienced by family caregivers of children with pervasive developmental disorders {\textbar} {SpringerLink}},
	volume = {21},
	url = {https://link.springer.com/article/10.1007/BF00705906},
	urldate = {2021-07-27},
	journal = {Child Psychiatry and Human Development},
	author = {Weiss, S},
	year = {1991},
	pages = {203--216},
	file = {Stressors experienced by family caregivers of children with pervasive developmental disorders | SpringerLink:/Users/dorothybishop/Zotero/storage/7P9BPDTX/BF00705906.html:text/html},
}

@article{burgoyne2018,
	title = {Evaluation of a parent-delivered early language enrichment programme: evidence from a randomised controlled trial},
	volume = {59},
	issn = {1469-7610},
	shorttitle = {Evaluation of a parent-delivered early language enrichment programme},
	doi = {10.1111/jcpp.12819},
	abstract = {BACKGROUND: It is widely believed that increasing parental involvement can improve children's educational outcomes although we lack good evidence for such claims. This study evaluated the effectiveness of a parent-delivered early language enrichment programme.
METHODS: We conducted a randomised controlled trial (RCT) with 208 preschool children and their parents living in socially diverse areas in the United Kingdom. Families were allocated to an oral language programme (N = 103) or an active control programme targeting motor skills (N = 105). Parents delivered the programmes to their child at home in daily 20-min sessions over 30 weeks of teaching.
RESULTS: Children receiving the language programme made significantly larger gains in language (d = .21) and narrative skills (d = .36) than children receiving the motor skills programme at immediate posttest. Effects on language were maintained 6 months later (d = .34), and at this point, the language group also scored higher on tests of early literacy (d values=.35 and .42). There was no evidence that the movement programme improved motor skills.
CONCLUSIONS: This study provides evidence for the effectiveness of a parent-delivered language enrichment programme. Further large-scale evaluations of the programme are needed to confirm and extend these findings.},
	language = {eng},
	number = {5},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Burgoyne, Kelly and Gardner, Rachel and Whiteley, Helen and Snowling, Margaret J. and Hulme, Charles},
	month = may,
	year = {2018},
	pmid = {28940192},
	keywords = {Child, Preschool, Early Intervention, Educational, early literacy, education, Female, Humans, Language, Language Development, Literacy, Male, motor skills, Motor Skills, Outcome Assessment, Health Care, parents, Parents, randomised controlled trial, United Kingdom},
	pages = {545--555},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/9AYMML2A/Burgoyne et al. - 2018 - Evaluation of a parent-delivered early language en.pdf:application/pdf},
}

@article{gillam2008,
	title = {The {Efficacy} of {Fast} {ForWord}-{Language} {Intervention} in {School}-{Age} {Children} with {Language} {Impairment}: {A} {Randomized} {Controlled} {Trial}},
	volume = {51},
	issn = {1092-4388},
	shorttitle = {The {Efficacy} of {Fast} {ForWord}-{Language} {Intervention} in {School}-{Age} {Children} with {Language} {Impairment}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2361096/},
	doi = {10.1044/1092-4388(2008/007)},
	abstract = {Purpose
A randomized controlled trial (RCT) was conducted to compare the language and auditory processing outcomes of children assigned to Fast ForWord-Language (FFW-L) to the outcomes of children assigned to nonspecific or specific language intervention comparison treatments that did not contain modified speech.

Method
Two hundred and sixteen children between the ages of 6 and 9 years with language impairments were randomly assigned to one of four arms: Fast ForWord-Language (FFW-L), academic enrichment (AE), computer-assisted language intervention (CALI), or individualized language intervention (ILI) provided by a speech-language pathologist. All children received 1 hour and 40 minutes of treatment, 5 days per week, for 6 weeks. Language and auditory processing measures were administered to the children by blinded examiners before treatment, immediately after treatment, 3 months after treatment, and 6 months after treatment.

Results
The children in all four arms improved significantly on a global language test and a test of backward masking. Children with poor backward masking scores who were randomized to the FFW-L arm did not present greater improvement on the language measures than children with poor backward masking scores who were randomized to the other three arms. Effect sizes, analyses of standard error of measurement, and normalization percentages supported the clinical significance of the improvements on the CASL. There was a treatment effect for the Blending Words subtest on the Comprehensive Test of Phonological Processing (). Participants in the FFW-L and CALI arms earned higher phonological awareness scores than children in the ILI and AE arms at the six-month follow-up testing.

Conclusion
Fast ForWord-Language, the language intervention that provided modified speech to address a hypothesized underlying auditory processing deficit, was not more effective at improving general language skills or temporal processing skills than a nonspecific comparison treatment (AE) or specific language intervention comparison treatments (CALI and ILI) that did not contain modified speech stimuli. These findings call into question the temporal processing hypothesis of language impairment and the hypothesized benefits of using acoustically modified speech to improve language skills. The finding that children in the three treatment arms and the active comparison arm made clinically relevant gains on measures of language and temporal auditory processing informs our understanding of the variety of intervention activities that can facilitate development.},
	number = {1},
	urldate = {2021-07-27},
	journal = {Journal of speech, language, and hearing research : JSLHR},
	author = {Gillam, Ronald B. and Loeb, Diane Frome and Hoffman, LaVae M. and Bohman, Thomas and Champlin, Craig A. and Thibodeau, Linda and Widen, Judith and Brandel, Jayne and Friel-Patti, Sandy},
	month = feb,
	year = {2008},
	pmid = {18230858},
	pmcid = {PMC2361096},
	pages = {97--119},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/PPWTSQAL/Gillam et al. - 2008 - The Efficacy of Fast ForWord-Language Intervention.pdf:application/pdf},
}

@article{mcgillion2017,
	title = {A randomised controlled trial to test the effect of promoting caregiver contingent talk on language development in infants from diverse socioeconomic status backgrounds},
	volume = {58},
	issn = {1469-7610},
	url = {https://acamh.onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.12725},
	doi = {10.1111/jcpp.12725},
	abstract = {Background Early language skills are critical for later academic success. Lower socioeconomic status (SES) children tend to start school with limited language skills compared to advantaged peers. We test the hypothesis that this is due in part to differences in caregiver contingent talk during infancy (how often the caregiver talks about what is in the focus of the infant's attention). Methods In a randomised controlled trial with high and low SES families, 142 11-month olds and their caregivers were randomly allocated to either a contingent talk intervention or a dental health control. Families in the language intervention watched a video about contingent talk and were asked to practise it for 15 min a day for a month. Caregiver communication was assessed at baseline and after 1 month. Infant communication was assessed at baseline, 12, 15, 18 and 24 months. Results At baseline, social gradients were observed in caregiver contingent talk to their 11-month olds (but not in infant communication). At posttest, when infants were 12 months old, caregivers across the SES spectrum who had been allocated to the language intervention group engaged in significantly more contingent talk. Lower SES caregivers in this intervention group also reported that their children produced significantly more words at 15 and 18 months. Effects of the intervention did not persist at 24 months. Instead expressive vocabulary at this age was best predicted by baseline infant communication, baseline contingent talk and SES. Conclusions A social gradient in children's communication emerges during the second year of life. A low-intensity intervention demonstrated that it is possible to increase caregiver contingent talk and that this is effective in promoting vocabulary growth for lower SES infants in the short term. However, these effects are not long-lasting, suggesting that follow-up interventions may be necessary to yield benefits lasting to school entry.},
	language = {en},
	number = {10},
	urldate = {2021-07-27},
	journal = {Journal of Child Psychology and Psychiatry},
	author = {McGillion, Michelle and Pine, Julian M. and Herbert, Jane S. and Matthews, Danielle},
	year = {2017},
	note = {\_eprint: https://acamh.onlinelibrary.wiley.com/doi/pdf/10.1111/jcpp.12725},
	keywords = {Infancy, intervention, language, parenting, socioeconomic status, vocabulary},
	pages = {1122--1131},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/ACAW4PEC/McGillion et al. - 2017 - A randomised controlled trial to test the effect o.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/U5L7BV5H/jcpp.html:text/html},
}

@article{noseworthy1994,
	title = {The impact of blinding on the results of a randomized, placebo‐controlled multiple sclerosis clinical trial},
	volume = {44},
	copyright = {© 1994 by the American Academy of Neurology},
	issn = {0028-3878, 1526-632X},
	url = {https://n.neurology.org/content/44/1/16},
	doi = {10.1212/WNL.44.1.16},
	abstract = {In the randomized, placebo-controlled, physician-blinded Canadian cooperative trial of cyclophosphamide and plasma exchange, neither active treatment regimens (group I: IV cyclophosphamide and prednisone; group II: weekly plasma exchange, oral cyclophosphamide, and prednisone) were superior to placebo (group III: sham plasma exchange and placebo medications) using the blinded, evaluating neurologists' assessments of disease course (primary analysis). All patients were examined by both a blinded and an unblinded neurologist at each assessment in this trial. We compared the blinded and unblinded neurologists' judgment of treatment response and analyzed the clinical behavior of patients who correctly guessed their treatment. The unblinded (but not the blinded) neurologists' scores demonstrated an apparent treatment benefit at 6, 12, and 24 months for the group II patients (not group I or placebo; p {\textless}0.05, two-tailed). There were no significant differences in the time to treatment failure or in the proportions of patients improved, stable, or worse between the group II and group III patients who correctly guessed their treatment assignments and those who did not. Physician blinding prevented an erroneous conclusion about treatment efficacy (false positive, type 1 error).},
	language = {en},
	number = {1},
	urldate = {2021-07-27},
	journal = {Neurology},
	author = {Noseworthy, J. H. and Ebers, G. C. and Vandervoort, M. K. and Farquhar, R. E. and Yetisir, E. and Roberts, R.},
	month = jan,
	year = {1994},
	pmid = {8290055},
	note = {Publisher: Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology
Section: Articles},
	pages = {16--16},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/Y6TZ73H9/16.html:text/html},
}

@article{hey2014,
	title = {The questionable use of unequal allocation in confirmatory trials},
	volume = {82},
	issn = {1526-632X},
	doi = {10.1212/01.wnl.0000438226.10353.1c},
	abstract = {Randomization is the standard means for addressing known and unknown confounders within the patient population in clinical trials. Although random assignment to treatment arms on a 1:1 basis has long been the norm, many 2-armed confirmatory trials now use unequal allocation schemes where the number of patients receiving investigational interventions exceeds those in the comparator arm. In what follows, we offer 3 arguments for why investigators, institutional review boards, and data and safety monitoring boards should exercise caution when planning or reviewing 2-armed confirmatory trials involving unequal allocation ratios. We close by laying out some of the conditions where uneven allocation can be justified ethically.},
	language = {eng},
	number = {1},
	journal = {Neurology},
	author = {Hey, Spencer Phillips and Kimmelman, Jonathan},
	month = jan,
	year = {2014},
	pmid = {24306005},
	pmcid = {PMC3873626},
	keywords = {Animals, Clinical Protocols, Humans, Random Allocation, Randomized Controlled Trials as Topic, Research Design},
	pages = {77--79},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/TKXSHKH8/Hey and Kimmelman - 2014 - The questionable use of unequal allocation in conf.pdf:application/pdf},
}

@article{hoare2013,
	title = {Introduction to a generalized method for adaptive randomization in trials},
	volume = {14},
	issn = {1745-6215},
	url = {https://doi.org/10.1186/1745-6215-14-19},
	doi = {10.1186/1745-6215-14-19},
	abstract = {Ideally clinical trials should use some form of randomization for allocating participants to the treatment groups under trial. As an integral part of the process of assessing the effectiveness of these treatment groups, randomization performed well can reduce, if not eliminate, some forms of bias that can be evident in non-randomized trials. Given the vast set of possible randomization methods to choose from we demonstrate a method that incorporates many of the advantages of these other methods.},
	number = {1},
	urldate = {2021-07-27},
	journal = {Trials},
	author = {Hoare, Zoë SJ and Whitaker, Christopher J. and Whitaker, Rhiannon},
	month = jan,
	year = {2013},
	keywords = {Allocation Ratio, Consort Statement, Relevant Level, Simple Randomization, Stratification Variable},
	pages = {19},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/KADX5AIF/Hoare et al. - 2013 - Introduction to a generalized method for adaptive .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/J6979AP8/1745-6215-14-19.html:text/html},
}

@article{pocock1975,
	title = {Sequential treatment assignment with balancing for prognostic factors in the controlled clinical trial},
	volume = {31},
	issn = {0006-341X},
	abstract = {In controlled clinical trials there are usually several prognostic factors known or thought to influence the patient's ability to respond to treatment. Therefore, the method of sequential treatment assignment needs to be designed so that treatment balance is simultaneously achieved across all such patients factor. Traditional methods of restricted randomization such as "permuted blocks within strata" prove inadequate once the number of strata, or combinations of factor levels, approaches the sample size. A new general procedure for treatment assignment is described which concentrates on minimizing imbalance in the distributions of treatment numbers within the levels of each individual prognostic factor. The improved treatment balance obtained by this approach is explored using simulation for a simple model of a clinical trial. Further discussion centers on the selection, predictability and practicability of such a procedure.},
	language = {eng},
	number = {1},
	journal = {Biometrics},
	author = {Pocock, S. J. and Simon, R.},
	month = mar,
	year = {1975},
	pmid = {1100130},
	keywords = {Carmustine, Clinical Trials as Topic, Cyclophosphamide, Evaluation Studies as Topic, Humans, Lymphoma, Models, Theoretical, Prednisone, Prognosis, Statistics as Topic, Vincristine},
	pages = {103--115},
}

@article{scott2002,
	title = {The method of minimization for allocation to clinical trials. a review},
	volume = {23},
	issn = {0197-2456},
	doi = {10.1016/s0197-2456(02)00242-8},
	abstract = {Minimization is a largely nonrandom method of treatment allocation for clinical trials. We conducted a systematic literature search to determine its advantages and disadvantages compared with other allocation methods. Minimization was originally proposed by Taves and by Pocock and Simon. The latter paper introduces a family of allocation methods of which Taves' method is the simplest example. Minimization aims to ensure treatment arms are balanced with respect to predefined patient factors as well as for the number of patients in each group. Further extensions of the method have also been proposed by other authors. Simulation studies show that minimization provides better balanced treatment groups when compared with restricted or unrestricted randomization and that it can incorporate more prognostic factors than stratified randomization methods such as permuted blocks within strata. Some more computationally complex methods may give an even better performance. Concerns over the use of minimization have centered on the fact that treatment assignments may be predicted with certainty in some situations and on the implications for the analysis methods used. It has been suggested that adjustment should always be made for minimization factors when analyzing trials where minimization is the allocation method used. The use of minimization may sometimes result in added organizational complexity compared with other methods. Minimization has been recommended by many commentators for use in clinical trials. Despite this it is still rarely used in practice. From the evidence presented in this review, we believe minimization to be a highly effective allocation method and recommend its wider adoption in the conduct of randomized controlled trials.},
	language = {eng},
	number = {6},
	journal = {Controlled Clinical Trials},
	author = {Scott, Neil W. and McPherson, Gladys C. and Ramsay, Craig R. and Campbell, Marion K.},
	month = dec,
	year = {2002},
	pmid = {12505244},
	keywords = {Clinical Trials as Topic, Humans, Random Allocation, Research Design},
	pages = {662--674},
}

@article{holman2015,
	title = {Evidence of {Experimental} {Bias} in the {Life} {Sciences}: {Why} {We} {Need} {Blind} {Data} {Recording}},
	volume = {13},
	issn = {1545-7885},
	shorttitle = {Evidence of {Experimental} {Bias} in the {Life} {Sciences}},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002190},
	doi = {10.1371/journal.pbio.1002190},
	abstract = {Observer bias and other “experimenter effects” occur when researchers’ expectations influence study outcome. These biases are strongest when researchers expect a particular result, are measuring subjective variables, and have an incentive to produce data that confirm predictions. To minimize bias, it is good practice to work “blind,” meaning that experimenters are unaware of the identity or treatment group of their subjects while conducting research. Here, using text mining and a literature review, we find evidence that blind protocols are uncommon in the life sciences and that nonblind studies tend to report higher effect sizes and more significant p-values. We discuss methods to minimize bias and urge researchers, editors, and peer reviewers to keep blind protocols in mind.},
	language = {en},
	number = {7},
	urldate = {2021-07-27},
	journal = {PLOS Biology},
	author = {Holman, Luke and Head, Megan L. and Lanfear, Robert and Jennions, Michael D.},
	month = jul,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Body weight, Clinical trials, Evolutionary biology, Medical journals, Medicine and health sciences, Metaanalysis, Statistical data, Text mining},
	pages = {e1002190},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/BRHN28X2/Holman et al. - 2015 - Evidence of Experimental Bias in the Life Sciences.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/7PSM5MPA/article.html:text/html},
}

@article{rosenthal1963,
	title = {The effect of experimenter bias on the performance of the albino rat},
	volume = {8},
	issn = {00057940, 10991743},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bs.3830080302},
	doi = {10.1002/bs.3830080302},
	language = {en},
	number = {3},
	urldate = {2021-07-27},
	journal = {Behavioral Science},
	author = {Rosenthal, Robert and Fode, Kermit L.},
	year = {1963},
	pages = {183--189},
	file = {Rosenthal and Fode - 2007 - The effect of experimenter bias on the performance.pdf:/Users/dorothybishop/Zotero/storage/TNLR2ETH/Rosenthal and Fode - 2007 - The effect of experimenter bias on the performance.pdf:application/pdf},
}

@article{duff2015,
	title = {Validity and sensitivity of the phonics screening check: implications for practice},
	volume = {38},
	issn = {1467-9817},
	shorttitle = {Validity and sensitivity of the phonics screening check},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9817.12029},
	doi = {10.1111/1467-9817.12029},
	abstract = {Background Introduced in June 2012, the phonics screening check aims to assess whether 6-year-old children are meeting an appropriate standard in phonic decoding and to identify children struggling with phonic skills. Aims We investigated whether the check is a valid measure of phonic skill and is sensitive in identifying children at risk of reading difficulties. Sample We obtained teacher assessments of phonic skills for 292 six-year-old children and additional psychometric data for 160 of these children. Methods Teacher assessment data were accessed from schools via the local authority; psychometric tests were administered by researchers shortly after the phonics screening check. Results The check was strongly correlated with other literacy skills and was sensitive in identifying at-risk readers. So too were teacher judgements of phonics. Conclusions Although the check fulfils its aims, we argue that resources might be better focused on training and supporting teachers in their ongoing monitoring of phonics.},
	language = {en},
	number = {2},
	urldate = {2021-07-27},
	journal = {Journal of Research in Reading},
	author = {Duff, Fiona J. and Mengoni, Silvana E. and Bailey, Alison M. and Snowling, Margaret J.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9817.12029},
	pages = {109--123},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/CHMZAGWY/Duff et al. - 2015 - Validity and sensitivity of the phonics screening .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/BL3K9R4K/1467-9817.html:text/html},
}

@article{henrich2010,
	title = {Most people are not {WEIRD}},
	volume = {466},
	copyright = {2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/466029a},
	doi = {10.1038/466029a},
	abstract = {To understand human psychology, behavioural scientists must stop doing most of their experiments on Westerners, argue Joseph Henrich, Steven J. Heine and Ara Norenzayan.},
	language = {en},
	number = {7302},
	urldate = {2021-07-27},
	journal = {Nature},
	author = {Henrich, Joseph and Heine, Steven J. and Norenzayan, Ara},
	month = jul,
	year = {2010},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 7302
Primary\_atype: Comments \& Opinion
Publisher: Nature Publishing Group
Subject\_term: Psychology and behaviour;Scientific community
Subject\_term\_id: psychology-and-behaviour;scientific-community},
	pages = {29--29},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/T4625YL3/Henrich et al. - 2010 - Most people are not WEIRD.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/NFAT4AQK/466029a.html:text/html},
}

@misc{zotero-1164,
	title = {https://academic.oup.com/psychsocgerontology/article/75/1/45/5033832 - {Google} {Search}},
	url = {https://www.google.com/search?q=https%3A%2F%2Facademic.oup.com%2Fpsychsocgerontology%2Farticle%2F75%2F1%2F45%2F5033832&client=firefox-b-d&ei=z7cDYcvcMcrS1fAP7N29qAw&oq=https%3A%2F%2Facademic.oup.com%2Fpsychsocgerontology%2Farticle%2F75%2F1%2F45%2F5033832&gs_lcp=Cgdnd3Mtd2l6EAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsANKBAhBGABQmfYRWJn2EWD4gBJoAXACeACAATSIATSSAQExmAEAoAECoAEByAEIwAEB&sclient=gws-wiz&ved=0ahUKEwiLgPvbr4ryAhVKaRUIHexuD8UQ4dUDCA4&uact=5},
	urldate = {2021-07-30},
	file = {https\://academic.oup.com/psychsocgerontology/article/75/1/45/5033832 - Google Search:/Users/dorothybishop/Zotero/storage/GFDT9EN3/search.html:text/html},
}

@techreport{lakens2021,
	title = {Sample {Size} {Justification}},
	url = {https://psyarxiv.com/9d3yf/},
	abstract = {An important step when designing a study is to justify the sample size that will be collected. The key aim of a sample size justification is to explain how the collected data is expected to provide valuable information given the inferential goals of the researcher. In this overview article six approaches are discussed to justify the sample size in a quantitative empirical study: 1) collecting data from (an)almost) the entire population, 2) choosing a sample size based on resource constraints, 3) performing an a-priori power analysis, 4) planning for a desired accuracy, 5) using heuristics, or 6) explicitly acknowledging the absence of a justification. An important question to consider when justifying sample sizes is which effect sizes are deemed interesting, and the extent to which the data that is collected informs inferences about these effect sizes. Depending on the sample size justification chosen, researchers could consider 1) what the smallest effect size of interest is, 2) which minimal effect size will be statistically significant, 3) which effect sizes they expect (and what they base these expectations on), 4) which effect sizes would be rejected based on a confidence interval around the effect size, 5) which ranges of effects a study has sufficient power to detect based on a sensitivity power analysis, and 6) which effect sizes are plausible in a specific research area. Researchers can use the guidelines presented in this article to improve their sample size justification, and hopefully, align the informational value of a study with their inferential goals.},
	urldate = {2021-07-30},
	institution = {PsyArXiv},
	author = {Lakens, Daniel},
	month = jan,
	year = {2021},
	doi = {10.31234/osf.io/9d3yf},
	note = {type: article},
	keywords = {Experimental Design and Sample Surveys, power analysis, Quantitative Methods, sample size justification, Social and Behavioral Sciences, study design, value of information},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/6T93MGWI/Lakens - 2021 - Sample Size Justification.pdf:application/pdf},
}

@article{lakens2018,
	title = {Justify your alpha},
	volume = {2},
	copyright = {2018 The Publisher},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-018-0311-x},
	doi = {10.1038/s41562-018-0311-x},
	abstract = {In response to recommendations to redefine statistical significance to P ≤ 0.005, we propose that researchers should transparently report and justify all choices they make when designing a study, including the alpha level.},
	language = {en},
	number = {3},
	urldate = {2021-07-30},
	journal = {Nature Human Behaviour},
	author = {Lakens, Daniel and Adolfi, Federico G. and Albers, Casper J. and Anvari, Farid and Apps, Matthew A. J. and Argamon, Shlomo E. and Baguley, Thom and Becker, Raymond B. and Benning, Stephen D. and Bradford, Daniel E. and Buchanan, Erin M. and Caldwell, Aaron R. and Van Calster, Ben and Carlsson, Rickard and Chen, Sau-Chin and Chung, Bryan and Colling, Lincoln J. and Collins, Gary S. and Crook, Zander and Cross, Emily S. and Daniels, Sameera and Danielsson, Henrik and DeBruine, Lisa and Dunleavy, Daniel J. and Earp, Brian D. and Feist, Michele I. and Ferrell, Jason D. and Field, James G. and Fox, Nicholas W. and Friesen, Amanda and Gomes, Caio and Gonzalez-Marquez, Monica and Grange, James A. and Grieve, Andrew P. and Guggenberger, Robert and Grist, James and van Harmelen, Anne-Laura and Hasselman, Fred and Hochard, Kevin D. and Hoffarth, Mark R. and Holmes, Nicholas P. and Ingre, Michael and Isager, Peder M. and Isotalus, Hanna K. and Johansson, Christer and Juszczyk, Konrad and Kenny, David A. and Khalil, Ahmed A. and Konat, Barbara and Lao, Junpeng and Larsen, Erik Gahner and Lodder, Gerine M. A. and Lukavský, Jiří and Madan, Christopher R. and Manheim, David and Martin, Stephen R. and Martin, Andrea E. and Mayo, Deborah G. and McCarthy, Randy J. and McConway, Kevin and McFarland, Colin and Nio, Amanda Q. X. and Nilsonne, Gustav and de Oliveira, Cilene Lino and de Xivry, Jean-Jacques Orban and Parsons, Sam and Pfuhl, Gerit and Quinn, Kimberly A. and Sakon, John J. and Saribay, S. Adil and Schneider, Iris K. and Selvaraju, Manojkumar and Sjoerds, Zsuzsika and Smith, Samuel G. and Smits, Tim and Spies, Jeffrey R. and Sreekumar, Vishnu and Steltenpohl, Crystal N. and Stenhouse, Neil and Świątkowski, Wojciech and Vadillo, Miguel A. and Van Assen, Marcel A. L. M. and Williams, Matt N. and Williams, Samantha E. and Williams, Donald R. and Yarkoni, Tal and Ziano, Ignazio and Zwaan, Rolf A.},
	month = mar,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 3
Primary\_atype: Comments \& Opinion
Publisher: Nature Publishing Group
Subject\_term: Human behaviour;Statistics
Subject\_term\_id: human-behaviour;statistics},
	pages = {168--171},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/BXBZEA62/Lakens et al. - 2018 - Justify your alpha.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/AMY3LWTK/s41562-018-0311-x.html:text/html},
}

@article{benjamin2018,
	title = {Redefine statistical significance},
	volume = {2},
	copyright = {2017 The Author(s)},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-017-0189-z},
	doi = {10.1038/s41562-017-0189-z},
	abstract = {We propose to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries.},
	language = {en},
	number = {1},
	urldate = {2021-07-30},
	journal = {Nature Human Behaviour},
	author = {Benjamin, Daniel J. and Berger, James O. and Johannesson, Magnus and Nosek, Brian A. and Wagenmakers, E.-J. and Berk, Richard and Bollen, Kenneth A. and Brembs, Björn and Brown, Lawrence and Camerer, Colin and Cesarini, David and Chambers, Christopher D. and Clyde, Merlise and Cook, Thomas D. and De Boeck, Paul and Dienes, Zoltan and Dreber, Anna and Easwaran, Kenny and Efferson, Charles and Fehr, Ernst and Fidler, Fiona and Field, Andy P. and Forster, Malcolm and George, Edward I. and Gonzalez, Richard and Goodman, Steven and Green, Edwin and Green, Donald P. and Greenwald, Anthony G. and Hadfield, Jarrod D. and Hedges, Larry V. and Held, Leonhard and Hua Ho, Teck and Hoijtink, Herbert and Hruschka, Daniel J. and Imai, Kosuke and Imbens, Guido and Ioannidis, John P. A. and Jeon, Minjeong and Jones, James Holland and Kirchler, Michael and Laibson, David and List, John and Little, Roderick and Lupia, Arthur and Machery, Edouard and Maxwell, Scott E. and McCarthy, Michael and Moore, Don A. and Morgan, Stephen L. and Munafó, Marcus and Nakagawa, Shinichi and Nyhan, Brendan and Parker, Timothy H. and Pericchi, Luis and Perugini, Marco and Rouder, Jeff and Rousseau, Judith and Savalei, Victoria and Schönbrodt, Felix D. and Sellke, Thomas and Sinclair, Betsy and Tingley, Dustin and Van Zandt, Trisha and Vazire, Simine and Watts, Duncan J. and Winship, Christopher and Wolpert, Robert L. and Xie, Yu and Young, Cristobal and Zinman, Jonathan and Johnson, Valen E.},
	month = jan,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Comments \& Opinion
Publisher: Nature Publishing Group
Subject\_term: Human behaviour;Statistics
Subject\_term\_id: human-behaviour;statistics},
	pages = {6--10},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/R9T3UD4I/Benjamin et al. - 2018 - Redefine statistical significance.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/I54JVUF3/s41562-017-0189-z.html:text/html},
}

@article{kerr1998,
	title = {{HARKing}: hypothesizing after the results are known},
	volume = {2},
	issn = {1088-8683},
	shorttitle = {{HARKing}},
	doi = {10.1207/s15327957pspr0203_4},
	abstract = {This article considers a practice in scientific communication termed HARKing (Hypothesizing After the Results are Known). HARKing is defined as presenting a post hoc hypothesis (i.e., one based on or informed by one's results) in one's research report as i f it were, in fact, an a priori hypotheses. Several forms of HARKing are identified and survey data are presented that suggests that at least some forms of HARKing are widely practiced and widely seen as inappropriate. I identify several reasons why scientists might HARK. Then I discuss several reasons why scientists ought not to HARK. It is conceded that the question of whether HARKing ' s costs exceed its benefits is a complex one that ought to be addressed through research, open discussion, and debate. To help stimulate such discussion (and for those such as myself who suspect that HARKing's costs do exceed its benefits), I conclude the article with some suggestions for deterring HARKing.},
	language = {eng},
	number = {3},
	journal = {Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc},
	author = {Kerr, N. L.},
	year = {1998},
	pmid = {15647155},
	pages = {196--217},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/HNUJNUMK/Kerr - 1998 - HARKing hypothesizing after the results are known.pdf:application/pdf},
}

@incollection{bem2004,
	address = {Washington, DC, US},
	title = {Writing the empirical journal article},
	isbn = {978-1-59147-035-9},
	abstract = {The purpose of this chapter is to enhance the chances that academic psychologists get their empirical articles published. Because I write, review, and edit primarily for journals in personality and social psychology, I have drawn most of my examples from those areas. Colleagues assure me, however, that the guidelines set forth are also pertinent for articles in experimental psychology and biopsychology. Similarly, this chapter focuses on an empirical study, but the general writing suggestions apply as well to the theoretical articles, literature reviews, and methodological contributions that also appear in psychology journals. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	booktitle = {The compleat academic: {A} career guide, 2nd ed},
	publisher = {American Psychological Association},
	author = {Bem, Daryl J.},
	year = {2004},
	keywords = {Experimental Psychology, Scientific Communication, Written Communication},
	pages = {185--219},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/YJ67QKBB/2003-06256-010.html:text/html},
}

@article{steegen2016,
	title = {Increasing {Transparency} {Through} a {Multiverse} {Analysis}},
	volume = {11},
	issn = {1745-6924},
	doi = {10.1177/1745691616658637},
	abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves choices among several reasonable options for excluding, transforming, and coding data. We suggest that instead of performing only one analysis, researchers could perform a multiverse analysis, which involves performing all analyses across the whole set of alternatively processed data sets corresponding to a large set of reasonable scenarios. Using an example focusing on the effect of fertility on religiosity and political attitudes, we show that analyzing a single data set can be misleading and propose a multiverse analysis as an alternative practice. A multiverse analysis offers an idea of how much the conclusions change because of arbitrary choices in data construction and gives pointers as to which choices are most consequential in the fragility of the result.},
	language = {eng},
	number = {5},
	journal = {Perspectives on Psychological Science: A Journal of the Association for Psychological Science},
	author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
	month = sep,
	year = {2016},
	pmid = {27694465},
	keywords = {arbitrary choices, Attitude, Choice Behavior, Data Interpretation, Statistical, data processing, Female, Fertility, good research practices, Humans, Information Management, Marital Status, multiverse analysis, Politics, Religion, Research Design, selective reporting, transparency},
	pages = {702--712},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/T5ZF74B6/Steegen et al. - 2016 - Increasing Transparency Through a Multiverse Analy.pdf:application/pdf},
}

@article{vorland2021,
	title = {Errors in the implementation, analysis, and reporting of randomization within obesity and nutrition research: a guide to their avoidance},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-5497},
	shorttitle = {Errors in the implementation, analysis, and reporting of randomization within obesity and nutrition research},
	url = {https://www.nature.com/articles/s41366-021-00909-z},
	doi = {10.1038/s41366-021-00909-z},
	abstract = {Randomization is an important tool used to establish causal inferences in studies designed to further our understanding of questions related to obesity and nutrition. To take advantage of the inferences afforded by randomization, scientific standards must be upheld during the planning, execution, analysis, and reporting of such studies. We discuss ten errors in randomized experiments from real-world examples from the literature and outline best practices for their avoidance. These ten errors include: representing nonrandom allocation as random, failing to adequately conceal allocation, not accounting for changing allocation ratios, replacing subjects in nonrandom ways, failing to account for non-independence, drawing inferences by comparing statistical significance from within-group comparisons instead of between-groups, pooling data and breaking the randomized design, failing to account for missing data, failing to report sufficient information to understand study methods, and failing to frame the causal question as testing the randomized assignment per se. We hope that these examples will aid researchers, reviewers, journal editors, and other readers to endeavor to a high standard of scientific rigor in randomized experiments within obesity and nutrition research.},
	language = {en},
	urldate = {2021-07-30},
	journal = {International Journal of Obesity},
	author = {Vorland, Colby J. and Brown, Andrew W. and Dawson, John A. and Dickinson, Stephanie L. and Golzarri-Arroyo, Lilian and Hannon, Bridget A. and Heo, Moonseong and Heymsfield, Steven B. and Jayawardene, Wasantha P. and Kahathuduwa, Chanaka N. and Keith, Scott W. and Oakes, J. Michael and Tekwe, Carmen D. and Thabane, Lehana and Allison, David B.},
	month = jul,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Diseases;Nutrition disorders
Subject\_term\_id: diseases;nutrition-disorders},
	pages = {1--12},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/XMT44WSJ/Vorland et al. - 2021 - Errors in the implementation, analysis, and report.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/TDK3M92G/s41366-021-00909-z.html:text/html},
}

@article{moher2010,
	title = {{CONSORT} 2010 explanation and elaboration: updated guidelines for reporting parallel group randomised trials},
	volume = {340},
	issn = {1756-1833},
	shorttitle = {{CONSORT} 2010 explanation and elaboration},
	doi = {10.1136/bmj.c869},
	language = {eng},
	journal = {BMJ (Clinical research ed.)},
	author = {Moher, David and Hopewell, Sally and Schulz, Kenneth F. and Montori, Victor and Gøtzsche, Peter C. and Devereaux, P. J. and Elbourne, Diana and Egger, Matthias and Altman, Douglas G.},
	month = mar,
	year = {2010},
	pmid = {20332511},
	pmcid = {PMC2844943},
	keywords = {Consensus, Practice Guidelines as Topic, Randomized Controlled Trials as Topic, Research Design},
	pages = {c869},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/G2GQ8TCK/Moher et al. - 2010 - CONSORT 2010 explanation and elaboration updated .pdf:application/pdf},
}

@book{campbell2014,
	address = {Chichester},
	title = {How to design, analyse and report cluster randomised trials in medicine and health related research.},
	publisher = {Wiley},
	author = {Campbell, MJ and Walters, SJ},
	year = {2014},
}

@article{araujo2016,
	title = {Understanding {Variation} in {Sets} of {N}-of-1 {Trials}},
	volume = {11},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167167},
	doi = {10.1371/journal.pone.0167167},
	abstract = {A recent paper in this journal by Chen and Chen has used computer simulations to examine a number of approaches to analysing sets of n-of-1 trials. We have examined such designs using a more theoretical approach based on considering the purpose of analysis and the structure as regards randomisation that the design uses. We show that different purposes require different analyses and that these in turn may produce quite different results. Our approach to incorporating the randomisation employed when the purpose is to test a null hypothesis of strict equality of the treatment makes use of Nelder’s theory of general balance. However, where the purpose is to make inferences about the effects for individual patients, we show that a mixed model is needed. There are strong parallels to the difference between fixed and random effects meta-analyses and these are discussed.},
	language = {en},
	number = {12},
	urldate = {2021-07-31},
	journal = {PLOS ONE},
	author = {Araujo, Artur and Julious, Steven and Senn, Stephen},
	month = dec,
	year = {2016},
	note = {Publisher: Public Library of Science},
	keywords = {ACE inhibitor therapy, Analysis of variance, Balance and falls, Beta-adrenergic antagonist therapy, Experimental design, Metaanalysis, Nicotine replacement therapy, Simulation and modeling},
	pages = {e0167167},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/N6MU7E4M/Araujo et al. - 2016 - Understanding Variation in Sets of N-of-1 Trials.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/DGZTTMC2/article.html:text/html},
}

@article{duan2013,
	title = {Single-patient (n-of-1) trials: a pragmatic clinical decision methodology for patient-centered comparative effectiveness research},
	volume = {66},
	issn = {1878-5921},
	shorttitle = {Single-patient (n-of-1) trials},
	doi = {10.1016/j.jclinepi.2013.04.006},
	abstract = {OBJECTIVE: To raise awareness among clinicians and epidemiologists that single-patient (n-of-1) trials are potentially useful for informing personalized treatment decisions for patients with chronic conditions.
STUDY DESIGN AND SETTING: We reviewed the clinical and statistical literature on methods and applications of single-patient trials and then critically evaluated the needs for further methodological developments.
RESULTS: Existing literature reports application of 2,154 single-patient trials in 108 studies for diverse clinical conditions; various recent commentaries advocate for wider application of such trials in clinical decision making. Preliminary evidence from several recent pilot acceptability studies suggests that single-patient trials have the potential for widespread acceptance by patients and clinicians as an effective modality for increasing the therapeutic precision. Bayesian and adaptive statistical methods hold promise for increasing the informational yield of single-patient trials while reducing participant burden, but are not widely used. Personalized applications of single-patient trials can be enhanced through further development and application of methodologies on adaptive trial design, stopping rules, network meta-analysis, washout methods, and methods for communicating trial findings to patients and clinicians.
CONCLUSIONS: Single-patient trials may be poised to emerge as an important part of the methodological armamentarium for comparative effectiveness research and patient-centered outcomes research. By permitting direct estimation of individual treatment effects, they can facilitate finely graded individualized care, enhance therapeutic precision, improve patient outcomes, and reduce costs.},
	language = {eng},
	number = {8 Suppl},
	journal = {Journal of Clinical Epidemiology},
	author = {Duan, Naihua and Kravitz, Richard L. and Schmid, Christopher H.},
	month = aug,
	year = {2013},
	pmid = {23849149},
	pmcid = {PMC3972259},
	keywords = {Adaptive trial, Bayes Theorem, Bayesian method, Borrow from strength, Carryover effect, Chronic Disease, Comparative Effectiveness Research, Cross-Over Studies, Crossover trial, Decision Support Techniques, Evidence-Based Medicine, Humans, Outcome Assessment, Health Care, Patient Participation, Patient Selection, Pilot Projects, Randomized Controlled Trials as Topic, Sequential trial, Washout},
	pages = {S21--28},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/DBQBAGBV/Duan et al. - 2013 - Single-patient (n-of-1) trials a pragmatic clinic.pdf:application/pdf},
}

@article{goldacre2019,
	title = {{COMPare}: a prospective cohort study correcting and monitoring 58 misreported trials in real time},
	volume = {20},
	issn = {1745-6215},
	shorttitle = {{COMPare}},
	url = {https://doi.org/10.1186/s13063-019-3173-2},
	doi = {10.1186/s13063-019-3173-2},
	abstract = {Discrepancies between pre-specified and reported outcomes are an important source of bias in trials. Despite legislation, guidelines and public commitments on correct reporting from journals, outcome misreporting continues to be prevalent. We aimed to document the extent of misreporting, establish whether it was possible to publish correction letters on all misreported trials as they were published, and monitor responses from editors and trialists to understand why outcome misreporting persists despite public commitments to address it.},
	number = {1},
	urldate = {2021-07-31},
	journal = {Trials},
	author = {Goldacre, Ben and Drysdale, Henry and Dale, Aaron and Milosevic, Ioan and Slade, Eirion and Hartley, Philip and Marston, Cicely and Powell-Smith, Anna and Heneghan, Carl and Mahtani, Kamal R.},
	month = feb,
	year = {2019},
	keywords = {Audit, CONSORT, Editorial conduct, ICMJE, Misreporting, Outcomes, Trials},
	pages = {118},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/8HZGQN2U/Goldacre et al. - 2019 - COMPare a prospective cohort study correcting and.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/PN7SUD5E/s13063-019-3173-2.html:text/html},
}

@article{bishop2017,
	title = {Phase 2 of {CATALISE}: a multinational and multidisciplinary {Delphi} consensus study of problems with language development: {Terminology}},
	volume = {58},
	issn = {1469-7610},
	shorttitle = {Phase 2 of {CATALISE}},
	url = {https://acamh.onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.12721},
	doi = {10.1111/jcpp.12721},
	abstract = {Background Lack of agreement about criteria and terminology for children's language problems affects access to services as well as hindering research and practice. We report the second phase of a study using an online Delphi method to address these issues. In the first phase, we focused on criteria for language disorder. Here we consider terminology. Methods The Delphi method is an iterative process in which an initial set of statements is rated by a panel of experts, who then have the opportunity to view anonymised ratings from other panel members. On this basis they can either revise their views or make a case for their position. The statements are then revised based on panel feedback, and again rated by and commented on by the panel. In this study, feedback from a second round was used to prepare a final set of statements in narrative form. The panel included 57 individuals representing a range of professions and nationalities. Results We achieved at least 78\% agreement for 19 of 21 statements within two rounds of ratings. These were collapsed into 12 statements for the final consensus reported here. The term ‘Language Disorder’ is recommended to refer to a profile of difficulties that causes functional impairment in everyday life and is associated with poor prognosis. The term, ‘Developmental Language Disorder’ (DLD) was endorsed for use when the language disorder was not associated with a known biomedical aetiology. It was also agreed that (a) presence of risk factors (neurobiological or environmental) does not preclude a diagnosis of DLD, (b) DLD can co-occur with other neurodevelopmental disorders (e.g. ADHD) and (c) DLD does not require a mismatch between verbal and nonverbal ability. Conclusions This Delphi exercise highlights reasons for disagreements about terminology for language disorders and proposes standard definitions and nomenclature.},
	language = {en},
	number = {10},
	urldate = {2021-07-31},
	journal = {Journal of Child Psychology and Psychiatry},
	author = {Bishop, Dorothy V. M. and Snowling, Margaret J. and Thompson, Paul A. and Greenhalgh, Trisha},
	year = {2017},
	note = {\_eprint: https://acamh.onlinelibrary.wiley.com/doi/pdf/10.1111/jcpp.12721},
	keywords = {definitions, Developmental language disorder, risk factors, specific language impairment, terminology},
	pages = {1068--1080},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/FLVTG6D6/Bishop et al. - 2017 - Phase 2 of CATALISE a multinational and multidisc.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/EIH5AIJ7/jcpp.html:text/html},
}

@article{tate2016,
	title = {The {Single}-{Case} {Reporting} {Guideline} {In} {BEhavioural} {Interventions} ({SCRIBE}) 2016 {Statement}},
	volume = {96},
	issn = {1538-6724},
	doi = {10.2522/ptj.2016.96.7.e1},
	abstract = {We developed a reporting guideline to provide authors with guidance about what should be reported when writing a paper for publication in a scientific journal using a particular type of research design: the single-case experimental design. This report describes the methods used to develop the Single-Case Reporting guideline In BEhavioural interventions (SCRIBE) 2016. As a result of 2 online surveys and a 2-day meeting of experts, the SCRIBE 2016 checklist was developed, which is a set of 26 items that authors need to address when writing about single-case research. This article complements the more detailed SCRIBE 2016 Explanation and Elaboration article (Tate et al., 2016) that provides a rationale for each of the items and examples of adequate reporting from the literature. Both these resources will assist authors to prepare reports of single-case research with clarity, completeness, accuracy, and transparency. They will also provide journal reviewers and editors with a practical checklist against which such reports may be critically evaluated. We recommend that the SCRIBE 2016 is used by authors preparing manuscripts describing single-case research for publication, as well as journal reviewers and editors who are evaluating such manuscripts.
SCIENTIFIC ABSTRACT: Reporting guidelines, such as the Consolidated Standards of Reporting Trials (CONSORT) Statement, improve the reporting of research in the medical literature (Turner et al., 2012). Many such guidelines exist and the CONSORT Extension to Nonpharmacological Trials (Boutron et al., 2008) provides suitable guidance for reporting between-groups intervention studies in the behavioral sciences. The CONSORT Extension for N-of-1 Trials (CENT 2015) was developed for multiple crossover trials with single individuals in the medical sciences (Shamseer et al., 2015; Vohra et al., 2015), but there is no reporting guideline in the CONSORT tradition for single-case research used in the behavioral sciences. We developed the Single-Case Reporting guideline In BEhavioural interventions (SCRIBE) 2016 to meet this need. This Statement article describes the methodology of the development of the SCRIBE 2016, along with the outcome of 2 Delphi surveys and a consensus meeting of experts. We present the resulting 26-item SCRIBE 2016 checklist. The article complements the more detailed SCRIBE 2016 Explanation and Elaboration article (Tate et al., 2016) that provides a rationale for each of the items and examples of adequate reporting from the literature. Both these resources will assist authors to prepare reports of single-case research with clarity, completeness, accuracy, and transparency. They will also provide journal reviewers and editors with a practical checklist against which such reports may be critically evaluated.},
	language = {eng},
	number = {7},
	journal = {Physical Therapy},
	author = {Tate, Robyn L. and Perdices, Michael and Rosenkoetter, Ulrike and Shadish, William and Vohra, Sunita and Barlow, David H. and Horner, Robert and Kazdin, Alan and Kratochwill, Thomas and McDonald, Skye and Sampson, Margaret and Shamseer, Larissa and Togher, Leanne and Albin, Richard and Backman, Catherine and Douglas, Jacinta and Evans, Jonathan J. and Gast, David and Manolov, Rumen and Mitchell, Geoffrey and Nickels, Lyndsey and Nikles, Jane and Ownsworth, Tamara and Rose, Miranda and Schmid, Christopher H. and Wilson, Barbara},
	month = jul,
	year = {2016},
	pmid = {27371692},
	keywords = {Behavior Therapy, Checklist, Delphi Technique, Guidelines as Topic, Humans, methodology, Peer Review, Research, publication standardsSupplemental materials: http://dx.doi.org/10.1037/arc0000026.supp., reporting guidelines, Research Design, Research Report, single-case design},
	pages = {e1--e10},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/4ZSVV4LM/Tate et al. - 2016 - The Single-Case Reporting Guideline In BEhavioural.pdf:application/pdf},
}

@article{perdices2009,
	title = {Single-subject designs as a tool for evidence-based clinical practice: {Are} they unrecognised and undervalued?},
	volume = {19},
	issn = {0960-2011},
	shorttitle = {Single-subject designs as a tool for evidence-based clinical practice},
	url = {https://doi.org/10.1080/09602010903040691},
	doi = {10.1080/09602010903040691},
	abstract = {One could be forgiven for thinking that the only road to evidence-based clinical practice is the application of results from randomised controlled trials (or systematic reviews of such). By contrast, single-subject designs in the context of evidence-based clinical practice are believed by many to be strange bedfellows. In this paper, we argue that single-subject designs play an important role in evidence-based clinical practice. We survey the contents of Neuropsychological Rehabilitation in relation to single-subject designs and tackle the main criticisms that have been levelled against them. We offer practical guidance for rating the methodological quality of single-subject designs and applying statistical techniques to measure treatment efficacy. These guides are equally applicable to research studies and everyday clinical practice with individual patients.},
	number = {6},
	urldate = {2021-08-01},
	journal = {Neuropsychological Rehabilitation},
	author = {Perdices, Michael and Tate, Robyn L.},
	month = dec,
	year = {2009},
	pmid = {19657974},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09602010903040691},
	keywords = {Corrigendum, Methodology, N-of-1 trials, Single-case experimental designs},
	pages = {904--927},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/7HWKAVGX/Perdices and Tate - 2009 - Single-subject designs as a tool for evidence-base.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/9NYTR32I/09602010903040691.html:text/html},
}

@article{ingham1981,
	title = {Some effects of the {Edinburgh} {Masker} on stuttering during oral reading and spontaneous speech},
	volume = {6},
	issn = {0094-730X},
	url = {https://www.sciencedirect.com/science/article/pii/0094730X81900115},
	doi = {10.1016/0094-730X(81)90011-5},
	abstract = {This study assessed the effect of a voice-activated masking unit, known as the Edinburgh Masker, on the speech of four stutterers during oral reading and spontaneous speech. The results show that one stutterer reduced stuttering almost completely whenever the masker was activated. Two subjects showed either marginal or temporary reductions of stuttering during one speaking condition but showed no change in the other condition. The other subject reduced stuttering only during spontaneous speech. No reduction in stuttering was associated with reduced speech rate. A perceptual analysis procedure conducted to assess for altered speech quality during masking conditions found changes in speech quality were evident in two subjects. The clinical implications of these findings are discussed.},
	language = {en},
	number = {2},
	urldate = {2021-08-01},
	journal = {Journal of Fluency Disorders},
	author = {Ingham, Roger J. and Southwood, Helen and Horsburgh, Gay},
	month = jun,
	year = {1981},
	pages = {135--154},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/Y2EXW5NP/Ingham et al. - 1981 - Some effects of the Edinburgh Masker on stuttering.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/5QWG7ZQ6/0094730X81900115.html:text/html},
}

@article{block1996,
	title = {The {Effects} of the {Edinburgh} {Masker} on {Stuttering}},
	volume = {24},
	issn = {0310-6853},
	url = {https://doi.org/10.3109/asl2.1996.24.issue-1.02},
	doi = {10.3109/asl2.1996.24.issue-1.02},
	abstract = {Auditory feedback masking has long been thought to be a clinically useful procedure for the modification of stuttered speech in adults, and the Edinburgh Masker is a commercial device for providing such masking. In the present study, 18 subjects spoke under various masking and nonmasking conditions using the Edinburgh Masker, both in and beyond the clinic. Results showed that stuttering rate reduced by a mean of around 50\% in masking compared to nonmasking conditions. Only one subject completely eliminated stuttering, and did so in only one of many speaking tasks. Listeners judged masked speech to be less natural sounding than nonmasked speech. It is concluded that, for some clients, there may be some benefit in masked speech by means of the Edinburgh Masker, but that the device does not appear to produce either stutter-free or natural sounding speech.},
	number = {1},
	urldate = {2021-08-01},
	journal = {Australian Journal of Human Communication Disorders},
	author = {Block, Susan and Ingham, Roger J. and Bench, R. John},
	month = jun,
	year = {1996},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.3109/asl2.1996.24.issue-1.02},
	pages = {11--18},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/4NNIB7DI/asl2.1996.24.issue-1.html:text/html},
}

@article{furukawa2014,
	title = {Waiting list may be a nocebo condition in psychotherapy trials: a contribution from network meta-analysis},
	volume = {130},
	issn = {1600-0447},
	shorttitle = {Waiting list may be a nocebo condition in psychotherapy trials},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/acps.12275},
	doi = {10.1111/acps.12275},
	abstract = {Objective Various control conditions have been employed in psychotherapy trials, but there is growing suspicion that they may lead to different effect size estimates. The present study aims to examine the differences among control conditions including waiting list (WL), no treatment (NT) and psychological placebo (PP). Method We comprehensively searched for all randomized controlled trials (RCTs) comparing cognitive-behaviour therapies (CBT) against various control conditions in the acute phase treatment of depression, and applied network meta-analysis (NMA) to combine all direct and indirect comparisons among the treatment and control arms. Results We identified 49 RCTs (2730 participants) comparing WL, NT, PP and CBT. This network of evidence was consistent, and the effect size estimates for CBT were substantively different depending on the control condition. The odds ratio of response for NT over WL was statistically significant at 2.9 (95\% CI: 1.3–5.7). However, the quality of evidence, including publication bias, was less than ideal and none of the preplanned sensitivity analyses limiting to high-quality studies could be conducted, while findings of significant differences did not persist in post hoc sensitivity analyses trying to adjust for publication bias. Conclusion There may be important differences in control conditions currently used in psychotherapy trials.},
	language = {en},
	number = {3},
	urldate = {2021-08-01},
	journal = {Acta Psychiatrica Scandinavica},
	author = {Furukawa, T. A. and Noma, H. and Caldwell, D. M. and Honyashiki, M. and Shinohara, K. and Imai, H. and Chen, P. and Hunot, V. and Churchill, R.},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/acps.12275},
	keywords = {clinical trials, cognitive therapy, control groups, placebo, waiting lists},
	pages = {181--192},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/V243F79J/Furukawa et al. - 2014 - Waiting list may be a nocebo condition in psychoth.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/WFRB53XT/acps.html:text/html},
}

@article{cunningham2013,
	title = {Exploratory randomized controlled trial evaluating the impact of a waiting list control design},
	volume = {13},
	issn = {1471-2288},
	url = {https://doi.org/10.1186/1471-2288-13-150},
	doi = {10.1186/1471-2288-13-150},
	abstract = {Employing waiting list control designs in psychological and behavioral intervention research may artificially inflate intervention effect estimates. This exploratory randomized controlled trial tested this proposition in a study employing a brief intervention for problem drinkers, one domain of research in which waiting list control designs are used.},
	number = {1},
	urldate = {2021-08-01},
	journal = {BMC Medical Research Methodology},
	author = {Cunningham, John A. and Kypri, Kypros and McCambridge, Jim},
	month = dec,
	year = {2013},
	keywords = {Alcohol, Alternate explanation, Brief intervention, Randomized controlled trials, Research methods, Waiting list control design},
	pages = {150},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/3FUAKS46/Cunningham et al. - 2013 - Exploratory randomized controlled trial evaluating.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/MLRLSHHF/1471-2288-13-150.html:text/html},
}

@incollection{howard2003,
	title = {Chapter 16: {Single} {Cases}, {Group} {Studies} and {Case} {Series} in {Aphasia} {Therapy}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/B9780080440736500171?token=402044775314B107D8FAC186B5A72020B85191FCEE862FCF95B2C037B17634D20F97DB7AFB2A1723513D3FCC21D586D4&originRegion=eu-west-1&originCreation=20210801103239},
	language = {en},
	urldate = {2021-08-01},
	booktitle = {The {Sciences} of {Aphasia}: {From} {Theory} to {Therapy}. {Ilias} {Papathanasiou} and {Ria} {De} {Bleser} ({Eds}).},
	publisher = {Elsevier},
	author = {Howard, David},
	year = {2003},
	doi = {10.1016/B978-008044073-6/50017-1},
	pages = {245--258},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/JVPIJRV2/B9780080440736500171.html:text/html;PII B978-0-08-044073-6.50017-1  Elsevier Enhance.pdf:/Users/dorothybishop/Zotero/storage/MPJNHFHN/PII B978-0-08-044073-6.50017-1  Elsevier Enhance.pdf:application/pdf},
}

@article{krasny-pacini2018,
	title = {Single-case experimental designs to assess intervention effectiveness in rehabilitation: {A} practical guide},
	volume = {61},
	issn = {1877-0657},
	shorttitle = {Single-case experimental designs to assess intervention effectiveness in rehabilitation},
	url = {https://www.sciencedirect.com/science/article/pii/S1877065717304542},
	doi = {10.1016/j.rehab.2017.12.002},
	abstract = {Single-case experimental designs (SCED) are experimental designs aiming at testing the effect of an intervention using a small number of patients (typically one to three), using repeated measurements, sequential (±randomized) introduction of an intervention and method-specific data analysis, including visual analysis and specific statistics. The aim of this paper is to familiarise professionals working in different fields of rehabilitation with SCEDs and provide practical advice on how to design and implement a SCED in clinical rehabilitation practice. Research questions suitable for SCEDs and the different types of SCEDs (e.g., alternating treatment designs, introduction/withdrawal designs and multiple baseline designs) are reviewed. Practical steps in preparing a SCED design are outlined. Examples from different rehabilitation domains are provided throughout the paper. Challenging issues such as the choice of the repeated measure, assessment of generalisation, randomization, procedural fidelity, replication and generalizability of findings are discussed. Simple rules and resources for data analysis are presented. The utility of SCEDs in physical and rehabilitation medicine (PRM) are discussed.},
	language = {en},
	number = {3},
	urldate = {2021-08-01},
	journal = {Annals of Physical and Rehabilitation Medicine},
	author = {Krasny-Pacini, Agata and Evans, Jonathan},
	month = may,
	year = {2018},
	keywords = {Alternating treatment, Methodology, Multiple baseline, Rehabilitation, Single-case},
	pages = {164--179},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/GTXS9KFF/Krasny-Pacini and Evans - 2018 - Single-case experimental designs to assess interve.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/ISHQCBBA/S1877065717304542.html:text/html},
}

@misc{zotero-1230,
	title = {The history and development of {N} of 1 trials.},
	url = {https://www.jameslindlibrary.org/articles/history-development-n-1-trials/},
	abstract = {Introduction ‘Trials of therapy’, in which physicians ‘try out’ treatments and assess patients’ responses, are long-established, common elements of routine medical practice. Because ‘trials of therapy’ are usually informal, they ...},
	language = {en-GB},
	urldate = {2021-08-01},
	journal = {The James Lind Library},
	note = {Section: N-of-1 crossover},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/HJHDUY9H/history-development-n-1-trials.html:text/html},
}

@article{mirza2017,
	title = {The history and development of {N}-of-1 trials},
	volume = {110},
	issn = {0141-0768},
	url = {https://doi.org/10.1177/0141076817721131},
	doi = {10.1177/0141076817721131},
	language = {en},
	number = {8},
	urldate = {2021-08-01},
	journal = {Journal of the Royal Society of Medicine},
	author = {Mirza, RD and Punja, S and Vohra, S and Guyatt, G},
	month = aug,
	year = {2017},
	note = {Publisher: SAGE Publications},
	pages = {330--340},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/PAEEEBQM/Mirza et al. - 2017 - The history and development of N-of-1 trials.pdf:application/pdf},
}

@article{leniston2021,
	title = {Investigation into the effectiveness of electropalatography in treating persisting speech sound disorders in adolescents with co-occurring developmental language disorder},
	issn = {1464-5076},
	doi = {10.1080/02699206.2021.1957022},
	abstract = {This study aimed to assess the effectiveness of Electropalatography (EPG) intervention in targeting specific phonemes/words in seven adolescents aged 14:10-18:06 with co-occurring speech sound and language disorders. Progress on individualised targets versus controls was evaluated following intervention undertaken as part of the participants' usual speech and language therapy provision. As a group, the participants showed significantly greater progress on their targets than controls, indicating that the EPG intervention was effective. However, performance varied between participants, targets and school terms. Factors that may have influenced the effectiveness of intervention include spending more time on targets and focusing on a specific phoneme. Overall, the results suggest EPG should be considered as an intervention approach for this client group, even in the late teenage years.},
	language = {eng},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Leniston, Hannah and Ebbels, Susan},
	month = jul,
	year = {2021},
	pmid = {34325597},
	keywords = {developmental language disorder, Electropalatography, intervention, school-aged children, speech sound disorder},
	pages = {1--16},
	file = {Leniston and Ebbels - 2021 - Investigation into the effectiveness of electropal.pdf:/Users/dorothybishop/Zotero/storage/C4V4PQDC/Leniston and Ebbels - 2021 - Investigation into the effectiveness of electropal.pdf:application/pdf},
}

@article{rothwell2005,
	title = {External validity of randomised controlled trials: “{To} whom do the results of this trial apply?”},
	volume = {365},
	issn = {0140-6736},
	shorttitle = {External validity of randomised controlled trials},
	url = {https://www.sciencedirect.com/science/article/pii/S0140673604176708},
	doi = {10.1016/S0140-6736(04)17670-8},
	abstract = {In making treatment decisions, doctors and patients must take into account relevant randomised controlled trials (RCTs) and systematic reviews. Relevance depends on external validity (or generalisability)—ie, whether the results can be reasonably applied to a definable group of patients in a particular clinical setting in routine practice. There is concern among clinicians that external validity is often poor, particularly for some pharmaceutical industry trials, a perception that has led to underuse of treatments that are effective. Yet researchers, funding agencies, ethics committees, the pharmaceutical industry, medical journals, and governmental regulators alike all neglect external validity, leaving clinicians to make judgments. However, reporting of the determinants of external validity in trial publications and systematic reviews is usually inadequate. This review discusses those determinants, presents a checklist for clinicians, and makes recommendations for greater consideration of external validity in the design and reporting of RCTs.},
	language = {en},
	number = {9453},
	urldate = {2021-08-01},
	journal = {The Lancet},
	author = {Rothwell, Peter M},
	month = jan,
	year = {2005},
	pages = {82--93},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/QZXHVGQ4/Rothwell - 2005 - External validity of randomised controlled trials.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/NYP2KIN8/S0140673604176708.html:text/html},
}

@article{garralda2019,
	title = {New clinical trial designs in the era of precision medicine},
	volume = {13},
	issn = {1574-7891},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6396357/},
	doi = {10.1002/1878-0261.12465},
	abstract = {Cancer treatment has made significant strides towards the promise of personalized medicine. Recent scientific advances have shown that there are numerous genetic deregulations that are common in multiple cancer types, raising the possibility of developing drugs targeting those deregulations irrespective of the tumour type. Precision Cancer Medicine (PCM) was born out of accumulated evidence matching targeted agents with these tumour molecular deregulations. At the same time, the therapeutic armamentarium is rapidly increasing and the number of new drugs (including immune‐oncology agents) entering drug development continues to rise. These factors, added to strong collaboration with regulatory agencies, which have approved novel agents based on data obtained from phase 1/2 trials, have led to unprecedented evolution in the design of early‐stage clinical trials. Currently, we have seen rapid phase 1 dose‐escalation trials followed by remarkably large expansion cohorts, and are witnessing the emergence of new trials, such as adaptive studies with basket and umbrella designs aimed at optimizing the biomarker–drug co‐development process. Alongside the growing complexity of these clinical trials, new frameworks for stronger and faster collaboration between all stakeholders in drug development, including academic institutions and frameworks, clinicians, pharma companies and regulatory agencies, have been established. In this review article, we describe the main challenges and opportunities that these new trial designs may provide for a more efficient drug development process, which may ultimately help ensure that PCM becomes a reality for patients.},
	number = {3},
	urldate = {2021-08-02},
	journal = {Molecular Oncology},
	author = {Garralda, Elena and Dienstmann, Rodrigo and Piris‐Giménez, Alejandro and Braña, Irene and Rodon, Jordi and Tabernero, Josep},
	month = mar,
	year = {2019},
	pmid = {30698321},
	pmcid = {PMC6396357},
	pages = {549--557},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/NXP5JN6H/Garralda et al. - 2019 - New clinical trial designs in the era of precision.pdf:application/pdf},
}

@article{bishop2013a,
	title = {Research {Review}: {Emanuel} {Miller} {Memorial} {Lecture} 2012 – {Neuroscientific} studies of intervention for language impairment in children: interpretive and methodological problems},
	volume = {54},
	issn = {0021-9630},
	shorttitle = {Research {Review}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3593170/},
	doi = {10.1111/jcpp.12034},
	abstract = {Background
Our ability to look at structure and function of a living brain has increased exponentially since the early 1970s. Many studies of developmental disorders now routinely include a brain imaging or electrophysiological component. Amid current enthusiasm for applications of neuroscience to educational interventions, we need to pause to consider what neuroimaging data can tell us. Images of brain activity are seductive, and have been used to give credibility to commercial interventions, yet we have only a limited idea of what the brain bases of language disorders are, let alone how to alter them.

Scope and findings
A review of six studies of neuroimaging correlates of language intervention found recurring methodological problems: lack of an adequate control group, inadequate power, incomplete reporting of data, no correction for multiple comparisons, data dredging and failure to analyse treatment effects appropriately. In addition, there is a tendency to regard neuroimaging data as more meaningful than behavioural data, even though it is behaviour that interventions aim to alter.

Conclusion
In our current state of knowledge, it would be better to spend research funds doing well-designed trials of behavioural treatment to establish which methods are effective, rather than rushing headlong into functional imaging studies of unproven treatments.},
	number = {3},
	urldate = {2021-08-02},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Bishop, D V M},
	month = mar,
	year = {2013},
	pmid = {23278309},
	pmcid = {PMC3593170},
	pages = {247--259},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/BKYDLHVX/Bishop - 2013 - Research Review Emanuel Miller Memorial Lecture 2.pdf:application/pdf},
}

@article{senn2018,
	title = {Statistical pitfalls of personalized medicine},
	volume = {563},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-018-07535-2},
	doi = {10.1038/d41586-018-07535-2},
	abstract = {Misleading terminology and arbitrary divisions stymie drug trials and can give false hope about the potential of tailoring drugs to individuals, warns Stephen Senn.},
	language = {en},
	number = {7733},
	urldate = {2021-08-02},
	journal = {Nature},
	author = {Senn, Stephen},
	month = nov,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Number: 7733
Publisher: Nature Publishing Group
Subject\_term: Medical research, Personalized medicine},
	pages = {619--621},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/GVVUPHS5/Senn - 2018 - Statistical pitfalls of personalized medicine.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/8ECCZ2DK/d41586-018-07535-2.html:text/html},
}

@article{best2013,
	title = {Aphasia rehabilitation: {Does} generalisation from anomia therapy occur and is it predictable? {A} case series study},
	volume = {49},
	issn = {0010-9452},
	shorttitle = {Aphasia rehabilitation},
	url = {https://www.sciencedirect.com/science/article/pii/S0010945213000087},
	doi = {10.1016/j.cortex.2013.01.005},
	abstract = {Introduction
The majority of adults with acquired aphasia have anomia which can respond to rehabilitation with cues. However, the literature and clinical consensus suggest change is usually limited to treated items. We investigated the effect of an experimentally controlled intervention using progressive cues in the rehabilitation of noun retrieval/production in 16 participants with chronic aphasia.
Method
Participants were sub-divided relative to the group according to performance on semantic tasks (spoken/written word to picture matching) and phonological output processing (presence/absence of word length effect and proportion of phonological errors in picture naming) in order to investigate outcome in relation to language profile. Cueing therapy took place weekly for 8 weeks.
Results
Intervention resulted in significant improvement on naming treated items for 15/16 participants, with stable performance on control tasks. Change occurred at the point of intervention and not during pre-therapy assessments. We predicted particular patterns of generalisation which were upheld. Only participants classified as having relatively less of a semantic difficulty and more of a phonological output deficit demonstrated generalisation to untreated items. Outcome did not relate to traditional aphasia classification.
Conclusion
A cueing hierarchy can improve word retrieval/production for adults with aphasia. In some cases generalisation to untreated items also occurs. The study demonstrates that the results of behavioural testing can be used to guide predictions of recovery with intervention.},
	language = {en},
	number = {9},
	urldate = {2021-08-02},
	journal = {Cortex},
	author = {Best, Wendy and Greenwood, Alison and Grassly, Jennie and Herbert, Ruth and Hickin, Julie and Howard, David},
	month = oct,
	year = {2013},
	keywords = {Anomia, Aphasia, Generalisation, Rehabilitation, Therapy},
	pages = {2345--2357},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/WDSX2AB2/Best et al. - 2013 - Aphasia rehabilitation Does generalisation from a.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/Y6M2XDIU/S0010945213000087.html:text/html},
}

@article{greenwald1975a,
	title = {Consequences of prejudice against the null hypothesis},
	volume = {82},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/h0076157},
	abstract = {Examined the consequences of prejudice against accepting the null hypothesis through (a) a mathematical model intended to stimulate the research-publication process and (b) case studies of apparent erroneous rejections of the null hypothesis in published psychological research. The input parameters for the model characterize investigators' probabilities of selecting a problem for which the null hypothesis is true, of reporting, following up on, or abandoning research when data do or do not reject the null hypothesis, and they characterize editors' probabilities of publishing manuscripts concluding in favor of or against the null hypothesis. With estimates of the input parameters based on a questionnaire survey of 75 social psychologists, the model output indicates a dysfunctional research-publication system. Particularly, the model indicates that there may be relatively few publications on problems for which the null hypothesis is (at least to a reasonable approximation) true, and of these, a high proportion will erroneously reject the null hypothesis. The case studies provide additional support for this conclusion. It is concluded that research traditions and customs of discrimination against accepting the null hypothesis may be very detrimental to research progress. (44 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Bulletin},
	author = {Greenwald, Anthony G.},
	year = {1975},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Consequence, Experimentation, Mathematical Modeling, Null Hypothesis Testing},
	pages = {1--20},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/XZVFNK7Q/Greenwald - 1975 - Consequences of prejudice against the null hypothe.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/XVT39ER3/1975-08612-001.html:text/html},
}

@article{rosenthal1979a,
	title = {The file drawer problem and tolerance for null results},
	volume = {86},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/0033-2909.86.3.638},
	abstract = {For any given research area, one cannot tell how many studies have been conducted but never reported. The extreme view of the "file drawer problem" is that journals are filled with the 5\% of the studies that show Type I errors, while the file drawers are filled with the 95\% of the studies that show nonsignificant results. Quantitative procedures for computing the tolerance for filed and future null results are reported and illustrated, and the implications are discussed. (15 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Psychological Bulletin},
	author = {Rosenthal, Robert},
	year = {1979},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Experimentation, Scientific Communication, Statistical Probability, Statistical Tests, Type I Errors},
	pages = {638--641},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/ME9HEVTA/1979-27602-001.html:text/html},
}

@article{devries2018,
	title = {The cumulative effect of reporting and citation biases on the apparent efficacy of treatments: the case of depression},
	volume = {48},
	issn = {0033-2917},
	shorttitle = {The cumulative effect of reporting and citation biases on the apparent efficacy of treatments},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6190062/},
	doi = {10.1017/S0033291718001873},
	number = {15},
	urldate = {2021-08-03},
	journal = {Psychological Medicine},
	author = {de Vries, Y. A. and Roest, A. M. and de Jonge, P. and Cuijpers, P. and Munafò, M. R. and Bastiaansen, J. A.},
	month = nov,
	year = {2018},
	pmid = {30070192},
	pmcid = {PMC6190062},
	pages = {2453--2455},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/6FX77EJD/de Vries et al. - 2018 - The cumulative effect of reporting and citation bi.pdf:application/pdf},
}

@book{leng2020,
	address = {Cambridge, MA},
	title = {The {Matter} of {Facts}: {Skepticism}, {Persuasion}, and {Evidence} in {Science}},
	publisher = {MIT Press},
	author = {Leng, G and Leng, R. I},
	year = {2020},
}

@article{robinson2011,
	title = {A {Systematic} {Examination} of the {Citation} of {Prior} {Research} in {Reports} of {Randomized}, {Controlled} {Trials}},
	volume = {154},
	issn = {0003-4819},
	url = {https://www.acpjournals.org/doi/10.7326/0003-4819-154-1-201101040-00007},
	doi = {10.7326/0003-4819-154-1-201101040-00007},
	abstract = {In reports of RCTs published over 4 decades, fewer than 25\% of preceding trials were cited, comprising fewer than 25\% of the participants enrolled in all relevant prior trials. A median of 2 trials was cited, regardless of the number of prior trials that had been conducted. Research is needed to explore the explanations for and consequences of this phenomenon. Potential implications include ethically unjustifiable trials, wasted resources, incorrect conclusions, and unnecessary risks for trial participants.},
	number = {1},
	urldate = {2021-08-03},
	journal = {Annals of Internal Medicine},
	author = {Robinson, Karen A. and Goodman, Steven N.},
	month = jan,
	year = {2011},
	note = {Publisher: American College of Physicians},
	pages = {50--55},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/NAWJBHN3/Robinson and Goodman - 2011 - A Systematic Examination of the Citation of Prior .pdf:application/pdf},
}

@article{bishop2020d,
	title = {The psychology of experimental psychologists: {Overcoming} cognitive constraints to improve research: {The} 47th {Sir} {Frederic} {Bartlett} {Lecture}},
	volume = {73},
	issn = {1747-0218},
	shorttitle = {The psychology of experimental psychologists},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6909195/},
	doi = {10.1177/1747021819886519},
	abstract = {Like many other areas of science, experimental psychology is affected by a “replication crisis” that is causing concern in many fields of research. Approaches to tackling this crisis include better training in statistical methods, greater transparency and openness, and changes to the incentives created by funding agencies, journals, and institutions. Here, I argue that if proposed solutions are to be effective, we also need to take into account human cognitive constraints that can distort all stages of the research process, including design and execution of experiments, analysis of data, and writing up findings for publication. I focus specifically on cognitive schemata in perception and memory, confirmation bias, systematic misunderstanding of statistics, and asymmetry in moral judgements of errors of commission and omission. Finally, I consider methods that may help mitigate the effect of cognitive constraints: better training, including use of simulations to overcome statistical misunderstanding; specific programmes directed at inoculating against cognitive biases; adoption of Registered Reports to encourage more critical reflection in planning studies; and using methods such as triangulation and “pre mortem” evaluation of study design to foster a culture of dialogue and criticism.},
	number = {1},
	urldate = {2021-08-03},
	journal = {Quarterly Journal of Experimental Psychology (2006)},
	author = {Bishop, Dorothy VM},
	month = jan,
	year = {2020},
	pmid = {31724919},
	pmcid = {PMC6909195},
	pages = {1--19},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/B6F9YV39/Bishop - 2020 - The psychology of experimental psychologists Over.pdf:application/pdf},
}

@article{irwin2009,
	title = {The {Role} of {Conflict} of {Interest} in {Reporting} of {Scientific} {Information}},
	volume = {136},
	issn = {0012-3692},
	url = {https://www.sciencedirect.com/science/article/pii/S001236920960430X},
	doi = {10.1378/chest.09-0890},
	abstract = {We have come to appreciate that scientific misconduct is often not intuitively obvious to those who perpetrate it. Therefore, this commentary has been written to review what we know about the role of conflict of interest (COI) in the reporting of scientific information and to challenge those of us in educator roles to do a better job in mentoring our trainees, junior faculty, and associates on what is right and wrong; what is ethical and unethical. The review addresses the following questions: (1) Why has the public trust in the clinical research industry been eroded? (2) How often is the ethical concept of equipoise violated in industry-sponsored randomized controlled clinical trials? (3) How often are negative trials underreported and favorable trials selectively or redundantly over-reported in industry-sponsored randomized controlled clinical trials? (4) What is being done to restore the public trust? While there are multiple strategies to mitigate COI in the reporting of scientific information, we have come to appreciate that the disclosure of potential conflicts of interest is not enough. It is our hope that this article and its contents can serve as a stimulus for the development and incorporation of an educational series in all training programs on what is ethical and unethical in the conducting and reporting of scientific studies.},
	language = {en},
	number = {1},
	urldate = {2021-08-03},
	journal = {Chest},
	author = {Irwin, Richard S.},
	month = jul,
	year = {2009},
	pages = {253--259},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/F55K7NNT/Irwin - 2009 - The Role of Conflict of Interest in Reporting of S.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/LN8LKNHT/S001236920960430X.html:text/html},
}

@article{friedman2004,
	title = {Relationship {Between} {Conflicts} of {Interest} and {Research} {Results}},
	volume = {19},
	issn = {0884-8734},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1494677/},
	doi = {10.1111/j.1525-1497.2004.30617.x},
	abstract = {CONTEXT
To date, research regarding the influence of conflicts of interest on the presentation of findings by researchers has been limited.

OBJECTIVE
To evaluate the sources of funding for published manuscripts, and association between reported findings and conflicts of interest.

METHODS
Data from both print and electronic issues of The New England Journal of Medicine (NEJM) and The Journal of the American Medical Association (JAMA) were analyzed for sources of funding, areas of investigation, conflict of interest (COI), and presentation of results. We reviewed all original manuscripts published during the year 2001 within NEJM (N = 193) and JAMA (N = 205). We use 3 definitions for COI in this paper: a broadly defined criterion, the criterion used by The International Council of Medical Journal Editors (ICMJE), and a criterion defined by the authors.

RESULTS
Depending on the COI criteria used, 16.6\% to 32.6\% of manuscripts had 1 or more author with COI. Based on ICMJE criterion, 38.7\% of studies investigating drug treatments had authors with COI. We observed a strong association between those studies whose authors had COI and reported positive findings (P {\textless} .001). When controlling for sample size, study design, and country of primary authors, we observed a strong association between positive results and COI (ICMJE definition) among all treatment studies (adjusted odds ratio [OR], 2.35; 95\% confidence interval [CI], 1.08 to 5.09) and drug studies alone (OR, 2.64; 95\% CI, 1.09 to 6.39).

CONCLUSION
COI is widespread among the authors of published manuscripts and these authors are more likely to present positive findings.},
	number = {1},
	urldate = {2021-08-03},
	journal = {Journal of General Internal Medicine},
	author = {Friedman, Lee S and Richter, Elihu D},
	month = jan,
	year = {2004},
	pmid = {14748860},
	pmcid = {PMC1494677},
	pages = {51--56},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/VUUBYX4B/Friedman and Richter - 2004 - Relationship Between Conflicts of Interest and Res.pdf:application/pdf},
}

@book{mahoney1976,
	address = {Cambridge, MA},
	title = {Scientist as {Subject}: {The} {Psychological} {Imperative}},
	publisher = {Ballinger Publishing Company},
	author = {Mahoney, Michael J},
	year = {1976},
}

@article{ferguson2012,
	title = {A {Vast} {Graveyard} of {Undead} {Theories}: {Publication} {Bias} and {Psychological} {Science}’s {Aversion} to the {Null}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {A {Vast} {Graveyard} of {Undead} {Theories}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612459059},
	doi = {10.1177/1745691612459059},
	abstract = {Publication bias remains a controversial issue in psychological science.The tendency of psychological science to avoid publishing null results produces a situation that limits the replicability assumption of science, as replication cannot be meaningful without the potential acknowledgment of failed replications.We argue that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.},
	language = {en},
	number = {6},
	urldate = {2021-08-03},
	journal = {Perspectives on Psychological Science},
	author = {Ferguson, Christopher J. and Heene, Moritz},
	month = nov,
	year = {2012},
	pages = {555--561},
	file = {Ferguson and Heene - 2012 - A Vast Graveyard of Undead Theories Publication B.pdf:/Users/dorothybishop/Zotero/storage/ETEMJXK7/Ferguson and Heene - 2012 - A Vast Graveyard of Undead Theories Publication B.pdf:application/pdf},
}

@book{christensen2019,
	address = {Oakland, CA},
	title = {Transparent and reproducible social science research: {How} to do open science.},
	publisher = {University of California Press},
	author = {Christensen, G and Freese, J and Miguel, E},
	year = {2019},
}

@article{deangelis2004,
	title = {Clinical trial registration: a statement from the {International} {Committee} of {Medical} {Journal} {Editors}},
	volume = {364},
	issn = {1474-547X},
	shorttitle = {Clinical trial registration},
	doi = {10.1016/S0140-6736(04)17034-7},
	language = {eng},
	number = {9438},
	journal = {Lancet (London, England)},
	author = {De Angelis, Catherine and Drazen, Jeffrey M. and Frizelle, Frank A. and Haug, Charlotte and Hoey, John and Horton, Richard and Kotzin, Sheldon and Laine, Christine and Marusic, Ana and Overbeke, A. John P. M. and Schroeder, Torben V. and Sox, Hal C. and Van Der Weyden, Martin B. and {International Committee of Medical Journal Editors}},
	month = sep,
	year = {2004},
	pmid = {15364170},
	keywords = {Biomedical and Behavioral Research, Clinical Trials as Topic, Editorial Policies, International Committee of Medical Journal Editors, Periodicals as Topic, Registries},
	pages = {911--912},
}

@techreport{hardwicke2021,
	title = {Preregistration: {A} pragmatic tool to reduce bias and calibrate confidence in scientific research},
	shorttitle = {Preregistration},
	url = {https://osf.io/preprints/metaarxiv/d7bcu/},
	abstract = {Scientific research is performed by fallible humans. Degrees of freedom in the construction and selection of evidence and hypotheses grant scientists considerable latitude to obtain study outcomes that align more with their preferences than is warranted. This creates a risk of bias and can lead to scientists fooling themselves and fooling others. Preregistration involves archiving study information (e.g., hypotheses, methods, and analyses) in a public registry before data are inspected. This offers two potential benefits: (1) reduce bias by ensuring that research decisions are made independently of study outcomes; and (2) calibrate confidence in research by transparently communicating information about a study’s risk of bias. In this article, we briefly review the historical evolution of preregistration in medicine, psychology, and other domains, clarify its pragmatic functions, discuss relevant meta-research, and provide recommendations for scientists and journal editors.},
	urldate = {2021-08-03},
	institution = {MetaArXiv},
	author = {Hardwicke, Tom E. and Wagenmakers, Eric-Jan},
	month = apr,
	year = {2021},
	doi = {10.31222/osf.io/d7bcu},
	note = {type: article},
	keywords = {bias, Medicine and Health Sciences, meta-research, multiplicity, preregistration, Social and Behavioral Sciences, transparency},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/CLVWMBL4/Hardwicke and Wagenmakers - 2021 - Preregistration A pragmatic tool to reduce bias a.pdf:application/pdf},
}

@misc{higgins2021,
	title = {Cochrane {Handbook} for {Systematic} {Reviews} of {Interventions}, version 6.2 (updated {February} 2021)},
	url = {https://training.cochrane.org/handbook/current},
	language = {en},
	urldate = {2021-08-06},
	author = {Higgins, J P T and Thomas, J and Chandler, J and Cumpston, M and Li, T and Page, M J and Welch, V A},
	year = {2021},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/FJU67HHD/current.html:text/html},
}

@techreport{hemingway2009,
	title = {What is a systematic review? 2nd edition.},
	url = {http://www.bandolier.org.uk/painres/download/whatis/Syst-review.pdf}},
	author = {Hemingway, P and Brereton, N. J.},
	year = {2009},
}

@article{strong2011,
	title = {A systematic meta-analytic review of evidence for the effectiveness of the ‘{Fast} {ForWord}’ language intervention program},
	volume = {52},
	issn = {0021-9630},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3061204/},
	doi = {10.1111/j.1469-7610.2010.02329.x},
	abstract = {Background
Fast ForWord is a suite of computer-based language intervention programs designed to improve children's reading and oral language skills. The programs are based on the hypothesis that oral language difficulties often arise from a rapid auditory temporal processing deficit that compromises the development of phonological representations.

Methods
A systematic review was designed, undertaken and reported using items from the PRISMA statement. A literature search was conducted using the terms ‘Fast ForWord’ ‘Fast For Word’ ‘Fastforword’ with no restriction on dates of publication. Following screening of (a) titles and abstracts and (b) full papers, using pre-established inclusion and exclusion criteria, six papers were identified as meeting the criteria for inclusion (randomised controlled trial (RCT) or matched group comparison studies with baseline equivalence published in refereed journals). Data extraction and analyses were carried out on reading and language outcome measures comparing the Fast ForWord intervention groups to both active and untreated control groups.

Results
Meta-analyses indicated that there was no significant effect of Fast ForWord on any outcome measure in comparison to active or untreated control groups.

Conclusions
There is no evidence from the analysis carried out that Fast ForWord is effective as a treatment for children's oral language or reading difficulties.},
	number = {3},
	urldate = {2021-08-06},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Strong, Gemma K and Torgerson, Carole J and Torgerson, David and Hulme, Charles},
	month = mar,
	year = {2011},
	pmid = {20950285},
	pmcid = {PMC3061204},
	pages = {224--235},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/AH6SDE3D/Strong et al. - 2011 - A systematic meta-analytic review of evidence for .pdf:application/pdf},
}

@misc{zotero-1331,
	title = {Telerehabilitation for people with aphasia: {A} systematic review and meta-analysis {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Telerehabilitation for people with aphasia},
	url = {https://reader.elsevier.com/reader/sd/pii/S0021992421000344?token=3099C6FCDCBACB8B331BF416E1EB56E1B38D0ABDE2EB9CFC553672622DFC385DE73824840E2A805A4BF2B6E4BD4A00CA&originRegion=eu-west-1&originCreation=20210806123944},
	language = {en},
	urldate = {2021-08-06},
	doi = {10.1016/j.jcomdis.2021.106111},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/A7B4MCAL/S0021992421000344.html:text/html},
}

@article{wood2021,
	title = {Is speech and language therapy effective at improving the communication of adults with intellectual disabilities?: {A} systematic review},
	volume = {56},
	issn = {1460-6984},
	shorttitle = {Is speech and language therapy effective at improving the communication of adults with intellectual disabilities?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1460-6984.12601},
	doi = {10.1111/1460-6984.12601},
	abstract = {Background A significant proportion of adults with intellectual disabilities (ID) experience speech, language and communication difficulties which are associated with poor physical and mental health outcomes. Speech and language therapy (SLT) interventions are an important way to address these communication difficulties, yet there is limited available evidence to provide information about the effectiveness of the different approaches used for this heterogeneous group. Aims To review the evidence available for the effectiveness of SLT interventions aimed at improving communication for adults with ID. Methods \& Procedures A systematic search across relevant databases was performed. Information on methodological details of each relevant study, along with descriptions of the SLT interventions employed, were extracted and the Crowe Critical Appraisal Tool (CCAT) was used to assess quality. Findings were discussed in a narrative synthesis grouped by target communication skill. Outcomes \& Results A total of 10 relevant studies met the inclusion criteria. These were predominantly interventions aimed directly at adults with ID to improve speech, increase augmentative and alternative communication (AAC) use and develop interaction skills, with one study addressing work with carers. The included studies were all rated as low quality. There is weak preliminary evidence that SLT input can improve the communication skills of adults with ID. Conclusions \& Implications There is insufficient evidence to draw strong conclusions about the effectiveness of SLT in this population. Further high-level evidence across speech, language and communication domains is urgently needed. What this paper adds What is already known on the subject There is limited evidence for community health interventions used with adults with ID. Previous reviews of SLT interventions found a lack of evidence base for this population. Some areas of SLT practice such as AAC have demonstrated potential benefits and other areas including speech work, social communication skills and training for communication partners have some evidence base for children with ID but there is currently insufficient evidence for adults with ID. What this paper adds to existing knowledge The study systematically reviews the current evidence base available when considering the effectiveness of SLT intervention for adults with ID. It provides weak evidence to suggest SLT intervention can improve communication in this population and highlights the need for clinically relevant, robustly designed studies to be undertaken in this field. What are the potential or actual clinical implications of this work? The lack of high-quality studies with sufficient power to draw conclusions about effectiveness means SLTs are not able to base their intervention choices on firm evidence. There is an urgent need to conduct robust research into the effectiveness of SLT interventions for adults with ID.},
	language = {en},
	number = {2},
	urldate = {2021-08-06},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Wood, Siȃn and Standen, Penny},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1460-6984.12601},
	keywords = {intellectual disabilities, speech and language therapy, systematic review},
	pages = {435--450},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/WTGJ46B8/Wood and Standen - 2021 - Is speech and language therapy effective at improv.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/JURA8JYB/1460-6984.html:text/html},
}

@article{dipper2020,
	title = {Treatment for improving discourse in aphasia: a systematic review and synthesis of the evidence base},
	issn = {0268-7038},
	shorttitle = {Treatment for improving discourse in aphasia},
	url = {https://openaccess.city.ac.uk/id/eprint/24272/},
	doi = {10.1080/02687038.2020.1765305},
	abstract = {Background
Improved discourse production is a priority for all key stakeholders in aphasia rehabilitation. A Cochrane review of randomised controlled trials (RCTs) for aphasia found speech and language therapy treatment to be effective for improving the ability to communicate in everyday interaction. However, this large-scale review did not focus exclusively on treatment for discourse production and did not include other treatment research designs. Thus, the extent of the evidence base addressing discourse interventions is currently unclear.

Objective
The present study undertakes the first systematic review of research on treatment for discourse production in aphasia, appraises the quality of the evidence base; characterises the methods for measuring outcomes; and describes discourse treatment in terms of both content and efficacy.

Design
Scopus, Medline, and EmBase databases were searched, providing 334 records. Twenty-five studies (reporting on 127 participants) met inclusion criteria and were reviewed with the following research questions: What is the quality of the study designs used? How complete is the intervention reporting? What is the range, type, and content of outcome measures used? What is the range, type, and content of discourse treatments reported to date? Are discourse treatments efficacious?

Results
Seven of the 25 studies met the criteria for quality review, with 3 RCTs scoring moderately well and 3 (of 4) case studies scoring moderate-low. Most studies had adequate levels of completeness of treatment reporting, with 3 scoring highly. There were 514 different outcome measures reported across the 25 studies, with measures of words-in-discourse the most common. Studies were grouped into six treatment categories: “word production in discourse”, “sentence production in discourse”, “discourse macrostructure”, “discourse scripts”, “multi-level”, and “no consensus”. Twenty-two studies reported post-treatment gains, most commonly noted in increased word production. Changes in sentence production and discourse macrostructure were present but infrequently assessed.

Conclusions
Discourse treatment is an emerging field of research. Despite limitations in the evidence base, there are clear positive signs that discourse treatment is efficacious. There is emerging evidence for beneficial effects on word and sentence production in discourse, for improved discourse macrostructure, and for treatments working at multiple levels of language. To strengthen the evidence in this field and improve outcomes for people with aphasia, we need more discourse treatment research using an explicit theoretical rationale, high-quality study designs, more complete reporting, and agreed treatment and assessment methods.},
	language = {en},
	urldate = {2021-08-06},
	journal = {Aphasiology},
	author = {Dipper, L. and Marshall, J. and Boyle, M. and Botting, N. and Hersh, D. and Pritchard, M. and Cruice, M.},
	month = jun,
	year = {2020},
	note = {Publisher: Informa UK Limited},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/9KWKXWG3/24272.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/A7X2TJN4/Dipper et al. - 2020 - Treatment for improving discourse in aphasia a sy.pdf:application/pdf},
}

@article{borenstein2007,
	title = {Introduction to {Meta}-{Analysis}},
	language = {en},
	author = {Borenstein, Michael and Hedges, Larry and Rothstein, Hannah},
	year = {2007},
	pages = {37},
	file = {Borenstein et al. - 2007 - Introduction to Meta-Analysis.pdf:/Users/dorothybishop/Zotero/storage/58SSEP87/Borenstein et al. - 2007 - Introduction to Meta-Analysis.pdf:application/pdf},
}

@article{balduzzi2019,
	title = {How to perform a meta-analysis with {R}: a practical tutorial},
	volume = {22},
	copyright = {© Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and permissions. Published by BMJ.},
	issn = {1362-0347, 1468-960X},
	shorttitle = {How to perform a meta-analysis with {R}},
	url = {https://ebmh.bmj.com/content/22/4/153},
	doi = {10.1136/ebmental-2019-300117},
	abstract = {Objective Meta-analysis is of fundamental importance to obtain an unbiased assessment of the available evidence. In general, the use of meta-analysis has been increasing over the last three decades with mental health as a major research topic. It is then essential to well understand its methodology and interpret its results. In this publication, we describe how to perform a meta-analysis with the freely available statistical software environment R, using a working example taken from the field of mental health.
Methods R package meta is used to conduct standard meta-analysis. Sensitivity analyses for missing binary outcome data and potential selection bias are conducted with R package metasens. All essential R commands are provided and clearly described to conduct and report analyses.
Results The working example considers a binary outcome: we show how to conduct a fixed effect and random effects meta-analysis and subgroup analysis, produce a forest and funnel plot and to test and adjust for funnel plot asymmetry. All these steps work similar for other outcome types.
Conclusions R represents a powerful and flexible tool to conduct meta-analyses. This publication gives a brief glimpse into the topic and provides directions to more advanced meta-analysis methods available in R.},
	language = {en},
	number = {4},
	urldate = {2021-08-06},
	journal = {Evidence-Based Mental Health},
	author = {Balduzzi, Sara and Rücker, Gerta and Schwarzer, Guido},
	month = nov,
	year = {2019},
	pmid = {31563865},
	note = {Publisher: Royal College of Psychiatrists
Section: Statistics in practice},
	pages = {153--160},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/M6FDT5A9/153.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/DWTMG92H/Balduzzi et al. - 2019 - How to perform a meta-analysis with R a practical.pdf:application/pdf},
}

@article{button2020,
	title = {Supporting ‘team science’},
	volume = {33},
	url = {https://thepsychologist.bps.org.uk/volume-33/october-2020/supporting-team-science},
	urldate = {2021-08-07},
	journal = {The Psychologist},
	author = {Button, K},
	year = {2020},
	pages = {30--33},
	file = {Supporting ‘team science’ | The Psychologist:/Users/dorothybishop/Zotero/storage/6GVBB8DA/supporting-team-science.html:text/html},
}

@article{button2018,
	title = {Reboot undergraduate courses for reproducibility},
	volume = {561},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-018-06692-8},
	doi = {10.1038/d41586-018-06692-8},
	abstract = {Collaboration across institutes can train students in open, team science, which better prepares them for challenges to come.},
	language = {en},
	number = {7723},
	urldate = {2021-08-07},
	journal = {Nature},
	author = {Button, K},
	month = sep,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: World View
Number: 7723
Publisher: Nature Publishing Group
Subject\_term: Education, Research management},
	pages = {287--287},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/S4QSCW9S/Button - 2018 - Reboot undergraduate courses for reproducibility.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/WC9ABEMU/d41586-018-06692-8.html:text/html},
}

@misc{hernan2018,
	title = {Causal {Inference} from {Observational} {Data}},
	url = {https://www.hsph.harvard.edu/miguel-hernan/research/causal-inference-from-observational-data/},
	abstract = {Try explaining to your extended family that you are considered an expert in causal inference. That’s why, when people ask, I just say that my job is to learn what works for the prevention and…},
	language = {en-us},
	urldate = {2021-08-07},
	journal = {Miguel Hernan's Faculty Website},
	author = {Hernan, Miguel},
	month = aug,
	year = {2018},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/YYUYPZZX/causal-inference-from-observational-data.html:text/html},
}

@article{mcarthur2008,
	title = {Does {What} {Works} {Clearinghouse} {Work}? {A} {Brief} {Review} of {Fast} {ForWord}®},
	volume = {32},
	issn = {1030-0112},
	shorttitle = {Does {What} {Works} {Clearinghouse} {Work}?},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10300110701845953},
	doi = {10.1080/10300110701845953},
	abstract = {The What Works Clearinghouse (WWC) provides online reports to the public about the scientific evidence for educational interventions. The quality of these reports is important because they effectively tell the non‐scientific community which programmes do and do not work. The aim of this brief review is to assess WWC's report on a clinically popular, yet theoretically controversial, intervention called Fast ForWord® (FFW). Some of the methods used by WWC to assess FFW were problematic: the literature review included studies that had not passed peer review; it failed to include a key study that had passed peer review; alphabetic skills were assessed with phonological awareness outcomes; effectiveness ratings were based on statistical significance; terms peculiar to WWC were not clearly defined; and existing quality control procedures failed to detect an error in the WWC report. These problems could be addressed by making minor adjustments to WWC's existing methods and by subjecting WWC reports to the scientific peer‐review process before they are released to the public.},
	number = {1},
	urldate = {2021-08-08},
	journal = {Australasian Journal of Special Education},
	author = {McArthur, Genevieve},
	month = apr,
	year = {2008},
	note = {Publisher: Routledge
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/10300110701845953},
	pages = {101--107},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/7CWLZ5QU/10300110701845953.html:text/html},
}

@article{cohen2005,
	title = {Effects of {Computer}-{Based} {Intervention} {Through} {Acoustically} {Modified} {Speech} ({Fast} {ForWord}) in {Severe} {Mixed} {Receptive}—{Expressive} {Language} {Impairment}},
	volume = {48},
	url = {https://pubs.asha.org/doi/10.1044/1092-4388(2005/049)},
	doi = {10.1044/1092-4388(2005/049)},
	abstract = {Seventy-seven children between the ages of 6 and 10 years, with severe mixed receptive-expressive specific language impairment (SLI), participated in a randomized controlled trial (RCT) of Fast ForWord (FFW; Scientific Learning Corporation, 1997, 2001). FFW is a computer-based intervention for treating SLI using acoustically enhanced speech stimuli. These stimuli are modified to exaggerate their time and intensity properties as part of an adaptive training process. All children who participated in the RCT maintained their regular speech and language therapy and school regime throughout the trial. Standardized measures of receptive and expressive language were used to assess performance at baseline and to measure outcome from treatment at 9 weeks and 6 months. Children were allocated to 1 of 3 groups. Group A (n=23) received the FFWintervention as a home-based therapy for 6 weeks. Group B (n=27) received commercially available computer-based activities designed to promote language as a control for computer games exposure. Group C (n=27) received no additional study intervention. Each group made significant gains in language scores, but there was no additional effect for either computer intervention. Thus, the findings from this RCT do not support the efficacy of FFW as an intervention for children with severe mixed receptive-expressive SLI.},
	number = {3},
	urldate = {2021-08-08},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Cohen, Wendy and Hodson, Ann and O, 'Hare Anne and Boyle, James and Durrani, Tariq and McCartney, Elspeth and Mattey, Mike and Naftalin, Lionel and Watson, Jocelynne},
	month = jun,
	year = {2005},
	note = {Publisher: American Speech-Language-Hearing Association},
	keywords = {computer applications, Fast ForWord, language disorders, randomized controlled trial},
	pages = {715--729},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/5T8ZKTTZ/Cohen et al. - 2005 - Effects of Computer-Based Intervention Through Aco.pdf:application/pdf},
}

@article{green2017,
	title = {Randomised trial of a parent‐mediated intervention for infants at high risk for autism: longitudinal outcomes to age 3 years},
	volume = {58},
	issn = {0021-9630},
	shorttitle = {Randomised trial of a parent‐mediated intervention for infants at high risk for autism},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5724485/},
	doi = {10.1111/jcpp.12728},
	abstract = {Background
There has been increasing interest in the potential for pre‐emptive interventions in the prodrome of autism, but little investigation as to their effect.

Methods
A two‐site, two‐arm assessor‐blinded randomised controlled trial (RCT) of a 12‐session parent‐mediated social communication intervention delivered between 9 and 14 months of age (Intervention in the British Autism Study of Infant Siblings‐Video Interaction for Promoting Positive Parenting), against no intervention. Fifty‐four infants (28 intervention, 26 nonintervention) at familial risk of autism but not otherwise selected for developmental atypicality were assessed at 9‐month baseline, 15‐month treatment endpoint, and 27‐ and 39‐month follow‐up. Primary outcome: severity of autism prodromal symptoms, blind‐rated on Autism Observation Schedule for Infants or Autism Diagnostic Observation Schedule 2nd Edition across the four assessment points. Secondary outcomes: blind‐rated parent–child interaction and child language; nonblind parent‐rated communication and socialisation. Prespecified intention‐to‐treat analysis combined estimates from repeated measures within correlated regressions to estimate the overall effect of the infancy intervention over time.

Results
Effect estimates in favour of intervention on autism prodromal symptoms, maximal at 27 months, had confidence intervals (CIs) at each separate time point including the null, but showed a significant overall effect over the course of the intervention and follow‐up period (effect size [ES] = 0.32; 95\% CI 0.04, 0.60; p = .026). Effects on proximal intervention targets of parent nondirectiveness/synchrony (ES = 0.33; CI 0.04, 0.63; p = .013) and child attentiveness/communication initiation (ES = 0.36; 95\% CI 0.04, 0.68; p = .015) showed similar results. There was no effect on categorical diagnostic outcome or formal language measures.

Conclusions
Follow‐up to 3 years of the first RCT of a very early social communication intervention for infants at familial risk of developing autism has shown a treatment effect, extending 24 months after intervention end, to reduce the overall severity of autism prodromal symptoms and enhance parent–child dyadic social communication over this period. We highlight the value of extended follow‐up and repeat assessment for early intervention trials.},
	number = {12},
	urldate = {2021-08-08},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Green, Jonathan and Pickles, Andrew and Pasco, Greg and Bedford, Rachael and Wan, Ming Wai and Elsabbagh, Mayada and Slonims, Vicky and Gliga, Teea and Jones, Emily and Cheung, Celeste and Charman, Tony and Johnson, Mark and Baron‐Cohen, Simon and Bolton, Patrick and Davies, Kim and Liew, Michelle and Fernandes, Janice and Gammer, Isobel and Salomone, Erica and Ribeiro, Helena and Tucker, Leslie and Taylor, Carol and Booth, Rhonda and Harrop, Claire and Holsgrove, Samina and McNally, Janet},
	month = dec,
	year = {2017},
	pmid = {28393350},
	pmcid = {PMC5724485},
	pages = {1330--1340},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/MWVXNIBV/Green et al. - 2017 - Randomised trial of a parent‐mediated intervention.pdf:application/pdf},
}

@article{morris2007,
	title = {Masking is better than blinding},
	volume = {334},
	copyright = {© BMJ Publishing Group Ltd 2007},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/content/334/7597/799},
	doi = {10.1136/bmj.39175.503299.94},
	abstract = {{\textless}p{\textgreater}Why the term “blinding” should not be used in clinical trials{\textless}/p{\textgreater}},
	language = {en},
	number = {7597},
	urldate = {2021-08-09},
	journal = {BMJ},
	author = {Morris, Daniel and Fraser, Scott and Wormald, Richard},
	month = apr,
	year = {2007},
	note = {Publisher: British Medical Journal Publishing Group
Section: Views \&amp; Reviews},
	pages = {799--799},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/SKVZJBKC/Morris et al. - 2007 - Masking is better than blinding.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/634APA8X/799.html:text/html},
}

@article{schulz2007,
	title = {Blinding is better than masking},
	volume = {334},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1865441/},
	doi = {10.1136/bmj.39199.461644.3A},
	number = {7600},
	urldate = {2021-08-09},
	journal = {BMJ : British Medical Journal},
	author = {Schulz, Kenneth F and Altman, Douglas G and Moher, David},
	month = may,
	year = {2007},
	pmid = {null},
	pmcid = {PMC1865441},
	pages = {918},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/WFDYRC8N/Schulz et al. - 2007 - Blinding is better than masking.pdf:application/pdf},
}

@book{lo2009,
	address = {Washington, DC},
	title = {Conflict of {Interest} in {Medical} {Research}, {Education}, and {Practice}},
	isbn = {13: 978-0-309-13188-9},
	publisher = {National Academies Press},
	author = {Lo, B and Field, M. J},
	year = {2009},
}

@article{barber1968,
	title = {Fact, fiction, and the experimenter bias effect},
	volume = {70},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/h0026724},
	abstract = {Critically analyzes 31 studies which attempted to demonstrate that Es' expectancies and desires significantly affect the experimental outcome (E bias effect). The majority of studies do not clearly demonstrate the effect. Many of these studies are criticized for inadequacies in the analysis of results, e.g., failure to perform an overall statistical analysis to exclude the null hypothesis and failure to avoid probability pyramiding when postmortem tests are performed. 2 conclusions are drawn: (1) The E bias effect appears to be more difficult to demonstrate and less pervasive than was implied in previous reviews in this journal. (2) In those instances in which the effect was obtained, it was apparently due to one or more of the following: the student Es misjudged, misrecorded or misreported the results; they verbally reinforced their Ss for expected responses; or they intentionally or unintentionally transmitted their expectancies and desires by paralinguistic or kinesic cues. (2 p. ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6, Pt.2},
	journal = {Psychological Bulletin},
	author = {Barber, Theodore X. and Silver, Maurice J.},
	year = {1968},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Expectations, Experimentation, Literature Review, Methodology, Prejudice},
	pages = {1--29},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/I5UH93QY/1969-06146-001.html:text/html},
}

@techreport{schonbrodt2016,
	title = {p-hacker: {Train} your p-hacking skills!},
	url = {http://shinyapps.org/apps/p-hacker/},
	author = {Schönbrodt, F D},
	year = {2016},
}

@article{singal2014,
	title = {A {Primer} on {Effectiveness} and {Efficacy} {Trials}},
	volume = {5},
	issn = {2155-384X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3912314/},
	doi = {10.1038/ctg.2013.13},
	abstract = {Although efficacy and effectiveness studies are both important when evaluating interventions, they serve distinct purposes and have different study designs. Unfortunately, the distinction between these two types of trials is often poorly understood. In this primer, we highlight several differences between these two types of trials including study design, patient populations, intervention design, data analysis, and result reporting.},
	number = {1},
	urldate = {2021-08-09},
	journal = {Clinical and Translational Gastroenterology},
	author = {Singal, Amit G and Higgins, Peter D R and Waljee, Akbar K},
	month = jan,
	year = {2014},
	pmid = {24384867},
	pmcid = {PMC3912314},
	pages = {e45},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/AS2YSSWM/Singal et al. - 2014 - A Primer on Effectiveness and Efficacy Trials.pdf:application/pdf},
}

@article{treweek2009,
	title = {Making trials matter: pragmatic and explanatory trials and the problem of applicability},
	volume = {10},
	issn = {1745-6215},
	shorttitle = {Making trials matter},
	url = {https://doi.org/10.1186/1745-6215-10-37},
	doi = {10.1186/1745-6215-10-37},
	abstract = {Randomised controlled trials are the best research design for decisions about the effect of different interventions but randomisation does not, of itself, promote the applicability of a trial's results to situations other than the precise one in which the trial was done. While methodologists and trialists have rightly paid great attention to internal validity, much less has been given to applicability.},
	number = {1},
	urldate = {2021-08-09},
	journal = {Trials},
	author = {Treweek, Shaun and Zwarenstein, Merrick},
	month = jun,
	year = {2009},
	keywords = {Chronic Obstructive Pulmonary Disease, Directly Observe Treatment, Explanatory Trial, Pragmatic Trial, Rofecoxib},
	pages = {37},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/TVJQI7CF/Treweek and Zwarenstein - 2009 - Making trials matter pragmatic and explanatory tr.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/TH787I75/1745-6215-10-37.html:text/html},
}

@article{thorlund2018,
	title = {Key design considerations for adaptive clinical trials: a primer for clinicians},
	volume = {360},
	copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions. This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
	issn = {0959-8138, 1756-1833},
	shorttitle = {Key design considerations for adaptive clinical trials},
	url = {https://www.bmj.com/content/360/bmj.k698},
	doi = {10.1136/bmj.k698},
	abstract = {{\textless}p{\textgreater}This article reviews important considerations for researchers who are designing adaptive clinical trials. These differ from conventional clinical trials because they allow and even enforce continual modifications to key components of trial design while data are being collected. This innovative approach has the potential to reduce resource use, decrease time to trial completion, limit allocation of participants to inferior interventions, and improve the likelihood that trial results will be scientifically or clinically relevant. Adaptive designs have mostly been used in trials evaluating drugs, but their use is spreading. The US Food and Drug Administration recently issued guidance on adaptive trial designs, which highlighted general principles and different types of adaptive clinical trials but did not provide concrete guidance about important considerations in designing such trials. Decisions to adapt a trial are not arbitrary; they are based on decision rules that have been rigorously examined via statistical simulations before the first trial participant is enrolled. The authors review important characteristics of adaptive trials and common types of study modifications and provide a practical guide, illustrated with a case study, to aid investigators who are planning an adaptive clinical trial{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-08-09},
	journal = {BMJ},
	author = {Thorlund, Kristian and Haggstrom, Jonas and Park, Jay JH and Mills, Edward J.},
	month = mar,
	year = {2018},
	pmid = {29519932},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research Methods \&amp; Reporting},
	pages = {k698},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/ZWTMQRBK/bmj.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/NQ8YUESV/Thorlund et al. - 2018 - Key design considerations for adaptive clinical tr.pdf:application/pdf},
}

@article{sibbald1998,
	title = {Understanding controlled trials {Crossover} trials},
	volume = {316},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1113275/},
	number = {7146},
	urldate = {2021-08-10},
	journal = {BMJ : British Medical Journal},
	author = {Sibbald, Bonnie and Roberts, Chris},
	month = jun,
	year = {1998},
	pmid = {9614025},
	pmcid = {PMC1113275},
	pages = {1719--1720},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/9P5C9G3Z/Sibbald and Roberts - 1998 - Understanding controlled trials Crossover trials.pdf:application/pdf},
}

@misc{westrick,
	title = {{LibGuides}: {Systematic} {Reviews}: {Systematic} {Review} or {Literature} {Review}?},
	copyright = {Copyright Rush University Medical Center 2021},
	shorttitle = {{LibGuides}},
	url = {https://rushu.libguides.com/c.php?g=595495&p=4585490},
	abstract = {LibGuides: Systematic Reviews: Systematic Review or Literature Review?},
	language = {en},
	urldate = {2021-08-10},
	author = {Westrick, Jennifer},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/DRJR49EB/c.html:text/html},
}
