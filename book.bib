
@article{bishop2020,
	title = {The psychology of experimental psychologists: {Overcoming} cognitive constraints to improve research: {The} 47th {Sir} {Frederic} {Bartlett} {Lecture}},
	volume = {73},
	issn = {1747-0218},
	shorttitle = {The psychology of experimental psychologists},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6909195/},
	doi = {10.1177/1747021819886519},
	abstract = {Like many other areas of science, experimental psychology is affected by a “replication crisis” that is causing concern in many fields of research. Approaches to tackling this crisis include better training in statistical methods, greater transparency and openness, and changes to the incentives created by funding agencies, journals, and institutions. Here, I argue that if proposed solutions are to be effective, we also need to take into account human cognitive constraints that can distort all stages of the research process, including design and execution of experiments, analysis of data, and writing up findings for publication. I focus specifically on cognitive schemata in perception and memory, confirmation bias, systematic misunderstanding of statistics, and asymmetry in moral judgements of errors of commission and omission. Finally, I consider methods that may help mitigate the effect of cognitive constraints: better training, including use of simulations to overcome statistical misunderstanding; specific programmes directed at inoculating against cognitive biases; adoption of Registered Reports to encourage more critical reflection in planning studies; and using methods such as triangulation and “pre mortem” evaluation of study design to foster a culture of dialogue and criticism.},
	number = {1},
	urldate = {2021-02-16},
	journal = {Quarterly Journal of Experimental Psychology (2006)},
	author = {Bishop, D. V. M.},
	year = {2020},
	pmid = {31724919},
	pmcid = {PMC6909195},
	keywords = {Reasoning, Cognitive bias},
	pages = {1--19},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/AIXFNULE/Bishop - 2020 - The psychology of experimental psychologists Over.pdf:application/pdf},
}

@article{simmons2011,
	title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976},
	shorttitle = {False-{Positive} {Psychology}},
	url = {https://doi.org/10.1177/0956797611417632},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2021-03-01},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	note = {Publisher: SAGE Publications Inc},
	keywords = {disclosure, methodology, motivated reasoning, publication},
	pages = {1359--1366},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/WAHA29FP/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf:application/pdf},
}

@article{bishop2016,
	title = {Problems in using p-curve analysis and text-mining to detect rate of p-hacking and evidential value},
	volume = {4},
	issn = {2167-8359},
	url = {https://peerj.com/articles/1715},
	doi = {10.7717/peerj.1715},
	abstract = {Background. The p-curve is a plot of the distribution of p-values reported in a set of scientific studies. Comparisons between ranges of p-values have been used to evaluate fields of research in terms of the extent to which studies have genuine evidential value, and the extent to which they suffer from bias in the selection of variables and analyses for publication, p-hacking. Methods. p-hacking can take various forms. Here we used R code to simulate the use of ghost variables, where an experimenter gathers data on several dependent variables but reports only those with statistically significant effects. We also examined a text-mined dataset used by Head et al. (2015) and assessed its suitability for investigating p-hacking. Results. We show that when there is ghost p-hacking, the shape of the p-curve depends on whether dependent variables are intercorrelated. For uncorrelated variables, simulated p-hacked data do not give the “p-hacking bump” just below .05 that is regarded as evidence of p-hacking, though there is a negative skew when simulated variables are inter-correlated. The way p-curves vary according to features of underlying data poses problems when automated text mining is used to detect p-values in heterogeneous sets of published papers. Conclusions. The absence of a bump in the p-curve is not indicative of lack of p-hacking. Furthermore, while studies with evidential value will usually generate a right-skewed p-curve, we cannot treat a right-skewed p-curve as an indicator of the extent of evidential value, unless we have a model specific to the type of p-values entered into the analysis. We conclude that it is not feasible to use the p-curve to estimate the extent of p-hacking and evidential value unless there is considerable control over the type of data entered into the analysis. In particular, p-hacking with ghost variables is likely to be missed.},
	language = {en},
	urldate = {2021-03-28},
	journal = {PeerJ},
	author = {Bishop, D. V. M. and Thompson, Paul A.},
	month = feb,
	year = {2016},
	note = {Publisher: PeerJ Inc.},
	pages = {e1715},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/8N5CDMZJ/Bishop and Thompson - 2016 - Problems in using p-curve analysis and text-mining.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/E3B8HCDM/1715.html:text/html},
}

@article{bishop2019,
	title = {Rein in the four horsemen of irreproducibility},
	volume = {568},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-019-01307-2},
	doi = {10.1038/d41586-019-01307-2},
	abstract = {Dorothy Bishop describes how threats to reproducibility, recognized but unaddressed for decades, might finally be brought under control.},
	language = {en},
	number = {7753},
	urldate = {2021-04-25},
	journal = {Nature},
	author = {Bishop, D. V. M.},
	month = apr,
	year = {2019},
	note = {Number: 7753
Publisher: Nature Publishing Group},
	pages = {435--435},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/D3MMHU64/Bishop - 2019 - Rein in the four horsemen of irreproducibility.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/JFX88ZT8/d41586-019-01307-2.html:text/html},
}

@article{greenwald1975,
	title = {Consequences of prejudice against the null hypothesis},
	volume = {82},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/h0076157},
	abstract = {Examined the consequences of prejudice against accepting the null hypothesis through (a) a mathematical model intended to stimulate the research-publication process and (b) case studies of apparent erroneous rejections of the null hypothesis in published psychological research. The input parameters for the model characterize investigators' probabilities of selecting a problem for which the null hypothesis is true, of reporting, following up on, or abandoning research when data do or do not reject the null hypothesis, and they characterize editors' probabilities of publishing manuscripts concluding in favor of or against the null hypothesis. With estimates of the input parameters based on a questionnaire survey of 75 social psychologists, the model output indicates a dysfunctional research-publication system. Particularly, the model indicates that there may be relatively few publications on problems for which the null hypothesis is (at least to a reasonable approximation) true, and of these, a high proportion will erroneously reject the null hypothesis. The case studies provide additional support for this conclusion. It is concluded that research traditions and customs of discrimination against accepting the null hypothesis may be very detrimental to research progress. (44 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Bulletin},
	author = {Greenwald, Anthony G.},
	year = {1975},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Experimentation, Null Hypothesis Testing, Consequence, Mathematical Modeling},
	pages = {1--20},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/CJ4YJ6Y2/Greenwald - 1975 - Consequences of prejudice against the null hypothe.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/JUYISGWX/1975-08612-001.html:text/html},
}

@article{saul2021,
	title = {A {Randomized} {Case} {Series} {Approach} to {Testing} {Efficacy} of {Interventions} for {Minimally} {Verbal} {Autistic} {Children}},
	volume = {12},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.621920/full},
	doi = {10.3389/fpsyg.2021.621920},
	abstract = {Background: Randomized Controlled Trials (RCTs) are the gold standard for assessing whether an intervention is effective; however, they require large sample sizes in order to detect small effects. For rare or complex populations, we advocate a case series approach as a more realistic and useful first step for intervention evaluation. We consider the importance of randomization to such designs, and advocate for the use of Randomization Tests and Between Case Effect Sizes to provide a robust and statistically powerful evaluation of outcomes. In this tutorial, we describe the method, procedures, and analysis code necessary to conduct robust single case series, using an empirical example with minimally verbal autistic children. Method: We applied a pre-registered (https://osf.io/9gvbs) randomized baseline design with between-case effect size to a case series (n=19), to test the efficacy of a novel, parent-mediated, app-based speech production intervention (BabbleBooster) for minimally verbal autistic children. Parent-rated probe scores were used to densely sample performance accuracy over time. Results: Parents were able to reliably code their children’s speech productions using BabbleBooster. A non-significant Randomization Test and small Between-Case Effect Size (d=0.267), suggested there was no evidence that BabbleBooster improved speech production in minimally verbal autistic children, relative to baseline scores, during this brief period of intervention. Conclusion: The current analyses exemplify a more robust approach to examining treatment effects in rare or complex populations, where RCT may be difficult or premature to implement. To facilitate adoption of this method by researchers and practitioners, we provide analysis code that can be adapted using open source R packages. Future studies could use this case series design to evaluate interventions aiming to improve speech and language outcomes for minimally verbal autistic children, and other heterogeneous and hard to reach populations.},
	language = {English},
	urldate = {2021-05-25},
	journal = {Frontiers in Psychology},
	author = {Saul, Jo and Norbury, Courtenay},
	year = {2021},
	note = {Publisher: Frontiers},
	keywords = {Speech, autism, intervention, minimally verbal, Parent-mediated, Randomization, Single case design},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/LVSWD8YD/Saul and Norbury - 2021 - A Randomized Case Series Approach to Testing Effic.pdf:application/pdf},
}

@book{wiig1992,
	title = {Celf - {Preschool}},
	isbn = {978-0-15-803380-8},
	language = {English},
	publisher = {Psychological Corporation},
	author = {Wiig, Elisabeth and Secord, Wayne and Semel, Eleanor},
	month = apr,
	year = {1992},
}

@misc{zotero-986,
	title = {Clinical {Evaluation} of {Language} {Fundamentals} - {Fifth} {Edition} ({CELF}-5 {UK}) {\textbar} {Pearson} {Assessment}},
	url = {https://www.pearsonclinical.co.uk/Psychology/ChildCognitionNeuropsychologyandLanguage/ChildLanguage/celf-5/clinical-evaluation-of-language-fundamentals-fifth-edition-celf-5.aspx?gclid=CjwKCAjwoZWHBhBgEiwAiMN66ZCgI2D45ubBirWCEKjtU6y87WyBi_4zgheGsgkBAQYfUkduPLMUdBoC2W8QAvD_BwE},
	urldate = {2021-07-07},
	file = {Clinical Evaluation of Language Fundamentals - Fifth Edition (CELF-5 UK) | Pearson Assessment:/Users/dorothybishop/Zotero/storage/JE369QRV/clinical-evaluation-of-language-fundamentals-fifth-edition-celf-5.html:text/html},
}

@book{wiig2006,
	address = {London},
	title = {{CELF}-{Preschool} 2 {UK}},
	url = {https://www.pearsonclinical.co.uk/Psychology/ChildCognitionNeuropsychologyandLanguage/ChildLanguage/CELF-Preschool2UK/CELF-Preschool2UK.aspx},
	urldate = {2021-07-07},
	publisher = {Pearson Assessment},
	author = {Wiig, Elisabeth H and Secord, Wayne and Semel, Eleanor},
	year = {2006},
	file = {CELF-Preschool 2 UK | Pearson Assessment:/Users/dorothybishop/Zotero/storage/5QTE3E8E/CELF-Preschool2UK.html:text/html},
}

@book{bricker1999,
	address = {Baltimore},
	title = {Ages and {Stages} {Questionnaires}: {A} parent-completed, child-monitoring system, 2nd ed.},
	publisher = {Paul H. Brookes},
	author = {Bricker, D and Squires, J},
	year = {1999},
}

@article{schmitt2017,
	title = {Establishing {Language} {Benchmarks} for {Children} {With} {Typically} {Developing} {Language} and {Children} {With} {Language} {Impairment}},
	volume = {60},
	issn = {1558-9102},
	doi = {10.1044/2016_JSLHR-L-15-0273},
	abstract = {Purpose: Practitioners, researchers, and policymakers (i.e., stakeholders) have vested interests in children's language growth yet currently do not have empirically driven methods for measuring such outcomes. The present study established language benchmarks for children with typically developing language (TDL) and children with language impairment (LI) from 3 to 9 years of age.
Method: Effect sizes for grammar, vocabulary, and overall language were calculated for children with TDL (n = 20,018) using raw score means and standard deviations from 8 norm-referenced measures of language. Effect sizes for children with LI were calculated using fall and spring norm-referenced language measures for 497 children with LI receiving business-as-usual therapy in the public schools.
Results: Considerable variability was found in expected change across both samples of children over time, with preschoolers exhibiting larger effect sizes (d = 0.82 and 0.70, respectively) compared with school-age children (d = 0.49 and 0.55, respectively).
Conclusions: This study provides a first step toward establishing empirically based language benchmarks for children. These data offer stakeholders an initial tool for setting goals based on expected growth (practitioners), making informed decisions on language-based curricula (policymakers), and measuring effectiveness of intervention research (researchers).},
	language = {eng},
	number = {2},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Schmitt, Mary Beth and Logan, Jessica A. R. and Tambyraja, Sherine R. and Farquharson, Kelly and Justice, Laura M.},
	month = feb,
	year = {2017},
	pmid = {28124066},
	keywords = {Humans, Child, Language Development Disorders, Language Tests, Child, Preschool, Language Therapy, Linguistics, Child Language, Cohort Studies, Reference Values},
	pages = {364--378},
}

@book{fielding1996,
	address = {London},
	title = {Bridget {Jones}' {Diary}},
	isbn = {0-670-88072-8},
	publisher = {Picador},
	author = {Fielding, Helen},
	year = {1996},
}

@book{lord1968,
	title = {Stastistical theories of mental test scores},
	publisher = {Addison-Wesley},
	author = {Lord, F. M. and Novick, M. R. and Birnbaum, Allan},
	year = {1968},
}

@article{ogieladianea.2021,
	title = {Norm-{Referenced} {Language} {Test} {Selection} {Practices} for {Elementary} {School} {Children} {With} {Suspected} {Developmental} {Language} {Disorder}},
	volume = {52},
	url = {https://pubs.asha.org/doi/full/10.1044/2020_LSHSS-19-00067},
	doi = {10.1044/2020_LSHSS-19-00067},
	abstract = {Purpose
      Standardized norm-referenced tests are an important aspect of language assessment
         for school-age children. This study explored the language test selection practices
         of school-based speech-language pathologists (SLPs) working with elementary school
         children suspected of having developmental language disorder. Specifically, we investigated
         which tests were most commonly selected as clinicians' first-choice and follow-up
         tests, which factors impacted their test selection decisions, and what sources of
         information they used to determine the psychometric quality of tests.
      
      Method
      School-based SLPs completed a web-based questionnaire regarding their use of norm-referenced
         language tests. A total of 370 elementary school SLPs completed the questionnaire.
      
      Results
      The vast majority of participants indicated that omnibus language tests are their
         first choice of test. For follow-up tests, participants selected semantics tests,
         especially single-word vocabulary tests, significantly more often than tests of pragmatics,
         processing skills, and morphology/syntax. Participants identified multiple factors
         as affecting test selection, including availability, familiarity, psychometric features,
         and others. Although more SLPs reported using data-based than subjective sources of
         information to judge the psychometric quality of tests, a substantial proportion reported
         that they relied on subjective sources.
      
      Conclusions
      Clinicians have a strong preference for using omnibus language tests. Follow-up test
         selection does not appear to align with the language difficulties most associated
         with developmental language disorder. The substantial use of subjective information
         about psychometric qualities of tests suggests that many SLPs may not attend to the
         technical meanings of terms such as validity, reliability, and diagnostic accuracy.
         These results indicate a need for improvement in evidence-based language assessment
         practices.
      
      Supplemental Material
      https://doi.org/10.23641/asha.13022471},
	number = {1},
	urldate = {2021-07-08},
	journal = {Language, Speech, and Hearing Services in Schools},
	author = {{Ogiela Diane A.} and {Montzka Jennifer L.}},
	month = jan,
	year = {2021},
	note = {Publisher: American Speech-Language-Hearing Association},
	pages = {288--303},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/G5MN3G7M/Ogiela Diane A. and Montzka Jennifer L. - 2021 - Norm-Referenced Language Test Selection Practices .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/LN9GZYGB/2020_LSHSS-19-00067.html:text/html},
}

@article{nitido2020,
	title = {Diagnosis of {Developmental} {Language} {Disorder} in {Research} {Studies}},
	volume = {63},
	copyright = {Copyright American Speech-Language-Hearing Association Aug 2020},
	url = {https://www.proquest.com/docview/2471511328/abstract/C7D557B8F82F441CPQ/1},
	doi = {http://dx.doi.org/10.1044/2020_JSLHR-20-00091},
	abstract = {Purpose: The aim of this study was to investigate the extent to which researchers in the field of developmental language disorder are utilizing validated methods to diagnose their research participants. Method: We examined 90 research articles published from 2015 to 2019 that included English-speaking participants from the United States who were identified as having a developmental language disorder or specific language impairment. From these articles, we identified the tests and measures used to identify participants and classify them as healthy or impaired. We then consulted the test manuals and the literature to find information on sensitivity and specificity of the test and the evidence-based cut score that maximized identification accuracy. Results: Of the 90 articles examined, 38 (42\%) were found to reflect validated diagnostic methods, and 51 (58\%) did not. Conclusion: Our results illustrate that validated methods are used less than half of the time even by those who should have a high level of expertise and despite calls for increasing scientific rigor in research practices.},
	language = {English},
	number = {8},
	urldate = {2021-07-08},
	journal = {Journal of Speech, Language and Hearing Research (Online)},
	author = {Nitido, Hallie and Plante, Elena},
	month = aug,
	year = {2020},
	note = {Num Pages: 2777-2788
Place: Rockville, United States
Publisher: American Speech-Language-Hearing Association
Section: Research Note},
	keywords = {Specific language impairment, Handicapped--Hearing Impaired, Language disorders, Medical Sciences--Otorhinolaryngology, Standard scores, Accuracy, Clinical medicine, Developmental disabilities, Quantitative psychology, Research},
	pages = {2777--2788},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/BWZ62FWR/Nitido and Plante - 2020 - Diagnosis of Developmental Language Disorder in Re.pdf:application/pdf},
}

@article{denman2017,
	title = {Psychometric {Properties} of {Language} {Assessments} for {Children} {Aged} 4–12 {Years}: {A} {Systematic} {Review}},
	volume = {8},
	issn = {1664-1078},
	shorttitle = {Psychometric {Properties} of {Language} {Assessments} for {Children} {Aged} 4–12 {Years}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01515/full},
	doi = {10.3389/fpsyg.2017.01515},
	abstract = {Abstract Introduction: Standardized assessments are widely used by speech pathologists in clinical and research settings to evaluate the language abilities of school-aged children and inform decisions about diagnosis, eligibility for services and intervention. Given the significance of these decisions, it is important that assessments have sound psychometric properties. Objective: The aim of this systematic review was to examine the psychometric quality of currently available comprehensive language assessments for school-aged children and identify assessments with the best evidence for use. Methods: Using the PRISMA framework as a guideline, a search of five databases and a review of websites and textbooks was undertaken to identify language assessments and published material on the reliability and validity of these assessments. The methodological quality of selected studies was evaluated using the COSMIN taxonomy and checklist. Results: Fifteen assessments were evaluated. For most assessments evidence of hypothesis testing (convergent and discriminant validity) was identified; with a smaller number of assessments having some evidence of reliability and content validity. No assessments presented with evidence of structural validity, internal consistency or error measurement. Overall, all assessments were identified as having limitations with regards to evidence of psychometric quality. Conclusions: Further research is required to provide good evidence of psychometric quality for currently available language assessments. Of the assessments evaluated, the Assessment of Literacy and Language, the Clinical Evaluation of Language Fundamentals- 5th Edition, the Clinical Evaluation of Language Fundamentals – Preschool: 2nd Edition and the Preschool Language Scales – 5th Edition presented with most evidence and are thus recommended for use.},
	language = {English},
	urldate = {2021-07-08},
	journal = {Frontiers in Psychology},
	author = {Denman, Deborah and Speyer, Renée and Munro, Natalie and Pearce, Wendy M. and Chen, Yu-Wei and Cordier, Reinie},
	year = {2017},
	note = {Publisher: Frontiers},
	keywords = {assessment reliability, assessment validity, Language assessment, Language impairment, psychometric properties},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/4Z74WMQS/Denman et al. - 2017 - Psychometric Properties of Language Assessments fo.pdf:application/pdf},
}

@article{mokkink2010,
	title = {The {COSMIN} study reached international consensus on taxonomy, terminology, and definitions of measurement properties for health-related patient-reported outcomes},
	volume = {63},
	issn = {0895-4356},
	url = {https://www.sciencedirect.com/science/article/pii/S0895435610000909},
	doi = {10.1016/j.jclinepi.2010.02.006},
	abstract = {Objective
Lack of consensus on taxonomy, terminology, and definitions has led to confusion about which measurement properties are relevant and which concepts they represent. The aim was to clarify and standardize terminology and definitions of measurement properties by reaching consensus among a group of experts and to develop a taxonomy of measurement properties relevant for evaluating health instruments.
Study Design and Setting
An international Delphi study with four written rounds was performed. Participating experts had a background in epidemiology, statistics, psychology, and clinical medicine. The panel was asked to rate their (dis)agreement about proposals on a five-point scale. Consensus was considered to be reached when at least 67\% of the panel agreed.
Results
Of 91 invited experts, 57 agreed to participate and 43 actually participated. Consensus was reached on positions of measurement properties in the taxonomy (68–84\%), terminology (74–88\%, except for structural validity [56\%]), and definitions of measurement properties (68–88\%). The panel extensively discussed the positions of internal consistency and responsiveness in the taxonomy, the terms “reliability” and “structural validity,” and the definitions of internal consistency and reliability.
Conclusions
Consensus on taxonomy, terminology, and definitions of measurement properties was reached. Hopefully, this will lead to a more uniform use of terms and definitions in the literature on measurement properties.},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {Journal of Clinical Epidemiology},
	author = {Mokkink, Lidwine B. and Terwee, Caroline B. and Patrick, Donald L. and Alonso, Jordi and Stratford, Paul W. and Knol, Dirk L. and Bouter, Lex M. and de Vet, Henrica C. W.},
	month = jul,
	year = {2010},
	keywords = {Classification, Psychometrics, Delphi technique, Outcome assessment, Quality of life, Questionnaire, Terminology},
	pages = {737--745},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/2FDX4ZX4/Mokkink et al. - 2010 - The COSMIN study reached international consensus o.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/SCEVHV4S/S0895435610000909.html:text/html},
}

@article{reise2005,
	title = {Item {Response} {Theory}: {Fundamentals}, {Applications}, and {Promise} in {Psychological} {Research}},
	volume = {14},
	issn = {0963-7214},
	shorttitle = {Item {Response} {Theory}},
	url = {https://doi.org/10.1111/j.0963-7214.2005.00342.x},
	doi = {10.1111/j.0963-7214.2005.00342.x},
	abstract = {Item response theory (IRT) is an increasingly popular approach to the development, evaluation, and administration of psychological measures. We introduce, first, three IRT fundamentals: (a) item response functions, (b) information functions, and (c) invariance. We next illustrate how IRT modeling can improve the quality of psychological measurement. Available evidence suggests that the differences between IRT and traditional psychometric methods are not trivial; IRT applications can improve the precision and validity of psychological research across a wide range of subjects.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Current Directions in Psychological Science},
	author = {Reise, Steven P. and Ainsworth, Andrew T. and Haviland, Mark G.},
	month = apr,
	year = {2005},
	note = {Publisher: SAGE Publications Inc},
	keywords = {classical test theory, item response theory, psychometrics, scaling},
	pages = {95--101},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/CH5GV4Q6/Reise et al. - 2005 - Item Response Theory Fundamentals, Applications, .pdf:application/pdf},
}

@book{torgesen1999,
	address = {Austin, TX},
	title = {Test of {Word} {Reading} {Efficiency}},
	url = {https://www.pearsonclinical.co.uk/Psychology/ChildCognitionNeuropsychologyandLanguage/ChildLanguage/TOWRE2/TestofWordReadingEfficiencySecondEdition.aspx},
	urldate = {2021-07-12},
	publisher = {Pro-Ed},
	author = {Torgesen, Joseph K and Wagner, Richard K and Rashotte, Carole A.},
	year = {1999},
	file = {Test of Word Reading Efficiency - Second Edition (TOWRE-2) | Pearson Assessment:/Users/dorothybishop/Zotero/storage/9BIVV5PR/TestofWordReadingEfficiencySecondEdition.html:text/html},
}

@article{bishop1987,
	title = {Language-{Impaired} 4-{Year}-{Olds}},
	volume = {52},
	url = {https://pubs.asha.org/doi/10.1044/jshd.5202.156},
	doi = {10.1044/jshd.5202.156},
	abstract = {In a prospective, longitudinal study, 87 language-impaired children were assessed
         at the ages of 4, 4½, and 5½ years on a battery of language measures. In 37\% of children,
         who were termed the "good outcome group," the language disorder had resolved by the
         age of 5½ years so that children were indistinguishable from a control group. If one
         restricted consideration only to those 68 children whose nonverbal ability was within
         normal limits, the figure rose to 44\%. Outcome for individual children (good or poor)
         could be predicted with 90\% accuracy on the basis of test measures obtained at 4 years.
         The best predictor was ability to tell back a simple story to pictures. The one language
         measure that did not relate to outcome was phonological competence.},
	number = {2},
	urldate = {2021-07-12},
	journal = {Journal of Speech and Hearing Disorders},
	author = {BIshop, D V M and Edmundson, A},
	month = may,
	year = {1987},
	note = {Publisher: American Speech-Language-Hearing Association},
	pages = {156--173},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/E2U8HVEX/jshd.5202.html:text/html},
}

@book{renfrew1967,
	address = {Oxford},
	title = {Action {Picture} {Test}},
	url = {https://www.routledge.com/Action-Picture-Test/peechmark-Renfrew/p/book/9781138586208},
	abstract = {*The Renfrew Action Picture Test cards are now available for free, to assist with online assessments and the ease of administrating the test, but in order to fully score the RAPT the pack will need to be purchased. You can find the downloadable cards under ‘Support Materials’ on the Routledge.com product page*

Since its first publication in 1967, the Renfrew Action Picture Test has been a reach-for assessment used by a range of professionals dedicated to the speech and language development},
	language = {en},
	urldate = {2021-07-12},
	publisher = {Catherine Renfrew},
	author = {Renfrew, Catherine},
	year = {1967},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/FUPVGH4D/9781138586208.html:text/html},
}

@book{renfrew2010,
	title = {Bus {Story} {Test}: {Revised} {Edition}},
	shorttitle = {Bus {Story} {Test}},
	url = {https://www.routledge.com/Bus-Story-Test-Revised-Edition/Renfrew/p/book/9780863888083},
	abstract = {The age level of consecutive speech used in retelling a story can be assessed from the information content, sentence length and grammatical usage of this revised test. The test includes a coloured picture story book, a scoring form to photocopy and a manual, but also requires the use of audio recording equipment. Catherine Renfrew's three tests have been used for many years and provide a means of assessing children's speech and language. All tests are suitable for use with 3-8 year olds are norm},
	language = {en},
	urldate = {2021-07-12},
	publisher = {Routledge},
	author = {Renfrew, Catherine},
	year = {2010},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/WXQ7ZTHE/9780863888083.html:text/html},
}

@book{crystal1977,
	address = {London},
	title = {The {Grammatical} {Analysis} of {Language} {Disability}: {A} {Procedure} for {Assessment} and {Remediation}},
	publisher = {Edward Arnold},
	author = {Crystal, David and Fletcher, Paul and Garman, Michael},
	year = {1977},
}

@article{loeb2001,
	title = {Language changes associated with {Fast} {ForWord}-language: {Evidence} from case studies},
	volume = {10},
	issn = {1558-9110(Electronic),1058-0360(Print)},
	shorttitle = {Language changes associated with {Fast} {ForWord}-language},
	doi = {10.1044/1058-0360(2001/020)},
	abstract = {The Scientific Learning Corporation claims that Fast ForWord-Language (FFW-L) yields 1-1/2 to 3 years language gain over a 6-week period. The authors evaluated various aspects of this claim by measuring the language changes of 4 children (aged 5 yrs 6 mo to 8 yrs 1 mo) who received FFW-L language intervention in their homes. Language change was assessed immediately following intervention and 3 months later, using standardized language measures, spontaneous measures of syntactic complexity, reading measures, pragmatic measures, and parent and teacher reports. Three of the 4 children successfully completed FFW-L, and all made gains on some of the same standardized measures used by P. Tallal et al (1996), although the improvements the authors observed were generally smaller than those previously reported. All children also made gains on measures of pragmatic performance. However, very few changes were observed in the children's Developmental Sentence Scores. Parents and teachers did not report many differences in performance after intervention; however, parental satisfaction with the program was generally high. 61\% of the gains observed at posttesting were maintained 3 months following intervention. Significant positive change occurred on 10\% of the items. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {American Journal of Speech-Language Pathology},
	author = {Loeb, Diane Frome and Stoke, Christene and Fey, Marc E.},
	year = {2001},
	note = {Place: US
Publisher: American Speech-Language-Hearing Assn},
	keywords = {Communication Disorders, Computer Applications, Computer Software, Language Disorders},
	pages = {216--230},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/AHF8NP79/2001-11320-003.html:text/html},
}

@article{bull2007,
	title = {Sunflower therapy for children with specific learning difficulties (dyslexia): a randomised, controlled trial},
	volume = {13},
	issn = {1744-3881},
	shorttitle = {Sunflower therapy for children with specific learning difficulties (dyslexia)},
	doi = {10.1016/j.ctcp.2006.07.003},
	abstract = {The aim of the study was to determine the clinical and perceived effectiveness of the Sunflower therapy in the treatment of childhood dyslexia. The Sunflower therapy includes applied kinesiology, physical manipulation, massage, homeopathy, herbal remedies and neuro-linguistic programming. A multi-centred, randomised controlled trial was undertaken with 70 dyslexic children aged 6-13 years. The research study aimed to test the research hypothesis that dyslexic children 'feel better' and 'perform better' as a result of treatment by the Sunflower therapy. Children in the treatment group and the control group were assessed using a battery of standardised cognitive, Literacy and self-esteem tests before and after the intervention. Parents of children in the treatment group gave feedback on their experience of the Sunflower therapy. Test scores were compared using the Mann Whitney, and Wilcoxon statistical tests. While both groups of children improved in some of their test scores over time, there were no statistically significant improvements in cognitive or Literacy test performance associated with the treatment. However, there were statistically significant improvements in academic self-esteem, and reading self-esteem, for the treatment group. The majority of parents (57.13\%) felt that the Sunflower therapy was effective in the treatment of learning difficulties. Further research is required to verify these findings, and should include a control group receiving a dummy treatment to exclude placebo effects.},
	language = {eng},
	number = {1},
	journal = {Complementary Therapies in Clinical Practice},
	author = {Bull, Leona},
	month = feb,
	year = {2007},
	pmid = {17210507},
	keywords = {Female, Humans, Male, Child, Dyslexia, Acupressure, Combined Modality Therapy, Complementary Therapies, Dietary Supplements, Kinesiology, Applied, Manipulation, Osteopathic, Neurolinguistic Programming, Phytotherapy},
	pages = {15--24},
}

@book{brown1973,
	address = {Cambridge, MA},
	title = {A {First} {Language} — {Roger} {Brown}},
	url = {https://www.hup.harvard.edu/catalog.php?isbn=9780674732469},
	abstract = {For many years, Brown and his colleagues have studied the developing language of pre-school children -- the language that ultimately will permit them to understand themselves and their world. This longitudinal research records the conversational performances of three children, studying semantic and grammatical aspects of their language development.},
	language = {en},
	urldate = {2021-07-12},
	publisher = {Harvard University Press},
	author = {Brown, Roger},
	year = {1973},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/BTWCCNJ6/catalog.html:text/html},
}

@article{aksayli2019,
	title = {The cognitive and academic benefits of {Cogmed}: {A} meta-analysis},
	volume = {27},
	issn = {1747-938X},
	shorttitle = {The cognitive and academic benefits of {Cogmed}},
	url = {https://www.sciencedirect.com/science/article/pii/S1747938X18303658},
	doi = {10.1016/j.edurev.2019.04.003},
	abstract = {Cogmed Working Memory Training (CWMT) is a commercial cognitive-training program designed to foster working-memory capacity. Enhanced working-memory capacity is then supposed to increase one's overall cognitive function and academic achievement. This meta-analysis investigates the effects of CWMT on cognitive and academic outcomes. The inclusion criteria were met by 50 studies (637 effect sizes). Highly consistent near-zero effects were estimated in far-transfer measures of cognitive ability (e.g., attention and intelligence) and academic achievement (language ability and mathematics). By contrast, slightly heterogeneous small to medium effects were observed in memory tasks (i.e., near transfer). Moderator analysis showed that these effects were weaker for near-transfer measures not directly related to the trained tasks. These results highlight that, while near transfer occurs regularly, far transfer is rare or, possibly, inexistent. Transfer thus appears to be a function of the degree of overlap between trained tasks and outcome tasks.},
	language = {en},
	urldate = {2021-07-12},
	journal = {Educational Research Review},
	author = {Aksayli, N. Deniz and Sala, Giovanni and Gobet, Fernand},
	month = jun,
	year = {2019},
	keywords = {Meta-analysis, Cogmed, Transfer, Working memory training},
	pages = {229--243},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/YILZ83YJ/Aksayli et al. - 2019 - The cognitive and academic benefits of Cogmed A m.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/R73D7Z7U/S1747938X18303658.html:text/html},
}

@article{ratner2016,
	title = {Your {Laptop} to the {Rescue}: {Using} the {Child} {Language} {Data} {Exchange} {System} {Archive} and {CLAN} {Utilities} to {Improve} {Child} {Language} {Sample} {Analysis}},
	volume = {37},
	issn = {1098-9056},
	shorttitle = {Your {Laptop} to the {Rescue}},
	doi = {10.1055/s-0036-1580742},
	abstract = {In this article, we review the advantages of language sample analysis (LSA) and explain how clinicians can make the process of LSA faster, easier, more accurate, and more insightful than LSA done "by hand" by using free, available software programs such as Computerized Language Analysis (CLAN). We demonstrate the utility of CLAN analysis in studying the expressive language of a very large cohort of 24-month-old toddlers tracked in a recent longitudinal study; toddlers in particular are the most likely group to receive LSA by clinicians, but existing reference "norms" for this population are based on fairly small cohorts of children. Finally, we demonstrate how a CLAN utility such as KidEval can now extract potential normative data from the very large number of corpora now available for English and other languages at the Child Language Data Exchange System project site. Most of the LSA measures that we studied appear to show developmental profiles suggesting that they may be of specifically higher value for children at certain ages, because they do not show an even developmental trajectory from 2 to 7 years of age.},
	language = {eng},
	number = {2},
	journal = {Seminars in Speech and Language},
	author = {Ratner, Nan Bernstein and MacWhinney, Brian},
	month = may,
	year = {2016},
	pmid = {27111268},
	keywords = {Humans, Language, Child, Child Language, Information Dissemination, Longitudinal Studies},
	pages = {74--84},
}

@article{forsythe2019,
	title = {Patient {Engagement} {In} {Research}: {Early} {Findings} {From} {The} {Patient}-{Centered} {Outcomes} {Research} {Institute}},
	volume = {38},
	issn = {0278-2715},
	shorttitle = {Patient {Engagement} {In} {Research}},
	url = {https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2018.05067},
	doi = {10.1377/hlthaff.2018.05067},
	abstract = {Charged with ensuring that research produces useful evidence to inform health decisions, the Patient-Centered Outcomes Research Institute (PCORI) requires investigators to engage patients and other health care stakeholders, such as clinicians and payers, in the research process. Many PCORI studies result in articles published in peer-reviewed journals that detail research findings and engagement’s role in research. To inform practices for engaging patients and others as research partners, we analyzed 126 articles that described engagement approaches and contributions to research. PCORI projects engaged patients and others as consultants and collaborators in determining the study design, selecting study outcomes, tailoring interventions to meet patients’ needs and preferences, and enrolling participants. Many articles reported that engagement provided valuable contributions to research feasibility, acceptability, rigor, and relevance, while a few noted trade-offs of engagement. The findings suggest that engagement can support more relevant research through better alignment with patients’ and clinicians’ real-world needs and concerns.},
	number = {3},
	urldate = {2021-07-26},
	journal = {Health Affairs},
	author = {Forsythe, Laura P. and Carman, Kristin L. and Szydlowski, Victoria and Fayish, Lauren and Davidson, Laurie and Hickam, David H. and Hall, Courtney and Bhat, Geeta and Neu, Denese and Stewart, Lisa and Jalowsky, Maggie and Aronson, Naomi and Anyanwu, Chinenye Ursla},
	month = mar,
	year = {2019},
	note = {Publisher: Health Affairs},
	pages = {359--367},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/2LQV6S87/Forsythe et al. - 2019 - Patient Engagement In Research Early Findings Fro.pdf:application/pdf},
}

@article{dockrell2015,
	title = {Measurement {Issues}: {Assessing} language skills in young children},
	volume = {20},
	issn = {1475-3588},
	shorttitle = {Measurement {Issues}},
	url = {https://acamh.onlinelibrary.wiley.com/doi/abs/10.1111/camh.12072},
	doi = {10.1111/camh.12072},
	abstract = {Background Language and communication skills are central to children's ability to engage in social relationships and access learning experiences. This paper identifies issues which practitioners and researchers should consider when assessing language skills. A range of current language assessments is reviewed. Key findings Current screening measures do not meet psychometric prerequisites to identify language problems. There are significant challenges in the interpretation of language assessments, where socioeconomic status, language status and dialect, hearing impairment and test characteristics impact results. Conclusions Psychometrically sound assessments of language are an essential component of developing effective and efficient interventions. The language trajectories of preschool children vary substantially; current screening measures have significant limitations. Composite measures of language performance are better indicators of language problems and disorders than single measures of component skills.},
	language = {en},
	number = {2},
	urldate = {2021-07-26},
	journal = {Child and Adolescent Mental Health},
	author = {Dockrell, Julie E. and Marshall, Chloë R.},
	year = {2015},
	note = {\_eprint: https://acamh.onlinelibrary.wiley.com/doi/pdf/10.1111/camh.12072},
	keywords = {Language, assessment, psychometrics, dynamic, preschool},
	pages = {116--125},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/AJDYINNM/Dockrell and Marshall - 2015 - Measurement Issues Assessing language skills in y.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/2MZNMZ3U/camh.html:text/html},
}

@article{ebbels2019,
	title = {Evidence-based pathways to intervention for children with language disorders},
	volume = {54},
	issn = {1368-2822},
	url = {https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcAuth=DOISource&SrcApp=WOS&KeyAID=10.1111%2F1460-6984.12387&DestApp=DOI&SrcAppSID=F5QzQ8a9YpOKqcBdgga&SrcJTitle=INTERNATIONAL+JOURNAL+OF+LANGUAGE+%26+COMMUNICATION+DISORDERS&DestDOIRegistrantName=Wiley+%28Blackwell+Publishing%29},
	doi = {10.1111/1460-6984.12387},
	abstract = {Background Paediatric speech and language therapist (SLT) roles often involve planning individualized intervention for specific children, working collaboratively with families and education staff, providing advice, training and coaching and raising awareness. A tiered approach to service delivery is currently recommended whereby services become increasingly specialized and individualized for children with greater needs. Aims To stimulate discussion regarding delivery of SLT services by examining evidence regarding the effectiveness of (1) intervention for children with language disorders at different tiers and (2) SLT roles within these tiers; and to propose an evidence-based model of SLT service delivery and a flowchart to aid clinical decision-making. Methods \& Procedures Meta-analyses and systematic reviews, together with controlled, peer-reviewed group studies where recent systematic reviews were not available, of interventions for children with language disorders are discussed, alongside the differing roles SLTs play in these interventions. Gaps in the evidence base are highlighted. Main Contribution The service-delivery model presented resembles the tiered model commonly used in education services, but divides individualized (Tier 3) services into Tier 3A: indirect intervention delivered by non-SLTs, and Tier 3B: direct intervention by an SLT. We report evidence for intervention effectiveness, which children might best be served by each tier, the role SLTs could take within each tier and the effectiveness of these roles. Regarding universal interventions provided to all children (Tier 1) and those targeted at children with language weaknesses or vulnerabilities (Tier 2), there is growing evidence that approaches led by education services can be effective when staff are highly trained and well supported. There is currently limited evidence regarding additional benefit of SLT-specific roles at Tiers 1 and 2. With regard to individualized intervention (Tier 3), children with complex or pervasive language disorders can progress following direct individualized intervention (Tier 3B), whereas children with milder or less pervasive difficulties can make progress when intervention is managed by an SLT, but delivered indirectly by others (Tier 3A), provided they are well trained and supported, and closely monitored. Conclusions \& Implications SLTs have a contribution to make at all tiers, but where prioritization for clinical services is a necessity, we need to establish the relative benefits and cost-effectiveness at each tier. Good evidence exists for SLTs delivering direct individualized intervention and we should ensure that this is available to children with pervasive and/or complex language disorders. In cases where service models are being provided which lack evidence, we strongly recommend that SLTs investigate the effectiveness of their approaches.},
	language = {English},
	number = {1},
	urldate = {2021-07-26},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Ebbels, Susan H. and McCartney, Elspeth and Slonims, Vicky and Dockrell, Julie E. and Norbury, Courtenay Frazier},
	month = feb,
	year = {2019},
	note = {Place: Hoboken
Publisher: Wiley
WOS:000454678800001},
	keywords = {intervention, clinical marker, communication outcomes, evidence based practice (EBP), joint attention intervention, language disorder, oral language, randomized controlled-trial, school-age-children, service   delivery models, vocabulary intervention, word   knowledge, young-children},
	pages = {3--19},
	file = {Accepted Version:/Users/dorothybishop/Zotero/storage/URTS9DXG/Ebbels et al. - 2019 - Evidence-based pathways to intervention for childr.pdf:application/pdf},
}

@article{levitt2011,
	title = {Was {There} {Really} a {Hawthorne} {Effect} at the {Hawthorne} {Plant}? {An} {Analysis} of the {Original} {Illumination} {Experiments}},
	volume = {3},
	issn = {1945-7782},
	shorttitle = {Was {There} {Really} a {Hawthorne} {Effect} at the {Hawthorne} {Plant}?},
	url = {https://www.aeaweb.org/articles?id=10.1257/app.3.1.224},
	doi = {10.1257/app.3.1.224},
	abstract = {The "Hawthorne effect" draws its name from a landmark set of studies conducted at the Hawthorne plant in the 1920s. The data from the first and most influential of these studies, the "Illumination Experiment," were never formally analyzed and were thought to have been destroyed. Our research has uncovered these data. Existing descriptions of supposedly remarkable data patterns prove to be entirely fictional. We do find more subtle manifestations of possible Hawthorne effects. We also propose a new means of testing for Hawthorne effects based on excess responsiveness to experimenter-
induced variations relative to naturally occurring variation. (JEL C90, J24, J28, M12, M54, N32)},
	language = {en},
	number = {1},
	urldate = {2021-07-27},
	journal = {American Economic Journal: Applied Economics},
	author = {Levitt, Steven D. and List, John A.},
	month = jan,
	year = {2011},
	keywords = {Canada: 1913-, Design of Experiments: General, Human Capital, Executive Compensation, Personnel Economics: Labor Management, Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S., Job Satisfaction, Labor Productivity, Safety, Occupational Choice, Related Public Policy, Personnel Management, Skills},
	pages = {224--238},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/25H6FQU2/Levitt and List - 2011 - Was There Really a Hawthorne Effect at the Hawthor.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/C5D8FVF7/articles.html:text/html},
}

@article{freedman1987,
	title = {Equipoise and the {Ethics} of {Clinical} {Research}},
	volume = {317},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJM198707163170304},
	doi = {10.1056/NEJM198707163170304},
	abstract = {THERE is widespread agreement that ethics requires that each clinical trial begin with an honest null hypothesis.1 , 2 In the simplest model, testing a new treatment B on a defined patient population P for which the current accepted treatment is A, it is necessary that the clinical investigator be in a state of genuine uncertainty regarding the comparative merits of treatments A and B for population P. If a physician knows that these treatments are not equivalent, ethics requires that the superior treatment be recommended. Following Fried, I call this state of uncertainty about the relative merits of A and B . . .},
	number = {3},
	urldate = {2021-07-27},
	journal = {New England Journal of Medicine},
	author = {Freedman, Benjamin},
	month = jul,
	year = {1987},
	pmid = {3600702},
	note = {Publisher: Massachusetts Medical Society
\_eprint: https://doi.org/10.1056/NEJM198707163170304},
	pages = {141--145},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/QEXBZQL4/Freedman - 1987 - Equipoise and the Ethics of Clinical Research.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/6DVI4Y3D/NEJM198707163170304.html:text/html},
}

@article{bishop2006,
	title = {Resistance of grammatical impairment to computerized comprehension training in children with specific and non-specific language impairments},
	volume = {41},
	issn = {1368-2822},
	doi = {10.1080/13682820500144000},
	abstract = {BACKGROUND: Receptive language impairments in school-age children have a poor prognosis, yet there is a dearth of research on effective interventions.
AIMS: Children's responses to a computerized grammatical training program were evaluated to consider whether repeated responding to spoken sentences with variable semantic content and the same syntactic structure would lead to consistent and fluent comprehension.
METHODS \& PROCEDURES: Children with receptive language impairments aged from 8 to 13 years were randomly assigned to three groups: Group S (n = 12) responded to reversible sentences in a computerized game, using speech stimuli with pauses before critical phrases. Group M (n = 12) had the same stimuli acoustically modified to lengthen and amplify dynamic portions of the signal. Group U (n = 9) was an untrained control group. On average, children in groups S and M completed over 1000 training trials, focusing on training comprehension of reversible sentences.
OUTCOMES \& RESULTS: Although responses speeded up over the course of training, and most children performed well above chance, accuracy typically remained below 95\% correct for constructions such as above/below and reversible active/passive. Trained groups did not differ from untrained children on language or auditory outcomes. There was no evidence that acoustically modified speech input enhanced comprehension.
CONCLUSIONS: Rote training of comprehension of reversible sentences does not seem to be an effective approach to remediating such problems. For most children, the pattern of performance suggested that the problem was not a lack of syntactic knowledge, bur rather limited processing capacity that led to failures of on-line computation of meaning.},
	language = {eng},
	number = {1},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Bishop, D. V. M. and Adams, C. V. and Rosen, S.},
	month = feb,
	year = {2006},
	pmid = {16272001},
	keywords = {Humans, Child, Language Development Disorders, Treatment Outcome, Speech, Adolescent, Language Therapy, Auditory Perception, Cognition, Discrimination Learning, Reaction Time, Speech Acoustics, Speech Discrimination Tests, Therapy, Computer-Assisted},
	pages = {19--40},
}

@article{bowen2020,
	title = {Independent research and the {Arrowsmith} {Program}},
	volume = {46},
	url = {http://www.onlinedigeditions.com/publication/?i=655062&p=54&pp=1&view=issueViewer},
	language = {en-US},
	number = {1},
	urldate = {2021-07-27},
	journal = {Perspectives on Language and Literacy},
	author = {Bowen, Caroline},
	year = {2020},
	pages = {47--54},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/WDRM8FH6/publication.html:text/html},
}

@article{steiner2012,
	title = {Issues and {Theoretical} {Constructs} {Regarding} {Parent} {Education} for {Autism} {Spectrum} {Disorders}},
	volume = {42},
	issn = {0162-3257},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3810158/},
	doi = {10.1007/s10803-011-1194-0},
	abstract = {Participation of parents of children with autism is commonplace in most comprehensive intervention programs, yet, there is limited research relating to the best practices in this area. This article provides an overview of parent education programs for young children with autism and details data-driven procedures which are associated with improved parent and child outcomes. In addition, we provide a troubleshooting guide based on the literature for professionals regarding a variety of complex issues which may arise during parent education.},
	number = {6},
	urldate = {2021-07-27},
	journal = {Journal of autism and developmental disorders},
	author = {Steiner, Amanda M. and Koegel, Lynn K. and Koegel, Robert L. and Ence, Whitney A.},
	month = jun,
	year = {2012},
	pmid = {21336525},
	pmcid = {PMC3810158},
	pages = {10.1007/s10803--011--1194--0},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/2DTFM2EX/Steiner et al. - 2012 - Issues and Theoretical Constructs Regarding Parent.pdf:application/pdf},
}

@article{weiss1991,
	title = {Stressors experienced by family caregivers of children with pervasive developmental disorders {\textbar} {SpringerLink}},
	volume = {21},
	url = {https://link.springer.com/article/10.1007/BF00705906},
	urldate = {2021-07-27},
	journal = {Child Psychiatry and Human Development},
	author = {Weiss, S},
	year = {1991},
	pages = {203--216},
	file = {Stressors experienced by family caregivers of children with pervasive developmental disorders | SpringerLink:/Users/dorothybishop/Zotero/storage/7P9BPDTX/BF00705906.html:text/html},
}

@article{burgoyne2018,
	title = {Evaluation of a parent-delivered early language enrichment programme: evidence from a randomised controlled trial},
	volume = {59},
	issn = {1469-7610},
	shorttitle = {Evaluation of a parent-delivered early language enrichment programme},
	doi = {10.1111/jcpp.12819},
	abstract = {BACKGROUND: It is widely believed that increasing parental involvement can improve children's educational outcomes although we lack good evidence for such claims. This study evaluated the effectiveness of a parent-delivered early language enrichment programme.
METHODS: We conducted a randomised controlled trial (RCT) with 208 preschool children and their parents living in socially diverse areas in the United Kingdom. Families were allocated to an oral language programme (N = 103) or an active control programme targeting motor skills (N = 105). Parents delivered the programmes to their child at home in daily 20-min sessions over 30 weeks of teaching.
RESULTS: Children receiving the language programme made significantly larger gains in language (d = .21) and narrative skills (d = .36) than children receiving the motor skills programme at immediate posttest. Effects on language were maintained 6 months later (d = .34), and at this point, the language group also scored higher on tests of early literacy (d values=.35 and .42). There was no evidence that the movement programme improved motor skills.
CONCLUSIONS: This study provides evidence for the effectiveness of a parent-delivered language enrichment programme. Further large-scale evaluations of the programme are needed to confirm and extend these findings.},
	language = {eng},
	number = {5},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Burgoyne, Kelly and Gardner, Rachel and Whiteley, Helen and Snowling, Margaret J. and Hulme, Charles},
	month = may,
	year = {2018},
	pmid = {28940192},
	keywords = {Female, Humans, Male, Language, Child, Preschool, Language Development, Early Intervention, Educational, United Kingdom, Parents, early literacy, education, Literacy, motor skills, Motor Skills, Outcome Assessment, Health Care, parents, randomised controlled trial},
	pages = {545--555},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/9AYMML2A/Burgoyne et al. - 2018 - Evaluation of a parent-delivered early language en.pdf:application/pdf},
}

@article{gillam2008,
	title = {The {Efficacy} of {Fast} {ForWord}-{Language} {Intervention} in {School}-{Age} {Children} with {Language} {Impairment}: {A} {Randomized} {Controlled} {Trial}},
	volume = {51},
	issn = {1092-4388},
	shorttitle = {The {Efficacy} of {Fast} {ForWord}-{Language} {Intervention} in {School}-{Age} {Children} with {Language} {Impairment}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2361096/},
	doi = {10.1044/1092-4388(2008/007)},
	abstract = {Purpose
A randomized controlled trial (RCT) was conducted to compare the language and auditory processing outcomes of children assigned to Fast ForWord-Language (FFW-L) to the outcomes of children assigned to nonspecific or specific language intervention comparison treatments that did not contain modified speech.

Method
Two hundred and sixteen children between the ages of 6 and 9 years with language impairments were randomly assigned to one of four arms: Fast ForWord-Language (FFW-L), academic enrichment (AE), computer-assisted language intervention (CALI), or individualized language intervention (ILI) provided by a speech-language pathologist. All children received 1 hour and 40 minutes of treatment, 5 days per week, for 6 weeks. Language and auditory processing measures were administered to the children by blinded examiners before treatment, immediately after treatment, 3 months after treatment, and 6 months after treatment.

Results
The children in all four arms improved significantly on a global language test and a test of backward masking. Children with poor backward masking scores who were randomized to the FFW-L arm did not present greater improvement on the language measures than children with poor backward masking scores who were randomized to the other three arms. Effect sizes, analyses of standard error of measurement, and normalization percentages supported the clinical significance of the improvements on the CASL. There was a treatment effect for the Blending Words subtest on the Comprehensive Test of Phonological Processing (). Participants in the FFW-L and CALI arms earned higher phonological awareness scores than children in the ILI and AE arms at the six-month follow-up testing.

Conclusion
Fast ForWord-Language, the language intervention that provided modified speech to address a hypothesized underlying auditory processing deficit, was not more effective at improving general language skills or temporal processing skills than a nonspecific comparison treatment (AE) or specific language intervention comparison treatments (CALI and ILI) that did not contain modified speech stimuli. These findings call into question the temporal processing hypothesis of language impairment and the hypothesized benefits of using acoustically modified speech to improve language skills. The finding that children in the three treatment arms and the active comparison arm made clinically relevant gains on measures of language and temporal auditory processing informs our understanding of the variety of intervention activities that can facilitate development.},
	number = {1},
	urldate = {2021-07-27},
	journal = {Journal of speech, language, and hearing research : JSLHR},
	author = {Gillam, Ronald B. and Loeb, Diane Frome and Hoffman, LaVae M. and Bohman, Thomas and Champlin, Craig A. and Thibodeau, Linda and Widen, Judith and Brandel, Jayne and Friel-Patti, Sandy},
	month = feb,
	year = {2008},
	pmid = {18230858},
	pmcid = {PMC2361096},
	pages = {97--119},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/PPWTSQAL/Gillam et al. - 2008 - The Efficacy of Fast ForWord-Language Intervention.pdf:application/pdf},
}

@article{mcgillion2017,
	title = {A randomised controlled trial to test the effect of promoting caregiver contingent talk on language development in infants from diverse socioeconomic status backgrounds},
	volume = {58},
	issn = {1469-7610},
	url = {https://acamh.onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.12725},
	doi = {10.1111/jcpp.12725},
	abstract = {Background Early language skills are critical for later academic success. Lower socioeconomic status (SES) children tend to start school with limited language skills compared to advantaged peers. We test the hypothesis that this is due in part to differences in caregiver contingent talk during infancy (how often the caregiver talks about what is in the focus of the infant's attention). Methods In a randomised controlled trial with high and low SES families, 142 11-month olds and their caregivers were randomly allocated to either a contingent talk intervention or a dental health control. Families in the language intervention watched a video about contingent talk and were asked to practise it for 15 min a day for a month. Caregiver communication was assessed at baseline and after 1 month. Infant communication was assessed at baseline, 12, 15, 18 and 24 months. Results At baseline, social gradients were observed in caregiver contingent talk to their 11-month olds (but not in infant communication). At posttest, when infants were 12 months old, caregivers across the SES spectrum who had been allocated to the language intervention group engaged in significantly more contingent talk. Lower SES caregivers in this intervention group also reported that their children produced significantly more words at 15 and 18 months. Effects of the intervention did not persist at 24 months. Instead expressive vocabulary at this age was best predicted by baseline infant communication, baseline contingent talk and SES. Conclusions A social gradient in children's communication emerges during the second year of life. A low-intensity intervention demonstrated that it is possible to increase caregiver contingent talk and that this is effective in promoting vocabulary growth for lower SES infants in the short term. However, these effects are not long-lasting, suggesting that follow-up interventions may be necessary to yield benefits lasting to school entry.},
	language = {en},
	number = {10},
	urldate = {2021-07-27},
	journal = {Journal of Child Psychology and Psychiatry},
	author = {McGillion, Michelle and Pine, Julian M. and Herbert, Jane S. and Matthews, Danielle},
	year = {2017},
	note = {\_eprint: https://acamh.onlinelibrary.wiley.com/doi/pdf/10.1111/jcpp.12725},
	keywords = {language, intervention, Infancy, parenting, socioeconomic status, vocabulary},
	pages = {1122--1131},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/ACAW4PEC/McGillion et al. - 2017 - A randomised controlled trial to test the effect o.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/U5L7BV5H/jcpp.html:text/html},
}

@article{noseworthy1994,
	title = {The impact of blinding on the results of a randomized, placebo‐controlled multiple sclerosis clinical trial},
	volume = {44},
	copyright = {© 1994 by the American Academy of Neurology},
	issn = {0028-3878, 1526-632X},
	url = {https://n.neurology.org/content/44/1/16},
	doi = {10.1212/WNL.44.1.16},
	abstract = {In the randomized, placebo-controlled, physician-blinded Canadian cooperative trial of cyclophosphamide and plasma exchange, neither active treatment regimens (group I: IV cyclophosphamide and prednisone; group II: weekly plasma exchange, oral cyclophosphamide, and prednisone) were superior to placebo (group III: sham plasma exchange and placebo medications) using the blinded, evaluating neurologists' assessments of disease course (primary analysis). All patients were examined by both a blinded and an unblinded neurologist at each assessment in this trial. We compared the blinded and unblinded neurologists' judgment of treatment response and analyzed the clinical behavior of patients who correctly guessed their treatment. The unblinded (but not the blinded) neurologists' scores demonstrated an apparent treatment benefit at 6, 12, and 24 months for the group II patients (not group I or placebo; p {\textless}0.05, two-tailed). There were no significant differences in the time to treatment failure or in the proportions of patients improved, stable, or worse between the group II and group III patients who correctly guessed their treatment assignments and those who did not. Physician blinding prevented an erroneous conclusion about treatment efficacy (false positive, type 1 error).},
	language = {en},
	number = {1},
	urldate = {2021-07-27},
	journal = {Neurology},
	author = {Noseworthy, J. H. and Ebers, G. C. and Vandervoort, M. K. and Farquhar, R. E. and Yetisir, E. and Roberts, R.},
	month = jan,
	year = {1994},
	pmid = {8290055},
	note = {Publisher: Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology
Section: Articles},
	pages = {16--16},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/Y6TZ73H9/16.html:text/html},
}

@article{hey2014,
	title = {The questionable use of unequal allocation in confirmatory trials},
	volume = {82},
	issn = {1526-632X},
	doi = {10.1212/01.wnl.0000438226.10353.1c},
	abstract = {Randomization is the standard means for addressing known and unknown confounders within the patient population in clinical trials. Although random assignment to treatment arms on a 1:1 basis has long been the norm, many 2-armed confirmatory trials now use unequal allocation schemes where the number of patients receiving investigational interventions exceeds those in the comparator arm. In what follows, we offer 3 arguments for why investigators, institutional review boards, and data and safety monitoring boards should exercise caution when planning or reviewing 2-armed confirmatory trials involving unequal allocation ratios. We close by laying out some of the conditions where uneven allocation can be justified ethically.},
	language = {eng},
	number = {1},
	journal = {Neurology},
	author = {Hey, Spencer Phillips and Kimmelman, Jonathan},
	month = jan,
	year = {2014},
	pmid = {24306005},
	pmcid = {PMC3873626},
	keywords = {Humans, Animals, Clinical Protocols, Random Allocation, Randomized Controlled Trials as Topic, Research Design},
	pages = {77--79},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/TKXSHKH8/Hey and Kimmelman - 2014 - The questionable use of unequal allocation in conf.pdf:application/pdf},
}

@article{hoare2013,
	title = {Introduction to a generalized method for adaptive randomization in trials},
	volume = {14},
	issn = {1745-6215},
	url = {https://doi.org/10.1186/1745-6215-14-19},
	doi = {10.1186/1745-6215-14-19},
	abstract = {Ideally clinical trials should use some form of randomization for allocating participants to the treatment groups under trial. As an integral part of the process of assessing the effectiveness of these treatment groups, randomization performed well can reduce, if not eliminate, some forms of bias that can be evident in non-randomized trials. Given the vast set of possible randomization methods to choose from we demonstrate a method that incorporates many of the advantages of these other methods.},
	number = {1},
	urldate = {2021-07-27},
	journal = {Trials},
	author = {Hoare, Zoë SJ and Whitaker, Christopher J. and Whitaker, Rhiannon},
	month = jan,
	year = {2013},
	keywords = {Allocation Ratio, Consort Statement, Relevant Level, Simple Randomization, Stratification Variable},
	pages = {19},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/KADX5AIF/Hoare et al. - 2013 - Introduction to a generalized method for adaptive .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/J6979AP8/1745-6215-14-19.html:text/html},
}

@article{pocock1975,
	title = {Sequential treatment assignment with balancing for prognostic factors in the controlled clinical trial},
	volume = {31},
	issn = {0006-341X},
	abstract = {In controlled clinical trials there are usually several prognostic factors known or thought to influence the patient's ability to respond to treatment. Therefore, the method of sequential treatment assignment needs to be designed so that treatment balance is simultaneously achieved across all such patients factor. Traditional methods of restricted randomization such as "permuted blocks within strata" prove inadequate once the number of strata, or combinations of factor levels, approaches the sample size. A new general procedure for treatment assignment is described which concentrates on minimizing imbalance in the distributions of treatment numbers within the levels of each individual prognostic factor. The improved treatment balance obtained by this approach is explored using simulation for a simple model of a clinical trial. Further discussion centers on the selection, predictability and practicability of such a procedure.},
	language = {eng},
	number = {1},
	journal = {Biometrics},
	author = {Pocock, S. J. and Simon, R.},
	month = mar,
	year = {1975},
	pmid = {1100130},
	keywords = {Humans, Prognosis, Statistics as Topic, Carmustine, Clinical Trials as Topic, Cyclophosphamide, Evaluation Studies as Topic, Lymphoma, Models, Theoretical, Prednisone, Vincristine},
	pages = {103--115},
}

@article{scott2002,
	title = {The method of minimization for allocation to clinical trials. a review},
	volume = {23},
	issn = {0197-2456},
	doi = {10.1016/s0197-2456(02)00242-8},
	abstract = {Minimization is a largely nonrandom method of treatment allocation for clinical trials. We conducted a systematic literature search to determine its advantages and disadvantages compared with other allocation methods. Minimization was originally proposed by Taves and by Pocock and Simon. The latter paper introduces a family of allocation methods of which Taves' method is the simplest example. Minimization aims to ensure treatment arms are balanced with respect to predefined patient factors as well as for the number of patients in each group. Further extensions of the method have also been proposed by other authors. Simulation studies show that minimization provides better balanced treatment groups when compared with restricted or unrestricted randomization and that it can incorporate more prognostic factors than stratified randomization methods such as permuted blocks within strata. Some more computationally complex methods may give an even better performance. Concerns over the use of minimization have centered on the fact that treatment assignments may be predicted with certainty in some situations and on the implications for the analysis methods used. It has been suggested that adjustment should always be made for minimization factors when analyzing trials where minimization is the allocation method used. The use of minimization may sometimes result in added organizational complexity compared with other methods. Minimization has been recommended by many commentators for use in clinical trials. Despite this it is still rarely used in practice. From the evidence presented in this review, we believe minimization to be a highly effective allocation method and recommend its wider adoption in the conduct of randomized controlled trials.},
	language = {eng},
	number = {6},
	journal = {Controlled Clinical Trials},
	author = {Scott, Neil W. and McPherson, Gladys C. and Ramsay, Craig R. and Campbell, Marion K.},
	month = dec,
	year = {2002},
	pmid = {12505244},
	keywords = {Humans, Random Allocation, Research Design, Clinical Trials as Topic},
	pages = {662--674},
}

@article{holman2015,
	title = {Evidence of {Experimental} {Bias} in the {Life} {Sciences}: {Why} {We} {Need} {Blind} {Data} {Recording}},
	volume = {13},
	issn = {1545-7885},
	shorttitle = {Evidence of {Experimental} {Bias} in the {Life} {Sciences}},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002190},
	doi = {10.1371/journal.pbio.1002190},
	abstract = {Observer bias and other “experimenter effects” occur when researchers’ expectations influence study outcome. These biases are strongest when researchers expect a particular result, are measuring subjective variables, and have an incentive to produce data that confirm predictions. To minimize bias, it is good practice to work “blind,” meaning that experimenters are unaware of the identity or treatment group of their subjects while conducting research. Here, using text mining and a literature review, we find evidence that blind protocols are uncommon in the life sciences and that nonblind studies tend to report higher effect sizes and more significant p-values. We discuss methods to minimize bias and urge researchers, editors, and peer reviewers to keep blind protocols in mind.},
	language = {en},
	number = {7},
	urldate = {2021-07-27},
	journal = {PLOS Biology},
	author = {Holman, Luke and Head, Megan L. and Lanfear, Robert and Jennions, Michael D.},
	month = jul,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Medicine and health sciences, Medical journals, Body weight, Clinical trials, Evolutionary biology, Metaanalysis, Statistical data, Text mining},
	pages = {e1002190},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/BRHN28X2/Holman et al. - 2015 - Evidence of Experimental Bias in the Life Sciences.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/7PSM5MPA/article.html:text/html},
}

@article{rosenthal1963,
	title = {The effect of experimenter bias on the performance of the albino rat},
	volume = {8},
	issn = {00057940, 10991743},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bs.3830080302},
	doi = {10.1002/bs.3830080302},
	language = {en},
	number = {3},
	urldate = {2021-07-27},
	journal = {Behavioral Science},
	author = {Rosenthal, Robert and Fode, Kermit L.},
	year = {1963},
	pages = {183--189},
	file = {Rosenthal and Fode - 2007 - The effect of experimenter bias on the performance.pdf:/Users/dorothybishop/Zotero/storage/TNLR2ETH/Rosenthal and Fode - 2007 - The effect of experimenter bias on the performance.pdf:application/pdf},
}

@article{duff2015,
	title = {Validity and sensitivity of the phonics screening check: implications for practice},
	volume = {38},
	issn = {1467-9817},
	shorttitle = {Validity and sensitivity of the phonics screening check},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9817.12029},
	doi = {10.1111/1467-9817.12029},
	abstract = {Background Introduced in June 2012, the phonics screening check aims to assess whether 6-year-old children are meeting an appropriate standard in phonic decoding and to identify children struggling with phonic skills. Aims We investigated whether the check is a valid measure of phonic skill and is sensitive in identifying children at risk of reading difficulties. Sample We obtained teacher assessments of phonic skills for 292 six-year-old children and additional psychometric data for 160 of these children. Methods Teacher assessment data were accessed from schools via the local authority; psychometric tests were administered by researchers shortly after the phonics screening check. Results The check was strongly correlated with other literacy skills and was sensitive in identifying at-risk readers. So too were teacher judgements of phonics. Conclusions Although the check fulfils its aims, we argue that resources might be better focused on training and supporting teachers in their ongoing monitoring of phonics.},
	language = {en},
	number = {2},
	urldate = {2021-07-27},
	journal = {Journal of Research in Reading},
	author = {Duff, Fiona J. and Mengoni, Silvana E. and Bailey, Alison M. and Snowling, Margaret J.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9817.12029},
	pages = {109--123},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/CHMZAGWY/Duff et al. - 2015 - Validity and sensitivity of the phonics screening .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/BL3K9R4K/1467-9817.html:text/html},
}

@article{henrich2010,
	title = {Most people are not {WEIRD}},
	volume = {466},
	copyright = {2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/466029a},
	doi = {10.1038/466029a},
	abstract = {To understand human psychology, behavioural scientists must stop doing most of their experiments on Westerners, argue Joseph Henrich, Steven J. Heine and Ara Norenzayan.},
	language = {en},
	number = {7302},
	urldate = {2021-07-27},
	journal = {Nature},
	author = {Henrich, Joseph and Heine, Steven J. and Norenzayan, Ara},
	month = jul,
	year = {2010},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 7302
Primary\_atype: Comments \& Opinion
Publisher: Nature Publishing Group
Subject\_term: Psychology and behaviour;Scientific community
Subject\_term\_id: psychology-and-behaviour;scientific-community},
	pages = {29--29},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/T4625YL3/Henrich et al. - 2010 - Most people are not WEIRD.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/NFAT4AQK/466029a.html:text/html},
}

@misc{zotero-1164,
	title = {https://academic.oup.com/psychsocgerontology/article/75/1/45/5033832 - {Google} {Search}},
	url = {https://www.google.com/search?q=https%3A%2F%2Facademic.oup.com%2Fpsychsocgerontology%2Farticle%2F75%2F1%2F45%2F5033832&client=firefox-b-d&ei=z7cDYcvcMcrS1fAP7N29qAw&oq=https%3A%2F%2Facademic.oup.com%2Fpsychsocgerontology%2Farticle%2F75%2F1%2F45%2F5033832&gs_lcp=Cgdnd3Mtd2l6EAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsANKBAhBGABQmfYRWJn2EWD4gBJoAXACeACAATSIATSSAQExmAEAoAECoAEByAEIwAEB&sclient=gws-wiz&ved=0ahUKEwiLgPvbr4ryAhVKaRUIHexuD8UQ4dUDCA4&uact=5},
	urldate = {2021-07-30},
	file = {https\://academic.oup.com/psychsocgerontology/article/75/1/45/5033832 - Google Search:/Users/dorothybishop/Zotero/storage/GFDT9EN3/search.html:text/html},
}

@techreport{lakens2021,
	title = {Sample {Size} {Justification}},
	url = {https://psyarxiv.com/9d3yf/},
	abstract = {An important step when designing a study is to justify the sample size that will be collected. The key aim of a sample size justification is to explain how the collected data is expected to provide valuable information given the inferential goals of the researcher. In this overview article six approaches are discussed to justify the sample size in a quantitative empirical study: 1) collecting data from (an)almost) the entire population, 2) choosing a sample size based on resource constraints, 3) performing an a-priori power analysis, 4) planning for a desired accuracy, 5) using heuristics, or 6) explicitly acknowledging the absence of a justification. An important question to consider when justifying sample sizes is which effect sizes are deemed interesting, and the extent to which the data that is collected informs inferences about these effect sizes. Depending on the sample size justification chosen, researchers could consider 1) what the smallest effect size of interest is, 2) which minimal effect size will be statistically significant, 3) which effect sizes they expect (and what they base these expectations on), 4) which effect sizes would be rejected based on a confidence interval around the effect size, 5) which ranges of effects a study has sufficient power to detect based on a sensitivity power analysis, and 6) which effect sizes are plausible in a specific research area. Researchers can use the guidelines presented in this article to improve their sample size justification, and hopefully, align the informational value of a study with their inferential goals.},
	urldate = {2021-07-30},
	institution = {PsyArXiv},
	author = {Lakens, Daniel},
	month = jan,
	year = {2021},
	doi = {10.31234/osf.io/9d3yf},
	note = {type: article},
	keywords = {Social and Behavioral Sciences, Experimental Design and Sample Surveys, power analysis, Quantitative Methods, sample size justification, study design, value of information},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/6T93MGWI/Lakens - 2021 - Sample Size Justification.pdf:application/pdf},
}

@article{lakens2018,
	title = {Justify your alpha},
	volume = {2},
	copyright = {2018 The Publisher},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-018-0311-x},
	doi = {10.1038/s41562-018-0311-x},
	abstract = {In response to recommendations to redefine statistical significance to P ≤ 0.005, we propose that researchers should transparently report and justify all choices they make when designing a study, including the alpha level.},
	language = {en},
	number = {3},
	urldate = {2021-07-30},
	journal = {Nature Human Behaviour},
	author = {Lakens, Daniel and Adolfi, Federico G. and Albers, Casper J. and Anvari, Farid and Apps, Matthew A. J. and Argamon, Shlomo E. and Baguley, Thom and Becker, Raymond B. and Benning, Stephen D. and Bradford, Daniel E. and Buchanan, Erin M. and Caldwell, Aaron R. and Van Calster, Ben and Carlsson, Rickard and Chen, Sau-Chin and Chung, Bryan and Colling, Lincoln J. and Collins, Gary S. and Crook, Zander and Cross, Emily S. and Daniels, Sameera and Danielsson, Henrik and DeBruine, Lisa and Dunleavy, Daniel J. and Earp, Brian D. and Feist, Michele I. and Ferrell, Jason D. and Field, James G. and Fox, Nicholas W. and Friesen, Amanda and Gomes, Caio and Gonzalez-Marquez, Monica and Grange, James A. and Grieve, Andrew P. and Guggenberger, Robert and Grist, James and van Harmelen, Anne-Laura and Hasselman, Fred and Hochard, Kevin D. and Hoffarth, Mark R. and Holmes, Nicholas P. and Ingre, Michael and Isager, Peder M. and Isotalus, Hanna K. and Johansson, Christer and Juszczyk, Konrad and Kenny, David A. and Khalil, Ahmed A. and Konat, Barbara and Lao, Junpeng and Larsen, Erik Gahner and Lodder, Gerine M. A. and Lukavský, Jiří and Madan, Christopher R. and Manheim, David and Martin, Stephen R. and Martin, Andrea E. and Mayo, Deborah G. and McCarthy, Randy J. and McConway, Kevin and McFarland, Colin and Nio, Amanda Q. X. and Nilsonne, Gustav and de Oliveira, Cilene Lino and de Xivry, Jean-Jacques Orban and Parsons, Sam and Pfuhl, Gerit and Quinn, Kimberly A. and Sakon, John J. and Saribay, S. Adil and Schneider, Iris K. and Selvaraju, Manojkumar and Sjoerds, Zsuzsika and Smith, Samuel G. and Smits, Tim and Spies, Jeffrey R. and Sreekumar, Vishnu and Steltenpohl, Crystal N. and Stenhouse, Neil and Świątkowski, Wojciech and Vadillo, Miguel A. and Van Assen, Marcel A. L. M. and Williams, Matt N. and Williams, Samantha E. and Williams, Donald R. and Yarkoni, Tal and Ziano, Ignazio and Zwaan, Rolf A.},
	month = mar,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 3
Primary\_atype: Comments \& Opinion
Publisher: Nature Publishing Group
Subject\_term: Human behaviour;Statistics
Subject\_term\_id: human-behaviour;statistics},
	pages = {168--171},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/BXBZEA62/Lakens et al. - 2018 - Justify your alpha.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/AMY3LWTK/s41562-018-0311-x.html:text/html},
}

@article{benjamin2018,
	title = {Redefine statistical significance},
	volume = {2},
	copyright = {2017 The Author(s)},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-017-0189-z},
	doi = {10.1038/s41562-017-0189-z},
	abstract = {We propose to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries.},
	language = {en},
	number = {1},
	urldate = {2021-07-30},
	journal = {Nature Human Behaviour},
	author = {Benjamin, Daniel J. and Berger, James O. and Johannesson, Magnus and Nosek, Brian A. and Wagenmakers, E.-J. and Berk, Richard and Bollen, Kenneth A. and Brembs, Björn and Brown, Lawrence and Camerer, Colin and Cesarini, David and Chambers, Christopher D. and Clyde, Merlise and Cook, Thomas D. and De Boeck, Paul and Dienes, Zoltan and Dreber, Anna and Easwaran, Kenny and Efferson, Charles and Fehr, Ernst and Fidler, Fiona and Field, Andy P. and Forster, Malcolm and George, Edward I. and Gonzalez, Richard and Goodman, Steven and Green, Edwin and Green, Donald P. and Greenwald, Anthony G. and Hadfield, Jarrod D. and Hedges, Larry V. and Held, Leonhard and Hua Ho, Teck and Hoijtink, Herbert and Hruschka, Daniel J. and Imai, Kosuke and Imbens, Guido and Ioannidis, John P. A. and Jeon, Minjeong and Jones, James Holland and Kirchler, Michael and Laibson, David and List, John and Little, Roderick and Lupia, Arthur and Machery, Edouard and Maxwell, Scott E. and McCarthy, Michael and Moore, Don A. and Morgan, Stephen L. and Munafó, Marcus and Nakagawa, Shinichi and Nyhan, Brendan and Parker, Timothy H. and Pericchi, Luis and Perugini, Marco and Rouder, Jeff and Rousseau, Judith and Savalei, Victoria and Schönbrodt, Felix D. and Sellke, Thomas and Sinclair, Betsy and Tingley, Dustin and Van Zandt, Trisha and Vazire, Simine and Watts, Duncan J. and Winship, Christopher and Wolpert, Robert L. and Xie, Yu and Young, Cristobal and Zinman, Jonathan and Johnson, Valen E.},
	month = jan,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Comments \& Opinion
Publisher: Nature Publishing Group
Subject\_term: Human behaviour;Statistics
Subject\_term\_id: human-behaviour;statistics},
	pages = {6--10},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/R9T3UD4I/Benjamin et al. - 2018 - Redefine statistical significance.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/I54JVUF3/s41562-017-0189-z.html:text/html},
}

@article{kerr1998,
	title = {{HARKing}: hypothesizing after the results are known},
	volume = {2},
	issn = {1088-8683},
	shorttitle = {{HARKing}},
	doi = {10.1207/s15327957pspr0203_4},
	abstract = {This article considers a practice in scientific communication termed HARKing (Hypothesizing After the Results are Known). HARKing is defined as presenting a post hoc hypothesis (i.e., one based on or informed by one's results) in one's research report as i f it were, in fact, an a priori hypotheses. Several forms of HARKing are identified and survey data are presented that suggests that at least some forms of HARKing are widely practiced and widely seen as inappropriate. I identify several reasons why scientists might HARK. Then I discuss several reasons why scientists ought not to HARK. It is conceded that the question of whether HARKing ' s costs exceed its benefits is a complex one that ought to be addressed through research, open discussion, and debate. To help stimulate such discussion (and for those such as myself who suspect that HARKing's costs do exceed its benefits), I conclude the article with some suggestions for deterring HARKing.},
	language = {eng},
	number = {3},
	journal = {Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc},
	author = {Kerr, N. L.},
	year = {1998},
	pmid = {15647155},
	pages = {196--217},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/HNUJNUMK/Kerr - 1998 - HARKing hypothesizing after the results are known.pdf:application/pdf},
}

@incollection{bem2004,
	address = {Washington, DC, US},
	title = {Writing the empirical journal article},
	isbn = {978-1-59147-035-9},
	abstract = {The purpose of this chapter is to enhance the chances that academic psychologists get their empirical articles published. Because I write, review, and edit primarily for journals in personality and social psychology, I have drawn most of my examples from those areas. Colleagues assure me, however, that the guidelines set forth are also pertinent for articles in experimental psychology and biopsychology. Similarly, this chapter focuses on an empirical study, but the general writing suggestions apply as well to the theoretical articles, literature reviews, and methodological contributions that also appear in psychology journals. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	booktitle = {The compleat academic: {A} career guide, 2nd ed},
	publisher = {American Psychological Association},
	author = {Bem, Daryl J.},
	year = {2004},
	keywords = {Scientific Communication, Experimental Psychology, Written Communication},
	pages = {185--219},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/YJ67QKBB/2003-06256-010.html:text/html},
}

@article{steegen2016,
	title = {Increasing {Transparency} {Through} a {Multiverse} {Analysis}},
	volume = {11},
	issn = {1745-6924},
	doi = {10.1177/1745691616658637},
	abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves choices among several reasonable options for excluding, transforming, and coding data. We suggest that instead of performing only one analysis, researchers could perform a multiverse analysis, which involves performing all analyses across the whole set of alternatively processed data sets corresponding to a large set of reasonable scenarios. Using an example focusing on the effect of fertility on religiosity and political attitudes, we show that analyzing a single data set can be misleading and propose a multiverse analysis as an alternative practice. A multiverse analysis offers an idea of how much the conclusions change because of arbitrary choices in data construction and gives pointers as to which choices are most consequential in the fragility of the result.},
	language = {eng},
	number = {5},
	journal = {Perspectives on Psychological Science: A Journal of the Association for Psychological Science},
	author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
	month = sep,
	year = {2016},
	pmid = {27694465},
	keywords = {Female, Humans, transparency, Research Design, arbitrary choices, Attitude, Choice Behavior, Data Interpretation, Statistical, data processing, Fertility, good research practices, Information Management, Marital Status, multiverse analysis, Politics, Religion, selective reporting},
	pages = {702--712},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/T5ZF74B6/Steegen et al. - 2016 - Increasing Transparency Through a Multiverse Analy.pdf:application/pdf},
}

@article{vorland2021,
	title = {Errors in the implementation, analysis, and reporting of randomization within obesity and nutrition research: a guide to their avoidance},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-5497},
	shorttitle = {Errors in the implementation, analysis, and reporting of randomization within obesity and nutrition research},
	url = {https://www.nature.com/articles/s41366-021-00909-z},
	doi = {10.1038/s41366-021-00909-z},
	abstract = {Randomization is an important tool used to establish causal inferences in studies designed to further our understanding of questions related to obesity and nutrition. To take advantage of the inferences afforded by randomization, scientific standards must be upheld during the planning, execution, analysis, and reporting of such studies. We discuss ten errors in randomized experiments from real-world examples from the literature and outline best practices for their avoidance. These ten errors include: representing nonrandom allocation as random, failing to adequately conceal allocation, not accounting for changing allocation ratios, replacing subjects in nonrandom ways, failing to account for non-independence, drawing inferences by comparing statistical significance from within-group comparisons instead of between-groups, pooling data and breaking the randomized design, failing to account for missing data, failing to report sufficient information to understand study methods, and failing to frame the causal question as testing the randomized assignment per se. We hope that these examples will aid researchers, reviewers, journal editors, and other readers to endeavor to a high standard of scientific rigor in randomized experiments within obesity and nutrition research.},
	language = {en},
	urldate = {2021-07-30},
	journal = {International Journal of Obesity},
	author = {Vorland, Colby J. and Brown, Andrew W. and Dawson, John A. and Dickinson, Stephanie L. and Golzarri-Arroyo, Lilian and Hannon, Bridget A. and Heo, Moonseong and Heymsfield, Steven B. and Jayawardene, Wasantha P. and Kahathuduwa, Chanaka N. and Keith, Scott W. and Oakes, J. Michael and Tekwe, Carmen D. and Thabane, Lehana and Allison, David B.},
	month = jul,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Diseases;Nutrition disorders
Subject\_term\_id: diseases;nutrition-disorders},
	pages = {1--12},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/XMT44WSJ/Vorland et al. - 2021 - Errors in the implementation, analysis, and report.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/TDK3M92G/s41366-021-00909-z.html:text/html},
}

@article{moher2010,
	title = {{CONSORT} 2010 explanation and elaboration: updated guidelines for reporting parallel group randomised trials},
	volume = {340},
	issn = {1756-1833},
	shorttitle = {{CONSORT} 2010 explanation and elaboration},
	doi = {10.1136/bmj.c869},
	language = {eng},
	journal = {BMJ (Clinical research ed.)},
	author = {Moher, David and Hopewell, Sally and Schulz, Kenneth F. and Montori, Victor and Gøtzsche, Peter C. and Devereaux, P. J. and Elbourne, Diana and Egger, Matthias and Altman, Douglas G.},
	month = mar,
	year = {2010},
	pmid = {20332511},
	pmcid = {PMC2844943},
	keywords = {Randomized Controlled Trials as Topic, Research Design, Consensus, Practice Guidelines as Topic},
	pages = {c869},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/G2GQ8TCK/Moher et al. - 2010 - CONSORT 2010 explanation and elaboration updated .pdf:application/pdf},
}

@book{campbell2014,
	address = {Chichester},
	title = {How to design, analyse and report cluster randomised trials in medicine and health related research.},
	publisher = {Wiley},
	author = {Campbell, MJ and Walters, SJ},
	year = {2014},
}

@article{araujo2016,
	title = {Understanding {Variation} in {Sets} of {N}-of-1 {Trials}},
	volume = {11},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167167},
	doi = {10.1371/journal.pone.0167167},
	abstract = {A recent paper in this journal by Chen and Chen has used computer simulations to examine a number of approaches to analysing sets of n-of-1 trials. We have examined such designs using a more theoretical approach based on considering the purpose of analysis and the structure as regards randomisation that the design uses. We show that different purposes require different analyses and that these in turn may produce quite different results. Our approach to incorporating the randomisation employed when the purpose is to test a null hypothesis of strict equality of the treatment makes use of Nelder’s theory of general balance. However, where the purpose is to make inferences about the effects for individual patients, we show that a mixed model is needed. There are strong parallels to the difference between fixed and random effects meta-analyses and these are discussed.},
	language = {en},
	number = {12},
	urldate = {2021-07-31},
	journal = {PLOS ONE},
	author = {Araujo, Artur and Julious, Steven and Senn, Stephen},
	month = dec,
	year = {2016},
	note = {Publisher: Public Library of Science},
	keywords = {Simulation and modeling, Analysis of variance, Metaanalysis, ACE inhibitor therapy, Balance and falls, Beta-adrenergic antagonist therapy, Experimental design, Nicotine replacement therapy},
	pages = {e0167167},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/N6MU7E4M/Araujo et al. - 2016 - Understanding Variation in Sets of N-of-1 Trials.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/DGZTTMC2/article.html:text/html},
}

@article{duan2013,
	title = {Single-patient (n-of-1) trials: a pragmatic clinical decision methodology for patient-centered comparative effectiveness research},
	volume = {66},
	issn = {1878-5921},
	shorttitle = {Single-patient (n-of-1) trials},
	doi = {10.1016/j.jclinepi.2013.04.006},
	abstract = {OBJECTIVE: To raise awareness among clinicians and epidemiologists that single-patient (n-of-1) trials are potentially useful for informing personalized treatment decisions for patients with chronic conditions.
STUDY DESIGN AND SETTING: We reviewed the clinical and statistical literature on methods and applications of single-patient trials and then critically evaluated the needs for further methodological developments.
RESULTS: Existing literature reports application of 2,154 single-patient trials in 108 studies for diverse clinical conditions; various recent commentaries advocate for wider application of such trials in clinical decision making. Preliminary evidence from several recent pilot acceptability studies suggests that single-patient trials have the potential for widespread acceptance by patients and clinicians as an effective modality for increasing the therapeutic precision. Bayesian and adaptive statistical methods hold promise for increasing the informational yield of single-patient trials while reducing participant burden, but are not widely used. Personalized applications of single-patient trials can be enhanced through further development and application of methodologies on adaptive trial design, stopping rules, network meta-analysis, washout methods, and methods for communicating trial findings to patients and clinicians.
CONCLUSIONS: Single-patient trials may be poised to emerge as an important part of the methodological armamentarium for comparative effectiveness research and patient-centered outcomes research. By permitting direct estimation of individual treatment effects, they can facilitate finely graded individualized care, enhance therapeutic precision, improve patient outcomes, and reduce costs.},
	language = {eng},
	number = {8 Suppl},
	journal = {Journal of Clinical Epidemiology},
	author = {Duan, Naihua and Kravitz, Richard L. and Schmid, Christopher H.},
	month = aug,
	year = {2013},
	pmid = {23849149},
	pmcid = {PMC3972259},
	keywords = {Humans, Outcome Assessment, Health Care, Randomized Controlled Trials as Topic, Adaptive trial, Bayes Theorem, Bayesian method, Borrow from strength, Carryover effect, Chronic Disease, Comparative Effectiveness Research, Cross-Over Studies, Crossover trial, Decision Support Techniques, Evidence-Based Medicine, Patient Participation, Patient Selection, Pilot Projects, Sequential trial, Washout},
	pages = {S21--28},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/DBQBAGBV/Duan et al. - 2013 - Single-patient (n-of-1) trials a pragmatic clinic.pdf:application/pdf},
}

@article{goldacre2019,
	title = {{COMPare}: a prospective cohort study correcting and monitoring 58 misreported trials in real time},
	volume = {20},
	issn = {1745-6215},
	shorttitle = {{COMPare}},
	url = {https://doi.org/10.1186/s13063-019-3173-2},
	doi = {10.1186/s13063-019-3173-2},
	abstract = {Discrepancies between pre-specified and reported outcomes are an important source of bias in trials. Despite legislation, guidelines and public commitments on correct reporting from journals, outcome misreporting continues to be prevalent. We aimed to document the extent of misreporting, establish whether it was possible to publish correction letters on all misreported trials as they were published, and monitor responses from editors and trialists to understand why outcome misreporting persists despite public commitments to address it.},
	number = {1},
	urldate = {2021-07-31},
	journal = {Trials},
	author = {Goldacre, Ben and Drysdale, Henry and Dale, Aaron and Milosevic, Ioan and Slade, Eirion and Hartley, Philip and Marston, Cicely and Powell-Smith, Anna and Heneghan, Carl and Mahtani, Kamal R.},
	month = feb,
	year = {2019},
	keywords = {Audit, CONSORT, Editorial conduct, ICMJE, Misreporting, Outcomes, Trials},
	pages = {118},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/8HZGQN2U/Goldacre et al. - 2019 - COMPare a prospective cohort study correcting and.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/PN7SUD5E/s13063-019-3173-2.html:text/html},
}

@article{bishop2017,
	title = {Phase 2 of {CATALISE}: a multinational and multidisciplinary {Delphi} consensus study of problems with language development: {Terminology}},
	volume = {58},
	issn = {1469-7610},
	shorttitle = {Phase 2 of {CATALISE}},
	url = {https://acamh.onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.12721},
	doi = {10.1111/jcpp.12721},
	abstract = {Background Lack of agreement about criteria and terminology for children's language problems affects access to services as well as hindering research and practice. We report the second phase of a study using an online Delphi method to address these issues. In the first phase, we focused on criteria for language disorder. Here we consider terminology. Methods The Delphi method is an iterative process in which an initial set of statements is rated by a panel of experts, who then have the opportunity to view anonymised ratings from other panel members. On this basis they can either revise their views or make a case for their position. The statements are then revised based on panel feedback, and again rated by and commented on by the panel. In this study, feedback from a second round was used to prepare a final set of statements in narrative form. The panel included 57 individuals representing a range of professions and nationalities. Results We achieved at least 78\% agreement for 19 of 21 statements within two rounds of ratings. These were collapsed into 12 statements for the final consensus reported here. The term ‘Language Disorder’ is recommended to refer to a profile of difficulties that causes functional impairment in everyday life and is associated with poor prognosis. The term, ‘Developmental Language Disorder’ (DLD) was endorsed for use when the language disorder was not associated with a known biomedical aetiology. It was also agreed that (a) presence of risk factors (neurobiological or environmental) does not preclude a diagnosis of DLD, (b) DLD can co-occur with other neurodevelopmental disorders (e.g. ADHD) and (c) DLD does not require a mismatch between verbal and nonverbal ability. Conclusions This Delphi exercise highlights reasons for disagreements about terminology for language disorders and proposes standard definitions and nomenclature.},
	language = {en},
	number = {10},
	urldate = {2021-07-31},
	journal = {Journal of Child Psychology and Psychiatry},
	author = {Bishop, D. V. M. and Snowling, Margaret J. and Thompson, Paul A. and Greenhalgh, Trisha},
	year = {2017},
	note = {\_eprint: https://acamh.onlinelibrary.wiley.com/doi/pdf/10.1111/jcpp.12721},
	keywords = {risk factors, specific language impairment, definitions, Developmental language disorder, terminology},
	pages = {1068--1080},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/FLVTG6D6/Bishop et al. - 2017 - Phase 2 of CATALISE a multinational and multidisc.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/EIH5AIJ7/jcpp.html:text/html},
}

@article{tate2016,
	title = {The {Single}-{Case} {Reporting} {Guideline} {In} {Behavioural} {Interventions} ({SCRIBE}) 2016 {Statement}},
	volume = {96},
	issn = {1538-6724},
	doi = {10.2522/ptj.2016.96.7.e1},
	abstract = {We developed a reporting guideline to provide authors with guidance about what should be reported when writing a paper for publication in a scientific journal using a particular type of research design: the single-case experimental design. This report describes the methods used to develop the Single-Case Reporting guideline In BEhavioural interventions (SCRIBE) 2016. As a result of 2 online surveys and a 2-day meeting of experts, the SCRIBE 2016 checklist was developed, which is a set of 26 items that authors need to address when writing about single-case research. This article complements the more detailed SCRIBE 2016 Explanation and Elaboration article (Tate et al., 2016) that provides a rationale for each of the items and examples of adequate reporting from the literature. Both these resources will assist authors to prepare reports of single-case research with clarity, completeness, accuracy, and transparency. They will also provide journal reviewers and editors with a practical checklist against which such reports may be critically evaluated. We recommend that the SCRIBE 2016 is used by authors preparing manuscripts describing single-case research for publication, as well as journal reviewers and editors who are evaluating such manuscripts.
SCIENTIFIC ABSTRACT: Reporting guidelines, such as the Consolidated Standards of Reporting Trials (CONSORT) Statement, improve the reporting of research in the medical literature (Turner et al., 2012). Many such guidelines exist and the CONSORT Extension to Nonpharmacological Trials (Boutron et al., 2008) provides suitable guidance for reporting between-groups intervention studies in the behavioral sciences. The CONSORT Extension for N-of-1 Trials (CENT 2015) was developed for multiple crossover trials with single individuals in the medical sciences (Shamseer et al., 2015; Vohra et al., 2015), but there is no reporting guideline in the CONSORT tradition for single-case research used in the behavioral sciences. We developed the Single-Case Reporting guideline In BEhavioural interventions (SCRIBE) 2016 to meet this need. This Statement article describes the methodology of the development of the SCRIBE 2016, along with the outcome of 2 Delphi surveys and a consensus meeting of experts. We present the resulting 26-item SCRIBE 2016 checklist. The article complements the more detailed SCRIBE 2016 Explanation and Elaboration article (Tate et al., 2016) that provides a rationale for each of the items and examples of adequate reporting from the literature. Both these resources will assist authors to prepare reports of single-case research with clarity, completeness, accuracy, and transparency. They will also provide journal reviewers and editors with a practical checklist against which such reports may be critically evaluated.},
	language = {eng},
	number = {7},
	journal = {Physical Therapy},
	author = {Tate, Robyn L. and Perdices, Michael and Rosenkoetter, Ulrike and Shadish, William and Vohra, Sunita and Barlow, David H. and Horner, Robert and Kazdin, Alan and Kratochwill, Thomas and McDonald, Skye and Sampson, Margaret and Shamseer, Larissa and Togher, Leanne and Albin, Richard and Backman, Catherine and Douglas, Jacinta and Evans, Jonathan J. and Gast, David and Manolov, Rumen and Mitchell, Geoffrey and Nickels, Lyndsey and Nikles, Jane and Ownsworth, Tamara and Rose, Miranda and Schmid, Christopher H. and Wilson, Barbara},
	month = jul,
	year = {2016},
	pmid = {27371692},
	keywords = {Humans, methodology, Research Design, Behavior Therapy, Checklist, Delphi Technique, Guidelines as Topic, Peer Review, Research, publication standardsSupplemental materials: http://dx.doi.org/10.1037/arc0000026.supp., reporting guidelines, Research Report, single-case design},
	pages = {e1--e10},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/4ZSVV4LM/Tate et al. - 2016 - The Single-Case Reporting Guideline In BEhavioural.pdf:application/pdf},
}

@article{perdices2009,
	title = {Single-subject designs as a tool for evidence-based clinical practice: {Are} they unrecognised and undervalued?},
	volume = {19},
	issn = {0960-2011},
	shorttitle = {Single-subject designs as a tool for evidence-based clinical practice},
	url = {https://doi.org/10.1080/09602010903040691},
	doi = {10.1080/09602010903040691},
	abstract = {One could be forgiven for thinking that the only road to evidence-based clinical practice is the application of results from randomised controlled trials (or systematic reviews of such). By contrast, single-subject designs in the context of evidence-based clinical practice are believed by many to be strange bedfellows. In this paper, we argue that single-subject designs play an important role in evidence-based clinical practice. We survey the contents of Neuropsychological Rehabilitation in relation to single-subject designs and tackle the main criticisms that have been levelled against them. We offer practical guidance for rating the methodological quality of single-subject designs and applying statistical techniques to measure treatment efficacy. These guides are equally applicable to research studies and everyday clinical practice with individual patients.},
	number = {6},
	urldate = {2021-08-01},
	journal = {Neuropsychological Rehabilitation},
	author = {Perdices, Michael and Tate, Robyn L.},
	month = dec,
	year = {2009},
	pmid = {19657974},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09602010903040691},
	keywords = {Methodology, Corrigendum, N-of-1 trials, Single-case experimental designs},
	pages = {904--927},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/7HWKAVGX/Perdices and Tate - 2009 - Single-subject designs as a tool for evidence-base.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/9NYTR32I/09602010903040691.html:text/html},
}

@article{ingham1981,
	title = {Some effects of the {Edinburgh} {Masker} on stuttering during oral reading and spontaneous speech},
	volume = {6},
	issn = {0094-730X},
	url = {https://www.sciencedirect.com/science/article/pii/0094730X81900115},
	doi = {10.1016/0094-730X(81)90011-5},
	abstract = {This study assessed the effect of a voice-activated masking unit, known as the Edinburgh Masker, on the speech of four stutterers during oral reading and spontaneous speech. The results show that one stutterer reduced stuttering almost completely whenever the masker was activated. Two subjects showed either marginal or temporary reductions of stuttering during one speaking condition but showed no change in the other condition. The other subject reduced stuttering only during spontaneous speech. No reduction in stuttering was associated with reduced speech rate. A perceptual analysis procedure conducted to assess for altered speech quality during masking conditions found changes in speech quality were evident in two subjects. The clinical implications of these findings are discussed.},
	language = {en},
	number = {2},
	urldate = {2021-08-01},
	journal = {Journal of Fluency Disorders},
	author = {Ingham, Roger J. and Southwood, Helen and Horsburgh, Gay},
	month = jun,
	year = {1981},
	pages = {135--154},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/Y2EXW5NP/Ingham et al. - 1981 - Some effects of the Edinburgh Masker on stuttering.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/5QWG7ZQ6/0094730X81900115.html:text/html},
}

@article{block1996,
	title = {The {Effects} of the {Edinburgh} {Masker} on {Stuttering}},
	volume = {24},
	issn = {0310-6853},
	url = {https://doi.org/10.3109/asl2.1996.24.issue-1.02},
	doi = {10.3109/asl2.1996.24.issue-1.02},
	abstract = {Auditory feedback masking has long been thought to be a clinically useful procedure for the modification of stuttered speech in adults, and the Edinburgh Masker is a commercial device for providing such masking. In the present study, 18 subjects spoke under various masking and nonmasking conditions using the Edinburgh Masker, both in and beyond the clinic. Results showed that stuttering rate reduced by a mean of around 50\% in masking compared to nonmasking conditions. Only one subject completely eliminated stuttering, and did so in only one of many speaking tasks. Listeners judged masked speech to be less natural sounding than nonmasked speech. It is concluded that, for some clients, there may be some benefit in masked speech by means of the Edinburgh Masker, but that the device does not appear to produce either stutter-free or natural sounding speech.},
	number = {1},
	urldate = {2021-08-01},
	journal = {Australian Journal of Human Communication Disorders},
	author = {Block, Susan and Ingham, Roger J. and Bench, R. John},
	month = jun,
	year = {1996},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.3109/asl2.1996.24.issue-1.02},
	pages = {11--18},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/4NNIB7DI/asl2.1996.24.issue-1.html:text/html},
}

@article{furukawa2014,
	title = {Waiting list may be a nocebo condition in psychotherapy trials: a contribution from network meta-analysis},
	volume = {130},
	issn = {1600-0447},
	shorttitle = {Waiting list may be a nocebo condition in psychotherapy trials},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/acps.12275},
	doi = {10.1111/acps.12275},
	abstract = {Objective Various control conditions have been employed in psychotherapy trials, but there is growing suspicion that they may lead to different effect size estimates. The present study aims to examine the differences among control conditions including waiting list (WL), no treatment (NT) and psychological placebo (PP). Method We comprehensively searched for all randomized controlled trials (RCTs) comparing cognitive-behaviour therapies (CBT) against various control conditions in the acute phase treatment of depression, and applied network meta-analysis (NMA) to combine all direct and indirect comparisons among the treatment and control arms. Results We identified 49 RCTs (2730 participants) comparing WL, NT, PP and CBT. This network of evidence was consistent, and the effect size estimates for CBT were substantively different depending on the control condition. The odds ratio of response for NT over WL was statistically significant at 2.9 (95\% CI: 1.3–5.7). However, the quality of evidence, including publication bias, was less than ideal and none of the preplanned sensitivity analyses limiting to high-quality studies could be conducted, while findings of significant differences did not persist in post hoc sensitivity analyses trying to adjust for publication bias. Conclusion There may be important differences in control conditions currently used in psychotherapy trials.},
	language = {en},
	number = {3},
	urldate = {2021-08-01},
	journal = {Acta Psychiatrica Scandinavica},
	author = {Furukawa, T. A. and Noma, H. and Caldwell, D. M. and Honyashiki, M. and Shinohara, K. and Imai, H. and Chen, P. and Hunot, V. and Churchill, R.},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/acps.12275},
	keywords = {clinical trials, cognitive therapy, control groups, placebo, waiting lists},
	pages = {181--192},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/V243F79J/Furukawa et al. - 2014 - Waiting list may be a nocebo condition in psychoth.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/WFRB53XT/acps.html:text/html},
}

@article{cunningham2013,
	title = {Exploratory randomized controlled trial evaluating the impact of a waiting list control design},
	volume = {13},
	issn = {1471-2288},
	url = {https://doi.org/10.1186/1471-2288-13-150},
	doi = {10.1186/1471-2288-13-150},
	abstract = {Employing waiting list control designs in psychological and behavioral intervention research may artificially inflate intervention effect estimates. This exploratory randomized controlled trial tested this proposition in a study employing a brief intervention for problem drinkers, one domain of research in which waiting list control designs are used.},
	number = {1},
	urldate = {2021-08-01},
	journal = {BMC Medical Research Methodology},
	author = {Cunningham, John A. and Kypri, Kypros and McCambridge, Jim},
	month = dec,
	year = {2013},
	keywords = {Randomized controlled trials, Alcohol, Alternate explanation, Brief intervention, Research methods, Waiting list control design},
	pages = {150},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/3FUAKS46/Cunningham et al. - 2013 - Exploratory randomized controlled trial evaluating.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/MLRLSHHF/1471-2288-13-150.html:text/html},
}

@incollection{howard2003,
	title = {Chapter 16: {Single} {Cases}, {Group} {Studies} and {Case} {Series} in {Aphasia} {Therapy}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/B9780080440736500171?token=402044775314B107D8FAC186B5A72020B85191FCEE862FCF95B2C037B17634D20F97DB7AFB2A1723513D3FCC21D586D4&originRegion=eu-west-1&originCreation=20210801103239},
	language = {en},
	urldate = {2021-08-01},
	booktitle = {The {Sciences} of {Aphasia}: {From} {Theory} to {Therapy}. {Ilias} {Papathanasiou} and {Ria} {De} {Bleser} ({Eds}).},
	publisher = {Elsevier},
	author = {Howard, David},
	year = {2003},
	doi = {10.1016/B978-008044073-6/50017-1},
	pages = {245--258},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/JVPIJRV2/B9780080440736500171.html:text/html;PII B978-0-08-044073-6.50017-1  Elsevier Enhance.pdf:/Users/dorothybishop/Zotero/storage/MPJNHFHN/PII B978-0-08-044073-6.50017-1  Elsevier Enhance.pdf:application/pdf},
}

@article{krasny-pacini2018,
	title = {Single-case experimental designs to assess intervention effectiveness in rehabilitation: {A} practical guide},
	volume = {61},
	issn = {1877-0657},
	shorttitle = {Single-case experimental designs to assess intervention effectiveness in rehabilitation},
	url = {https://www.sciencedirect.com/science/article/pii/S1877065717304542},
	doi = {10.1016/j.rehab.2017.12.002},
	abstract = {Single-case experimental designs (SCED) are experimental designs aiming at testing the effect of an intervention using a small number of patients (typically one to three), using repeated measurements, sequential (±randomized) introduction of an intervention and method-specific data analysis, including visual analysis and specific statistics. The aim of this paper is to familiarise professionals working in different fields of rehabilitation with SCEDs and provide practical advice on how to design and implement a SCED in clinical rehabilitation practice. Research questions suitable for SCEDs and the different types of SCEDs (e.g., alternating treatment designs, introduction/withdrawal designs and multiple baseline designs) are reviewed. Practical steps in preparing a SCED design are outlined. Examples from different rehabilitation domains are provided throughout the paper. Challenging issues such as the choice of the repeated measure, assessment of generalisation, randomization, procedural fidelity, replication and generalizability of findings are discussed. Simple rules and resources for data analysis are presented. The utility of SCEDs in physical and rehabilitation medicine (PRM) are discussed.},
	language = {en},
	number = {3},
	urldate = {2021-08-01},
	journal = {Annals of Physical and Rehabilitation Medicine},
	author = {Krasny-Pacini, Agata and Evans, Jonathan},
	month = may,
	year = {2018},
	keywords = {Methodology, Alternating treatment, Multiple baseline, Rehabilitation, Single-case},
	pages = {164--179},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/GTXS9KFF/Krasny-Pacini and Evans - 2018 - Single-case experimental designs to assess interve.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/ISHQCBBA/S1877065717304542.html:text/html},
}

@misc{zotero-1230,
	title = {The history and development of {N} of 1 trials.},
	url = {https://www.jameslindlibrary.org/articles/history-development-n-1-trials/},
	abstract = {Introduction ‘Trials of therapy’, in which physicians ‘try out’ treatments and assess patients’ responses, are long-established, common elements of routine medical practice. Because ‘trials of therapy’ are usually informal, they ...},
	language = {en-GB},
	urldate = {2021-08-01},
	journal = {The James Lind Library},
	note = {Section: N-of-1 crossover},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/HJHDUY9H/history-development-n-1-trials.html:text/html},
}

@article{mirza2017,
	title = {The history and development of {N}-of-1 trials},
	volume = {110},
	issn = {0141-0768},
	url = {https://doi.org/10.1177/0141076817721131},
	doi = {10.1177/0141076817721131},
	language = {en},
	number = {8},
	urldate = {2021-08-01},
	journal = {Journal of the Royal Society of Medicine},
	author = {Mirza, RD and Punja, S and Vohra, S and Guyatt, G},
	month = aug,
	year = {2017},
	note = {Publisher: SAGE Publications},
	pages = {330--340},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/PAEEEBQM/Mirza et al. - 2017 - The history and development of N-of-1 trials.pdf:application/pdf},
}

@article{leniston2021,
	title = {Investigation into the effectiveness of electropalatography in treating persisting speech sound disorders in adolescents with co-occurring developmental language disorder},
	issn = {1464-5076},
	doi = {10.1080/02699206.2021.1957022},
	abstract = {This study aimed to assess the effectiveness of Electropalatography (EPG) intervention in targeting specific phonemes/words in seven adolescents aged 14:10-18:06 with co-occurring speech sound and language disorders. Progress on individualised targets versus controls was evaluated following intervention undertaken as part of the participants' usual speech and language therapy provision. As a group, the participants showed significantly greater progress on their targets than controls, indicating that the EPG intervention was effective. However, performance varied between participants, targets and school terms. Factors that may have influenced the effectiveness of intervention include spending more time on targets and focusing on a specific phoneme. Overall, the results suggest EPG should be considered as an intervention approach for this client group, even in the late teenage years.},
	language = {eng},
	journal = {Clinical Linguistics \& Phonetics},
	author = {Leniston, Hannah and Ebbels, Susan},
	month = jul,
	year = {2021},
	pmid = {34325597},
	keywords = {intervention, developmental language disorder, Electropalatography, school-aged children, speech sound disorder},
	pages = {1--16},
	file = {Leniston and Ebbels - 2021 - Investigation into the effectiveness of electropal.pdf:/Users/dorothybishop/Zotero/storage/C4V4PQDC/Leniston and Ebbels - 2021 - Investigation into the effectiveness of electropal.pdf:application/pdf},
}

@article{rothwell2005,
	title = {External validity of randomised controlled trials: “{To} whom do the results of this trial apply?”},
	volume = {365},
	issn = {0140-6736},
	shorttitle = {External validity of randomised controlled trials},
	url = {https://www.sciencedirect.com/science/article/pii/S0140673604176708},
	doi = {10.1016/S0140-6736(04)17670-8},
	abstract = {In making treatment decisions, doctors and patients must take into account relevant randomised controlled trials (RCTs) and systematic reviews. Relevance depends on external validity (or generalisability)—ie, whether the results can be reasonably applied to a definable group of patients in a particular clinical setting in routine practice. There is concern among clinicians that external validity is often poor, particularly for some pharmaceutical industry trials, a perception that has led to underuse of treatments that are effective. Yet researchers, funding agencies, ethics committees, the pharmaceutical industry, medical journals, and governmental regulators alike all neglect external validity, leaving clinicians to make judgments. However, reporting of the determinants of external validity in trial publications and systematic reviews is usually inadequate. This review discusses those determinants, presents a checklist for clinicians, and makes recommendations for greater consideration of external validity in the design and reporting of RCTs.},
	language = {en},
	number = {9453},
	urldate = {2021-08-01},
	journal = {The Lancet},
	author = {Rothwell, Peter M},
	month = jan,
	year = {2005},
	pages = {82--93},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/QZXHVGQ4/Rothwell - 2005 - External validity of randomised controlled trials.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/NYP2KIN8/S0140673604176708.html:text/html},
}

@article{garralda2019,
	title = {New clinical trial designs in the era of precision medicine},
	volume = {13},
	issn = {1574-7891},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6396357/},
	doi = {10.1002/1878-0261.12465},
	abstract = {Cancer treatment has made significant strides towards the promise of personalized medicine. Recent scientific advances have shown that there are numerous genetic deregulations that are common in multiple cancer types, raising the possibility of developing drugs targeting those deregulations irrespective of the tumour type. Precision Cancer Medicine (PCM) was born out of accumulated evidence matching targeted agents with these tumour molecular deregulations. At the same time, the therapeutic armamentarium is rapidly increasing and the number of new drugs (including immune‐oncology agents) entering drug development continues to rise. These factors, added to strong collaboration with regulatory agencies, which have approved novel agents based on data obtained from phase 1/2 trials, have led to unprecedented evolution in the design of early‐stage clinical trials. Currently, we have seen rapid phase 1 dose‐escalation trials followed by remarkably large expansion cohorts, and are witnessing the emergence of new trials, such as adaptive studies with basket and umbrella designs aimed at optimizing the biomarker–drug co‐development process. Alongside the growing complexity of these clinical trials, new frameworks for stronger and faster collaboration between all stakeholders in drug development, including academic institutions and frameworks, clinicians, pharma companies and regulatory agencies, have been established. In this review article, we describe the main challenges and opportunities that these new trial designs may provide for a more efficient drug development process, which may ultimately help ensure that PCM becomes a reality for patients.},
	number = {3},
	urldate = {2021-08-02},
	journal = {Molecular Oncology},
	author = {Garralda, Elena and Dienstmann, Rodrigo and Piris‐Giménez, Alejandro and Braña, Irene and Rodon, Jordi and Tabernero, Josep},
	month = mar,
	year = {2019},
	pmid = {30698321},
	pmcid = {PMC6396357},
	pages = {549--557},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/NXP5JN6H/Garralda et al. - 2019 - New clinical trial designs in the era of precision.pdf:application/pdf},
}

@article{bishop2013a,
	title = {Research {Review}: {Emanuel} {Miller} {Memorial} {Lecture} 2012 – {Neuroscientific} studies of intervention for language impairment in children: interpretive and methodological problems},
	volume = {54},
	issn = {0021-9630},
	shorttitle = {Research {Review}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3593170/},
	doi = {10.1111/jcpp.12034},
	abstract = {Background
Our ability to look at structure and function of a living brain has increased exponentially since the early 1970s. Many studies of developmental disorders now routinely include a brain imaging or electrophysiological component. Amid current enthusiasm for applications of neuroscience to educational interventions, we need to pause to consider what neuroimaging data can tell us. Images of brain activity are seductive, and have been used to give credibility to commercial interventions, yet we have only a limited idea of what the brain bases of language disorders are, let alone how to alter them.

Scope and findings
A review of six studies of neuroimaging correlates of language intervention found recurring methodological problems: lack of an adequate control group, inadequate power, incomplete reporting of data, no correction for multiple comparisons, data dredging and failure to analyse treatment effects appropriately. In addition, there is a tendency to regard neuroimaging data as more meaningful than behavioural data, even though it is behaviour that interventions aim to alter.

Conclusion
In our current state of knowledge, it would be better to spend research funds doing well-designed trials of behavioural treatment to establish which methods are effective, rather than rushing headlong into functional imaging studies of unproven treatments.},
	number = {3},
	urldate = {2021-08-02},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Bishop, D V M},
	month = mar,
	year = {2013},
	pmid = {23278309},
	pmcid = {PMC3593170},
	pages = {247--259},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/BKYDLHVX/Bishop - 2013 - Research Review Emanuel Miller Memorial Lecture 2.pdf:application/pdf},
}

@article{senn2018,
	title = {Statistical pitfalls of personalized medicine},
	volume = {563},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-018-07535-2},
	doi = {10.1038/d41586-018-07535-2},
	abstract = {Misleading terminology and arbitrary divisions stymie drug trials and can give false hope about the potential of tailoring drugs to individuals, warns Stephen Senn.},
	language = {en},
	number = {7733},
	urldate = {2021-08-02},
	journal = {Nature},
	author = {Senn, Stephen},
	month = nov,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Number: 7733
Publisher: Nature Publishing Group
Subject\_term: Medical research, Personalized medicine},
	pages = {619--621},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/GVVUPHS5/Senn - 2018 - Statistical pitfalls of personalized medicine.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/8ECCZ2DK/d41586-018-07535-2.html:text/html},
}

@article{best2013,
	title = {Aphasia rehabilitation: {Does} generalisation from anomia therapy occur and is it predictable? {A} case series study},
	volume = {49},
	issn = {0010-9452},
	shorttitle = {Aphasia rehabilitation},
	url = {https://www.sciencedirect.com/science/article/pii/S0010945213000087},
	doi = {10.1016/j.cortex.2013.01.005},
	abstract = {Introduction
The majority of adults with acquired aphasia have anomia which can respond to rehabilitation with cues. However, the literature and clinical consensus suggest change is usually limited to treated items. We investigated the effect of an experimentally controlled intervention using progressive cues in the rehabilitation of noun retrieval/production in 16 participants with chronic aphasia.
Method
Participants were sub-divided relative to the group according to performance on semantic tasks (spoken/written word to picture matching) and phonological output processing (presence/absence of word length effect and proportion of phonological errors in picture naming) in order to investigate outcome in relation to language profile. Cueing therapy took place weekly for 8 weeks.
Results
Intervention resulted in significant improvement on naming treated items for 15/16 participants, with stable performance on control tasks. Change occurred at the point of intervention and not during pre-therapy assessments. We predicted particular patterns of generalisation which were upheld. Only participants classified as having relatively less of a semantic difficulty and more of a phonological output deficit demonstrated generalisation to untreated items. Outcome did not relate to traditional aphasia classification.
Conclusion
A cueing hierarchy can improve word retrieval/production for adults with aphasia. In some cases generalisation to untreated items also occurs. The study demonstrates that the results of behavioural testing can be used to guide predictions of recovery with intervention.},
	language = {en},
	number = {9},
	urldate = {2021-08-02},
	journal = {Cortex},
	author = {Best, Wendy and Greenwood, Alison and Grassly, Jennie and Herbert, Ruth and Hickin, Julie and Howard, David},
	month = oct,
	year = {2013},
	keywords = {Aphasia, Rehabilitation, Anomia, Generalisation, Therapy},
	pages = {2345--2357},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/WDSX2AB2/Best et al. - 2013 - Aphasia rehabilitation Does generalisation from a.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/Y6M2XDIU/S0010945213000087.html:text/html},
}

@article{rosenthal1979a,
	title = {The file drawer problem and tolerance for null results},
	volume = {86},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/0033-2909.86.3.638},
	abstract = {For any given research area, one cannot tell how many studies have been conducted but never reported. The extreme view of the "file drawer problem" is that journals are filled with the 5\% of the studies that show Type I errors, while the file drawers are filled with the 95\% of the studies that show nonsignificant results. Quantitative procedures for computing the tolerance for filed and future null results are reported and illustrated, and the implications are discussed. (15 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Psychological Bulletin},
	author = {Rosenthal, Robert},
	year = {1979},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Statistical Probability, Experimentation, Scientific Communication, Statistical Tests, Type I Errors},
	pages = {638--641},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/ME9HEVTA/1979-27602-001.html:text/html},
}

@article{devries2018,
	title = {The cumulative effect of reporting and citation biases on the apparent efficacy of treatments: the case of depression},
	volume = {48},
	issn = {0033-2917},
	shorttitle = {The cumulative effect of reporting and citation biases on the apparent efficacy of treatments},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6190062/},
	doi = {10.1017/S0033291718001873},
	number = {15},
	urldate = {2021-08-03},
	journal = {Psychological Medicine},
	author = {de Vries, Y. A. and Roest, A. M. and de Jonge, P. and Cuijpers, P. and Munafò, M. R. and Bastiaansen, J. A.},
	month = nov,
	year = {2018},
	pmid = {30070192},
	pmcid = {PMC6190062},
	pages = {2453--2455},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/6FX77EJD/de Vries et al. - 2018 - The cumulative effect of reporting and citation bi.pdf:application/pdf},
}

@book{leng2020,
	address = {Cambridge, MA},
	title = {The {Matter} of {Facts}: {Skepticism}, {Persuasion}, and {Evidence} in {Science}},
	publisher = {MIT Press},
	author = {Leng, G and Leng, R. I},
	year = {2020},
}

@article{robinson2011,
	title = {A {Systematic} {Examination} of the {Citation} of {Prior} {Research} in {Reports} of {Randomized}, {Controlled} {Trials}},
	volume = {154},
	issn = {0003-4819},
	url = {https://www.acpjournals.org/doi/10.7326/0003-4819-154-1-201101040-00007},
	doi = {10.7326/0003-4819-154-1-201101040-00007},
	abstract = {In reports of RCTs published over 4 decades, fewer than 25\% of preceding trials were cited, comprising fewer than 25\% of the participants enrolled in all relevant prior trials. A median of 2 trials was cited, regardless of the number of prior trials that had been conducted. Research is needed to explore the explanations for and consequences of this phenomenon. Potential implications include ethically unjustifiable trials, wasted resources, incorrect conclusions, and unnecessary risks for trial participants.},
	number = {1},
	urldate = {2021-08-03},
	journal = {Annals of Internal Medicine},
	author = {Robinson, Karen A. and Goodman, Steven N.},
	month = jan,
	year = {2011},
	note = {Publisher: American College of Physicians},
	pages = {50--55},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/NAWJBHN3/Robinson and Goodman - 2011 - A Systematic Examination of the Citation of Prior .pdf:application/pdf},
}

@article{irwin2009,
	title = {The {Role} of {Conflict} of {Interest} in {Reporting} of {Scientific} {Information}},
	volume = {136},
	issn = {0012-3692},
	url = {https://www.sciencedirect.com/science/article/pii/S001236920960430X},
	doi = {10.1378/chest.09-0890},
	abstract = {We have come to appreciate that scientific misconduct is often not intuitively obvious to those who perpetrate it. Therefore, this commentary has been written to review what we know about the role of conflict of interest (COI) in the reporting of scientific information and to challenge those of us in educator roles to do a better job in mentoring our trainees, junior faculty, and associates on what is right and wrong; what is ethical and unethical. The review addresses the following questions: (1) Why has the public trust in the clinical research industry been eroded? (2) How often is the ethical concept of equipoise violated in industry-sponsored randomized controlled clinical trials? (3) How often are negative trials underreported and favorable trials selectively or redundantly over-reported in industry-sponsored randomized controlled clinical trials? (4) What is being done to restore the public trust? While there are multiple strategies to mitigate COI in the reporting of scientific information, we have come to appreciate that the disclosure of potential conflicts of interest is not enough. It is our hope that this article and its contents can serve as a stimulus for the development and incorporation of an educational series in all training programs on what is ethical and unethical in the conducting and reporting of scientific studies.},
	language = {en},
	number = {1},
	urldate = {2021-08-03},
	journal = {Chest},
	author = {Irwin, Richard S.},
	month = jul,
	year = {2009},
	pages = {253--259},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/F55K7NNT/Irwin - 2009 - The Role of Conflict of Interest in Reporting of S.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/LN8LKNHT/S001236920960430X.html:text/html},
}

@article{friedman2004,
	title = {Relationship {Between} {Conflicts} of {Interest} and {Research} {Results}},
	volume = {19},
	issn = {0884-8734},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1494677/},
	doi = {10.1111/j.1525-1497.2004.30617.x},
	abstract = {CONTEXT
To date, research regarding the influence of conflicts of interest on the presentation of findings by researchers has been limited.

OBJECTIVE
To evaluate the sources of funding for published manuscripts, and association between reported findings and conflicts of interest.

METHODS
Data from both print and electronic issues of The New England Journal of Medicine (NEJM) and The Journal of the American Medical Association (JAMA) were analyzed for sources of funding, areas of investigation, conflict of interest (COI), and presentation of results. We reviewed all original manuscripts published during the year 2001 within NEJM (N = 193) and JAMA (N = 205). We use 3 definitions for COI in this paper: a broadly defined criterion, the criterion used by The International Council of Medical Journal Editors (ICMJE), and a criterion defined by the authors.

RESULTS
Depending on the COI criteria used, 16.6\% to 32.6\% of manuscripts had 1 or more author with COI. Based on ICMJE criterion, 38.7\% of studies investigating drug treatments had authors with COI. We observed a strong association between those studies whose authors had COI and reported positive findings (P {\textless} .001). When controlling for sample size, study design, and country of primary authors, we observed a strong association between positive results and COI (ICMJE definition) among all treatment studies (adjusted odds ratio [OR], 2.35; 95\% confidence interval [CI], 1.08 to 5.09) and drug studies alone (OR, 2.64; 95\% CI, 1.09 to 6.39).

CONCLUSION
COI is widespread among the authors of published manuscripts and these authors are more likely to present positive findings.},
	number = {1},
	urldate = {2021-08-03},
	journal = {Journal of General Internal Medicine},
	author = {Friedman, Lee S and Richter, Elihu D},
	month = jan,
	year = {2004},
	pmid = {14748860},
	pmcid = {PMC1494677},
	pages = {51--56},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/VUUBYX4B/Friedman and Richter - 2004 - Relationship Between Conflicts of Interest and Res.pdf:application/pdf},
}

@book{mahoney1976,
	address = {Cambridge, MA},
	title = {Scientist as {Subject}: {The} {Psychological} {Imperative}},
	publisher = {Ballinger Publishing Company},
	author = {Mahoney, Michael J},
	year = {1976},
}

@article{ferguson2012,
	title = {A {Vast} {Graveyard} of {Undead} {Theories}: {Publication} {Bias} and {Psychological} {Science}’s {Aversion} to the {Null}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {A {Vast} {Graveyard} of {Undead} {Theories}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612459059},
	doi = {10.1177/1745691612459059},
	abstract = {Publication bias remains a controversial issue in psychological science.The tendency of psychological science to avoid publishing null results produces a situation that limits the replicability assumption of science, as replication cannot be meaningful without the potential acknowledgment of failed replications.We argue that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.},
	language = {en},
	number = {6},
	urldate = {2021-08-03},
	journal = {Perspectives on Psychological Science},
	author = {Ferguson, Christopher J. and Heene, Moritz},
	month = nov,
	year = {2012},
	pages = {555--561},
	file = {Ferguson and Heene - 2012 - A Vast Graveyard of Undead Theories Publication B.pdf:/Users/dorothybishop/Zotero/storage/ETEMJXK7/Ferguson and Heene - 2012 - A Vast Graveyard of Undead Theories Publication B.pdf:application/pdf},
}

@book{christensen2019,
	address = {Oakland, CA},
	title = {Transparent and reproducible social science research: {How} to do open science.},
	publisher = {University of California Press},
	author = {Christensen, G and Freese, J and Miguel, E},
	year = {2019},
}

@article{deangelis2004,
	title = {Clinical trial registration: a statement from the {International} {Committee} of {Medical} {Journal} {Editors}},
	volume = {364},
	issn = {1474-547X},
	shorttitle = {Clinical trial registration},
	doi = {10.1016/S0140-6736(04)17034-7},
	language = {eng},
	number = {9438},
	journal = {Lancet (London, England)},
	author = {De Angelis, Catherine and Drazen, Jeffrey M. and Frizelle, Frank A. and Haug, Charlotte and Hoey, John and Horton, Richard and Kotzin, Sheldon and Laine, Christine and Marusic, Ana and Overbeke, A. John P. M. and Schroeder, Torben V. and Sox, Hal C. and Van Der Weyden, Martin B. and {International Committee of Medical Journal Editors}},
	month = sep,
	year = {2004},
	pmid = {15364170},
	keywords = {Registries, Clinical Trials as Topic, Biomedical and Behavioral Research, Editorial Policies, International Committee of Medical Journal Editors, Periodicals as Topic},
	pages = {911--912},
}

@techreport{hardwicke2021,
	title = {Preregistration: {A} pragmatic tool to reduce bias and calibrate confidence in scientific research},
	shorttitle = {Preregistration},
	url = {https://osf.io/preprints/metaarxiv/d7bcu/},
	abstract = {Scientific research is performed by fallible humans. Degrees of freedom in the construction and selection of evidence and hypotheses grant scientists considerable latitude to obtain study outcomes that align more with their preferences than is warranted. This creates a risk of bias and can lead to scientists fooling themselves and fooling others. Preregistration involves archiving study information (e.g., hypotheses, methods, and analyses) in a public registry before data are inspected. This offers two potential benefits: (1) reduce bias by ensuring that research decisions are made independently of study outcomes; and (2) calibrate confidence in research by transparently communicating information about a study’s risk of bias. In this article, we briefly review the historical evolution of preregistration in medicine, psychology, and other domains, clarify its pragmatic functions, discuss relevant meta-research, and provide recommendations for scientists and journal editors.},
	urldate = {2021-08-03},
	institution = {MetaArXiv},
	author = {Hardwicke, Tom E. and Wagenmakers, Eric-Jan},
	month = apr,
	year = {2021},
	doi = {10.31222/osf.io/d7bcu},
	note = {type: article},
	keywords = {bias, Social and Behavioral Sciences, Medicine and Health Sciences, preregistration, transparency, meta-research, multiplicity},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/CLVWMBL4/Hardwicke and Wagenmakers - 2021 - Preregistration A pragmatic tool to reduce bias a.pdf:application/pdf},
}

@article{chalmers2014,
	title = {How to increase value and reduce waste when research priorities are set},
	volume = {383},
	issn = {0140-6736, 1474-547X},
	url = {https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(13)62229-1/abstract},
	doi = {10.1016/S0140-6736(13)62229-1},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}The increase in annual global investment in biomedical research—reaching US\$240 billion in 2010—has resulted in important health dividends for patients and the public. However, much research does not lead to worthwhile achievements, partly because some studies are done to improve understanding of basic mechanisms that might not have relevance for human health. Additionally, good research ideas often do not yield the anticipated results. As long as the way in which these ideas are prioritised for research is transparent and warranted, these disappointments should not be deemed wasteful; they are simply an inevitable feature of the way science works. However, some sources of waste cannot be justified. In this report, we discuss how avoidable waste can be considered when research priorities are set. We have four recommendations. First, ways to improve the yield from basic research should be investigated. Second, the transparency of processes by which funders prioritise important uncertainties should be increased, making clear how they take account of the needs of potential users of research. Third, investment in additional research should always be preceded by systematic assessment of existing evidence. Fourth, sources of information about research that is in progress should be strengthened and developed and used by researchers. Research funders have primary responsibility for reductions in waste resulting from decisions about what research to do.{\textless}/p{\textgreater}},
	language = {English},
	number = {9912},
	urldate = {2021-08-03},
	journal = {The Lancet},
	author = {Chalmers, Iain and Bracken, Michael B. and Djulbegovic, Ben and Garattini, Silvio and Grant, Jonathan and Gülmezoglu, A. Metin and Howells, David W. and Ioannidis, John P. A. and Oliver, Sandy},
	month = jan,
	year = {2014},
	pmid = {24411644},
	note = {Publisher: Elsevier},
	pages = {156--165},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/TS48J33T/Chalmers et al. - 2014 - How to increase value and reduce waste when resear.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/WTHUQCA7/fulltext.html:text/html},
}

@article{law2017,
	title = {Speech and language therapy interventions for children with primary speech and/or language disorders},
	issn = {1465-1858},
	url = {https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD012490/information},
	doi = {10.1002/14651858.CD012490},
	language = {en},
	number = {1},
	urldate = {2021-08-03},
	journal = {Cochrane Database of Systematic Reviews},
	author = {Law, James and Dennis, Jane A. and Charlton, Jenna JV},
	year = {2017},
	note = {Publisher: John Wiley \& Sons, Ltd},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/WIXFQEAV/information.html:text/html;Full Text:/Users/dorothybishop/Zotero/storage/DUF7CF46/Law et al. - 2017 - Speech and language therapy interventions for chil.pdf:application/pdf},
}

@article{law2003,
	title = {Speech and language therapy interventions for children with primary speech and language delay or disorder},
	issn = {1465-1858},
	url = {https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD004110/information},
	doi = {10.1002/14651858.CD004110},
	language = {en},
	number = {3},
	urldate = {2021-08-03},
	journal = {Cochrane Database of Systematic Reviews},
	author = {Law, James and Garrett, Zoe and Nye, Chad},
	year = {2003},
	note = {Publisher: John Wiley \& Sons, Ltd},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/LC4A4AL5/information.html:text/html},
}

@article{law2004,
	title = {The efficacy of treatment for children with developmental speech and language delay/disorder: a meta-analysis},
	volume = {47},
	issn = {1092-4388},
	shorttitle = {The efficacy of treatment for children with developmental speech and language delay/disorder},
	doi = {10.1044/1092-4388(2004/069)},
	abstract = {A meta-analysis was carried out of interventions for children with primary developmental speech and language delays/disorders. The data were categorized depending on the control group used in the study (no treatment, general stimulation, or routine speech and language therapy) and were considered in terms of the effects of intervention on expressive and receptive phonology, syntax, and vocabulary. The outcomes used in the analysis were dependent on the aims of the study; only the primary effects of intervention are considered in this review. These were investigated at the level of the target of therapy, measures of overall linguistic development, and broader measures of linguistic functioning taken from parent report or language samples. Thirty-six articles reporting 33 different trials were found. Of these articles, 25 provided sufficient information for use in the meta-analyses; however, only 13 of these, spanning 25 years, were considered to be sufficiently similar to be combined. The results indicated that speech and language therapy might be effective for children with phonological or expressive vocabulary difficulties. There was mixed evidence concerning the effectiveness of intervention for children with expressive syntax difficulties and little evidence available considering the effectiveness of intervention for children with receptive language difficulties. No significant differences were found between interventions administered by trained parents and those administered by clinicians. The review identified longer duration ({\textgreater}8 weeks) of therapy as being a potential factor in good clinical outcomes. A number of gaps in the evidence base are identified.},
	language = {eng},
	number = {4},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Law, James and Garrett, Zoe and Nye, Chad},
	month = aug,
	year = {2004},
	pmid = {15324296},
	keywords = {Humans, Child, Language Development Disorders, Language Tests, Language Therapy, Phonetics, Linguistics, Randomized Controlled Trials as Topic, Severity of Illness Index},
	pages = {924--943},
}

@misc{higgins2021,
	title = {Cochrane {Handbook} for {Systematic} {Reviews} of {Interventions}, version 6.2 (updated {February} 2021)},
	url = {https://training.cochrane.org/handbook/current},
	language = {en},
	urldate = {2021-08-06},
	author = {Higgins, J P T and Thomas, J and Chandler, J and Cumpston, M and Li, T and Page, M J and Welch, V A},
	year = {2021},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/FJU67HHD/current.html:text/html},
}

@techreport{hemingway2009,
	title = {What is a systematic review? 2nd edition.},
	url = {http://www.bandolier.org.uk/painres/download/whatis/Syst-review.pdf}},
	author = {Hemingway, P and Brereton, N. J.},
	year = {2009},
}

@article{strong2011,
	title = {A systematic meta-analytic review of evidence for the effectiveness of the ‘{Fast} {ForWord}’ language intervention program},
	volume = {52},
	issn = {0021-9630},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3061204/},
	doi = {10.1111/j.1469-7610.2010.02329.x},
	abstract = {Background
Fast ForWord is a suite of computer-based language intervention programs designed to improve children's reading and oral language skills. The programs are based on the hypothesis that oral language difficulties often arise from a rapid auditory temporal processing deficit that compromises the development of phonological representations.

Methods
A systematic review was designed, undertaken and reported using items from the PRISMA statement. A literature search was conducted using the terms ‘Fast ForWord’ ‘Fast For Word’ ‘Fastforword’ with no restriction on dates of publication. Following screening of (a) titles and abstracts and (b) full papers, using pre-established inclusion and exclusion criteria, six papers were identified as meeting the criteria for inclusion (randomised controlled trial (RCT) or matched group comparison studies with baseline equivalence published in refereed journals). Data extraction and analyses were carried out on reading and language outcome measures comparing the Fast ForWord intervention groups to both active and untreated control groups.

Results
Meta-analyses indicated that there was no significant effect of Fast ForWord on any outcome measure in comparison to active or untreated control groups.

Conclusions
There is no evidence from the analysis carried out that Fast ForWord is effective as a treatment for children's oral language or reading difficulties.},
	number = {3},
	urldate = {2021-08-06},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Strong, Gemma K and Torgerson, Carole J and Torgerson, David and Hulme, Charles},
	month = mar,
	year = {2011},
	pmid = {20950285},
	pmcid = {PMC3061204},
	pages = {224--235},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/AH6SDE3D/Strong et al. - 2011 - A systematic meta-analytic review of evidence for .pdf:application/pdf},
}

@misc{zotero-1331,
	title = {Telerehabilitation for people with aphasia: {A} systematic review and meta-analysis {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Telerehabilitation for people with aphasia},
	url = {https://reader.elsevier.com/reader/sd/pii/S0021992421000344?token=3099C6FCDCBACB8B331BF416E1EB56E1B38D0ABDE2EB9CFC553672622DFC385DE73824840E2A805A4BF2B6E4BD4A00CA&originRegion=eu-west-1&originCreation=20210806123944},
	language = {en},
	urldate = {2021-08-06},
	doi = {10.1016/j.jcomdis.2021.106111},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/A7B4MCAL/S0021992421000344.html:text/html},
}

@article{wood2021,
	title = {Is speech and language therapy effective at improving the communication of adults with intellectual disabilities?: {A} systematic review},
	volume = {56},
	issn = {1460-6984},
	shorttitle = {Is speech and language therapy effective at improving the communication of adults with intellectual disabilities?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1460-6984.12601},
	doi = {10.1111/1460-6984.12601},
	abstract = {Background A significant proportion of adults with intellectual disabilities (ID) experience speech, language and communication difficulties which are associated with poor physical and mental health outcomes. Speech and language therapy (SLT) interventions are an important way to address these communication difficulties, yet there is limited available evidence to provide information about the effectiveness of the different approaches used for this heterogeneous group. Aims To review the evidence available for the effectiveness of SLT interventions aimed at improving communication for adults with ID. Methods \& Procedures A systematic search across relevant databases was performed. Information on methodological details of each relevant study, along with descriptions of the SLT interventions employed, were extracted and the Crowe Critical Appraisal Tool (CCAT) was used to assess quality. Findings were discussed in a narrative synthesis grouped by target communication skill. Outcomes \& Results A total of 10 relevant studies met the inclusion criteria. These were predominantly interventions aimed directly at adults with ID to improve speech, increase augmentative and alternative communication (AAC) use and develop interaction skills, with one study addressing work with carers. The included studies were all rated as low quality. There is weak preliminary evidence that SLT input can improve the communication skills of adults with ID. Conclusions \& Implications There is insufficient evidence to draw strong conclusions about the effectiveness of SLT in this population. Further high-level evidence across speech, language and communication domains is urgently needed. What this paper adds What is already known on the subject There is limited evidence for community health interventions used with adults with ID. Previous reviews of SLT interventions found a lack of evidence base for this population. Some areas of SLT practice such as AAC have demonstrated potential benefits and other areas including speech work, social communication skills and training for communication partners have some evidence base for children with ID but there is currently insufficient evidence for adults with ID. What this paper adds to existing knowledge The study systematically reviews the current evidence base available when considering the effectiveness of SLT intervention for adults with ID. It provides weak evidence to suggest SLT intervention can improve communication in this population and highlights the need for clinically relevant, robustly designed studies to be undertaken in this field. What are the potential or actual clinical implications of this work? The lack of high-quality studies with sufficient power to draw conclusions about effectiveness means SLTs are not able to base their intervention choices on firm evidence. There is an urgent need to conduct robust research into the effectiveness of SLT interventions for adults with ID.},
	language = {en},
	number = {2},
	urldate = {2021-08-06},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Wood, Siȃn and Standen, Penny},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1460-6984.12601},
	keywords = {intellectual disabilities, speech and language therapy, systematic review},
	pages = {435--450},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/WTGJ46B8/Wood and Standen - 2021 - Is speech and language therapy effective at improv.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/JURA8JYB/1460-6984.html:text/html},
}

@article{dipper2020,
	title = {Treatment for improving discourse in aphasia: a systematic review and synthesis of the evidence base},
	issn = {0268-7038},
	shorttitle = {Treatment for improving discourse in aphasia},
	url = {https://openaccess.city.ac.uk/id/eprint/24272/},
	doi = {10.1080/02687038.2020.1765305},
	abstract = {Background
Improved discourse production is a priority for all key stakeholders in aphasia rehabilitation. A Cochrane review of randomised controlled trials (RCTs) for aphasia found speech and language therapy treatment to be effective for improving the ability to communicate in everyday interaction. However, this large-scale review did not focus exclusively on treatment for discourse production and did not include other treatment research designs. Thus, the extent of the evidence base addressing discourse interventions is currently unclear.

Objective
The present study undertakes the first systematic review of research on treatment for discourse production in aphasia, appraises the quality of the evidence base; characterises the methods for measuring outcomes; and describes discourse treatment in terms of both content and efficacy.

Design
Scopus, Medline, and EmBase databases were searched, providing 334 records. Twenty-five studies (reporting on 127 participants) met inclusion criteria and were reviewed with the following research questions: What is the quality of the study designs used? How complete is the intervention reporting? What is the range, type, and content of outcome measures used? What is the range, type, and content of discourse treatments reported to date? Are discourse treatments efficacious?

Results
Seven of the 25 studies met the criteria for quality review, with 3 RCTs scoring moderately well and 3 (of 4) case studies scoring moderate-low. Most studies had adequate levels of completeness of treatment reporting, with 3 scoring highly. There were 514 different outcome measures reported across the 25 studies, with measures of words-in-discourse the most common. Studies were grouped into six treatment categories: “word production in discourse”, “sentence production in discourse”, “discourse macrostructure”, “discourse scripts”, “multi-level”, and “no consensus”. Twenty-two studies reported post-treatment gains, most commonly noted in increased word production. Changes in sentence production and discourse macrostructure were present but infrequently assessed.

Conclusions
Discourse treatment is an emerging field of research. Despite limitations in the evidence base, there are clear positive signs that discourse treatment is efficacious. There is emerging evidence for beneficial effects on word and sentence production in discourse, for improved discourse macrostructure, and for treatments working at multiple levels of language. To strengthen the evidence in this field and improve outcomes for people with aphasia, we need more discourse treatment research using an explicit theoretical rationale, high-quality study designs, more complete reporting, and agreed treatment and assessment methods.},
	language = {en},
	urldate = {2021-08-06},
	journal = {Aphasiology},
	author = {Dipper, L. and Marshall, J. and Boyle, M. and Botting, N. and Hersh, D. and Pritchard, M. and Cruice, M.},
	month = jun,
	year = {2020},
	note = {Publisher: Informa UK Limited},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/9KWKXWG3/24272.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/A7X2TJN4/Dipper et al. - 2020 - Treatment for improving discourse in aphasia a sy.pdf:application/pdf},
}

@article{borenstein2007,
	title = {Introduction to {Meta}-{Analysis}},
	language = {en},
	author = {Borenstein, Michael and Hedges, Larry and Rothstein, Hannah},
	year = {2007},
	pages = {37},
	file = {Borenstein et al. - 2007 - Introduction to Meta-Analysis.pdf:/Users/dorothybishop/Zotero/storage/58SSEP87/Borenstein et al. - 2007 - Introduction to Meta-Analysis.pdf:application/pdf},
}

@article{balduzzi2019,
	title = {How to perform a meta-analysis with {R}: a practical tutorial},
	volume = {22},
	copyright = {© Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and permissions. Published by BMJ.},
	issn = {1362-0347, 1468-960X},
	shorttitle = {How to perform a meta-analysis with {R}},
	url = {https://ebmh.bmj.com/content/22/4/153},
	doi = {10.1136/ebmental-2019-300117},
	abstract = {Objective Meta-analysis is of fundamental importance to obtain an unbiased assessment of the available evidence. In general, the use of meta-analysis has been increasing over the last three decades with mental health as a major research topic. It is then essential to well understand its methodology and interpret its results. In this publication, we describe how to perform a meta-analysis with the freely available statistical software environment R, using a working example taken from the field of mental health.
Methods R package meta is used to conduct standard meta-analysis. Sensitivity analyses for missing binary outcome data and potential selection bias are conducted with R package metasens. All essential R commands are provided and clearly described to conduct and report analyses.
Results The working example considers a binary outcome: we show how to conduct a fixed effect and random effects meta-analysis and subgroup analysis, produce a forest and funnel plot and to test and adjust for funnel plot asymmetry. All these steps work similar for other outcome types.
Conclusions R represents a powerful and flexible tool to conduct meta-analyses. This publication gives a brief glimpse into the topic and provides directions to more advanced meta-analysis methods available in R.},
	language = {en},
	number = {4},
	urldate = {2021-08-06},
	journal = {Evidence-Based Mental Health},
	author = {Balduzzi, Sara and Rücker, Gerta and Schwarzer, Guido},
	month = nov,
	year = {2019},
	pmid = {31563865},
	note = {Publisher: Royal College of Psychiatrists
Section: Statistics in practice},
	pages = {153--160},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/M6FDT5A9/153.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/DWTMG92H/Balduzzi et al. - 2019 - How to perform a meta-analysis with R a practical.pdf:application/pdf},
}

@book{borenstein2009,
	title = {Introduction to meta-analysis},
	isbn = {978-0-470-74338-6},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470743386.fmatter},
	abstract = {The prelims comprise: Half-Title Page Title Page Copyright Page Table of Contents List of Tables List of Figures Acknowledgements Preface Web Site},
	language = {en},
	urldate = {2021-08-06},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Borenstein, M and Hedges, L and Higgins, J P T and Rothstein, H},
	year = {2009},
	doi = {10.1002/9780470743386.fmatter},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470743386.fmatter},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/AGU9TNAN/9780470743386.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/PDJX4Z8V/2009 - Front Matter.pdf:application/pdf},
}

@article{button2020,
	title = {Supporting ‘team science’},
	volume = {33},
	url = {https://thepsychologist.bps.org.uk/volume-33/october-2020/supporting-team-science},
	urldate = {2021-08-07},
	journal = {The Psychologist},
	author = {Button, K},
	year = {2020},
	pages = {30--33},
	file = {Supporting ‘team science’ | The Psychologist:/Users/dorothybishop/Zotero/storage/6GVBB8DA/supporting-team-science.html:text/html},
}

@article{button2018,
	title = {Reboot undergraduate courses for reproducibility},
	volume = {561},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-018-06692-8},
	doi = {10.1038/d41586-018-06692-8},
	abstract = {Collaboration across institutes can train students in open, team science, which better prepares them for challenges to come.},
	language = {en},
	number = {7723},
	urldate = {2021-08-07},
	journal = {Nature},
	author = {Button, K},
	month = sep,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: World View
Number: 7723
Publisher: Nature Publishing Group
Subject\_term: Education, Research management},
	pages = {287--287},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/S4QSCW9S/Button - 2018 - Reboot undergraduate courses for reproducibility.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/WC9ABEMU/d41586-018-06692-8.html:text/html},
}

@misc{hernan2018,
	title = {Causal {Inference} from {Observational} {Data}},
	url = {https://www.hsph.harvard.edu/miguel-hernan/research/causal-inference-from-observational-data/},
	abstract = {Try explaining to your extended family that you are considered an expert in causal inference. That’s why, when people ask, I just say that my job is to learn what works for the prevention and…},
	language = {en-us},
	urldate = {2021-08-07},
	journal = {Miguel Hernan's Faculty Website},
	author = {Hernan, Miguel},
	month = aug,
	year = {2018},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/YYUYPZZX/causal-inference-from-observational-data.html:text/html},
}

@article{mcarthur2008,
	title = {Does {What} {Works} {Clearinghouse} {Work}? {A} {Brief} {Review} of {Fast} {ForWord}®},
	volume = {32},
	issn = {1030-0112},
	shorttitle = {Does {What} {Works} {Clearinghouse} {Work}?},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10300110701845953},
	doi = {10.1080/10300110701845953},
	abstract = {The What Works Clearinghouse (WWC) provides online reports to the public about the scientific evidence for educational interventions. The quality of these reports is important because they effectively tell the non‐scientific community which programmes do and do not work. The aim of this brief review is to assess WWC's report on a clinically popular, yet theoretically controversial, intervention called Fast ForWord® (FFW). Some of the methods used by WWC to assess FFW were problematic: the literature review included studies that had not passed peer review; it failed to include a key study that had passed peer review; alphabetic skills were assessed with phonological awareness outcomes; effectiveness ratings were based on statistical significance; terms peculiar to WWC were not clearly defined; and existing quality control procedures failed to detect an error in the WWC report. These problems could be addressed by making minor adjustments to WWC's existing methods and by subjecting WWC reports to the scientific peer‐review process before they are released to the public.},
	number = {1},
	urldate = {2021-08-08},
	journal = {Australasian Journal of Special Education},
	author = {McArthur, Genevieve},
	month = apr,
	year = {2008},
	note = {Publisher: Routledge
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/10300110701845953},
	pages = {101--107},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/7CWLZ5QU/10300110701845953.html:text/html},
}

@article{cohen2005,
	title = {Effects of {Computer}-{Based} {Intervention} {Through} {Acoustically} {Modified} {Speech} ({Fast} {ForWord}) in {Severe} {Mixed} {Receptive}—{Expressive} {Language} {Impairment}},
	volume = {48},
	url = {https://pubs.asha.org/doi/10.1044/1092-4388(2005/049)},
	doi = {10.1044/1092-4388(2005/049)},
	abstract = {Seventy-seven children between the ages of 6 and 10 years, with severe mixed receptive-expressive specific language impairment (SLI), participated in a randomized controlled trial (RCT) of Fast ForWord (FFW; Scientific Learning Corporation, 1997, 2001). FFW is a computer-based intervention for treating SLI using acoustically enhanced speech stimuli. These stimuli are modified to exaggerate their time and intensity properties as part of an adaptive training process. All children who participated in the RCT maintained their regular speech and language therapy and school regime throughout the trial. Standardized measures of receptive and expressive language were used to assess performance at baseline and to measure outcome from treatment at 9 weeks and 6 months. Children were allocated to 1 of 3 groups. Group A (n=23) received the FFWintervention as a home-based therapy for 6 weeks. Group B (n=27) received commercially available computer-based activities designed to promote language as a control for computer games exposure. Group C (n=27) received no additional study intervention. Each group made significant gains in language scores, but there was no additional effect for either computer intervention. Thus, the findings from this RCT do not support the efficacy of FFW as an intervention for children with severe mixed receptive-expressive SLI.},
	number = {3},
	urldate = {2021-08-08},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Cohen, Wendy and Hodson, Ann and O, 'Hare Anne and Boyle, James and Durrani, Tariq and McCartney, Elspeth and Mattey, Mike and Naftalin, Lionel and Watson, Jocelynne},
	month = jun,
	year = {2005},
	note = {Publisher: American Speech-Language-Hearing Association},
	keywords = {computer applications, Fast ForWord, language disorders, randomized controlled trial},
	pages = {715--729},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/5T8ZKTTZ/Cohen et al. - 2005 - Effects of Computer-Based Intervention Through Aco.pdf:application/pdf},
}

@article{green2017,
	title = {Randomised trial of a parent‐mediated intervention for infants at high risk for autism: longitudinal outcomes to age 3 years},
	volume = {58},
	issn = {0021-9630},
	shorttitle = {Randomised trial of a parent‐mediated intervention for infants at high risk for autism},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5724485/},
	doi = {10.1111/jcpp.12728},
	abstract = {Background
There has been increasing interest in the potential for pre‐emptive interventions in the prodrome of autism, but little investigation as to their effect.

Methods
A two‐site, two‐arm assessor‐blinded randomised controlled trial (RCT) of a 12‐session parent‐mediated social communication intervention delivered between 9 and 14 months of age (Intervention in the British Autism Study of Infant Siblings‐Video Interaction for Promoting Positive Parenting), against no intervention. Fifty‐four infants (28 intervention, 26 nonintervention) at familial risk of autism but not otherwise selected for developmental atypicality were assessed at 9‐month baseline, 15‐month treatment endpoint, and 27‐ and 39‐month follow‐up. Primary outcome: severity of autism prodromal symptoms, blind‐rated on Autism Observation Schedule for Infants or Autism Diagnostic Observation Schedule 2nd Edition across the four assessment points. Secondary outcomes: blind‐rated parent–child interaction and child language; nonblind parent‐rated communication and socialisation. Prespecified intention‐to‐treat analysis combined estimates from repeated measures within correlated regressions to estimate the overall effect of the infancy intervention over time.

Results
Effect estimates in favour of intervention on autism prodromal symptoms, maximal at 27 months, had confidence intervals (CIs) at each separate time point including the null, but showed a significant overall effect over the course of the intervention and follow‐up period (effect size [ES] = 0.32; 95\% CI 0.04, 0.60; p = .026). Effects on proximal intervention targets of parent nondirectiveness/synchrony (ES = 0.33; CI 0.04, 0.63; p = .013) and child attentiveness/communication initiation (ES = 0.36; 95\% CI 0.04, 0.68; p = .015) showed similar results. There was no effect on categorical diagnostic outcome or formal language measures.

Conclusions
Follow‐up to 3 years of the first RCT of a very early social communication intervention for infants at familial risk of developing autism has shown a treatment effect, extending 24 months after intervention end, to reduce the overall severity of autism prodromal symptoms and enhance parent–child dyadic social communication over this period. We highlight the value of extended follow‐up and repeat assessment for early intervention trials.},
	number = {12},
	urldate = {2021-08-08},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Green, Jonathan and Pickles, Andrew and Pasco, Greg and Bedford, Rachael and Wan, Ming Wai and Elsabbagh, Mayada and Slonims, Vicky and Gliga, Teea and Jones, Emily and Cheung, Celeste and Charman, Tony and Johnson, Mark and Baron‐Cohen, Simon and Bolton, Patrick and Davies, Kim and Liew, Michelle and Fernandes, Janice and Gammer, Isobel and Salomone, Erica and Ribeiro, Helena and Tucker, Leslie and Taylor, Carol and Booth, Rhonda and Harrop, Claire and Holsgrove, Samina and McNally, Janet},
	month = dec,
	year = {2017},
	pmid = {28393350},
	pmcid = {PMC5724485},
	pages = {1330--1340},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/MWVXNIBV/Green et al. - 2017 - Randomised trial of a parent‐mediated intervention.pdf:application/pdf},
}

@article{morris2007,
	title = {Masking is better than blinding},
	volume = {334},
	copyright = {© BMJ Publishing Group Ltd 2007},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/content/334/7597/799},
	doi = {10.1136/bmj.39175.503299.94},
	abstract = {{\textless}p{\textgreater}Why the term “blinding” should not be used in clinical trials{\textless}/p{\textgreater}},
	language = {en},
	number = {7597},
	urldate = {2021-08-09},
	journal = {BMJ},
	author = {Morris, Daniel and Fraser, Scott and Wormald, Richard},
	month = apr,
	year = {2007},
	note = {Publisher: British Medical Journal Publishing Group
Section: Views \&amp; Reviews},
	pages = {799--799},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/SKVZJBKC/Morris et al. - 2007 - Masking is better than blinding.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/634APA8X/799.html:text/html},
}

@article{schulz2007,
	title = {Blinding is better than masking},
	volume = {334},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1865441/},
	doi = {10.1136/bmj.39199.461644.3A},
	number = {7600},
	urldate = {2021-08-09},
	journal = {BMJ : British Medical Journal},
	author = {Schulz, Kenneth F and Altman, Douglas G and Moher, David},
	month = may,
	year = {2007},
	pmid = {null},
	pmcid = {PMC1865441},
	pages = {918},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/WFDYRC8N/Schulz et al. - 2007 - Blinding is better than masking.pdf:application/pdf},
}

@book{lo2009,
	address = {Washington, DC},
	title = {Conflict of {Interest} in {Medical} {Research}, {Education}, and {Practice}},
	isbn = {13: 978-0-309-13188-9},
	publisher = {National Academies Press},
	author = {Lo, B and Field, M. J},
	year = {2009},
}

@article{barber1968,
	title = {Fact, fiction, and the experimenter bias effect},
	volume = {70},
	issn = {1939-1455(Electronic),0033-2909(Print)},
	doi = {10.1037/h0026724},
	abstract = {Critically analyzes 31 studies which attempted to demonstrate that Es' expectancies and desires significantly affect the experimental outcome (E bias effect). The majority of studies do not clearly demonstrate the effect. Many of these studies are criticized for inadequacies in the analysis of results, e.g., failure to perform an overall statistical analysis to exclude the null hypothesis and failure to avoid probability pyramiding when postmortem tests are performed. 2 conclusions are drawn: (1) The E bias effect appears to be more difficult to demonstrate and less pervasive than was implied in previous reviews in this journal. (2) In those instances in which the effect was obtained, it was apparently due to one or more of the following: the student Es misjudged, misrecorded or misreported the results; they verbally reinforced their Ss for expected responses; or they intentionally or unintentionally transmitted their expectancies and desires by paralinguistic or kinesic cues. (2 p. ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6, Pt.2},
	journal = {Psychological Bulletin},
	author = {Barber, Theodore X. and Silver, Maurice J.},
	year = {1968},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Experimentation, Methodology, Expectations, Literature Review, Prejudice},
	pages = {1--29},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/I5UH93QY/1969-06146-001.html:text/html},
}

@techreport{schonbrodt2016,
	title = {p-hacker: {Train} your p-hacking skills!},
	url = {http://shinyapps.org/apps/p-hacker/},
	author = {Schönbrodt, F D},
	year = {2016},
}

@article{singal2014,
	title = {A {Primer} on {Effectiveness} and {Efficacy} {Trials}},
	volume = {5},
	issn = {2155-384X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3912314/},
	doi = {10.1038/ctg.2013.13},
	abstract = {Although efficacy and effectiveness studies are both important when evaluating interventions, they serve distinct purposes and have different study designs. Unfortunately, the distinction between these two types of trials is often poorly understood. In this primer, we highlight several differences between these two types of trials including study design, patient populations, intervention design, data analysis, and result reporting.},
	number = {1},
	urldate = {2021-08-09},
	journal = {Clinical and Translational Gastroenterology},
	author = {Singal, Amit G and Higgins, Peter D R and Waljee, Akbar K},
	month = jan,
	year = {2014},
	pmid = {24384867},
	pmcid = {PMC3912314},
	pages = {e45},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/AS2YSSWM/Singal et al. - 2014 - A Primer on Effectiveness and Efficacy Trials.pdf:application/pdf},
}

@article{treweek2009,
	title = {Making trials matter: pragmatic and explanatory trials and the problem of applicability},
	volume = {10},
	issn = {1745-6215},
	shorttitle = {Making trials matter},
	url = {https://doi.org/10.1186/1745-6215-10-37},
	doi = {10.1186/1745-6215-10-37},
	abstract = {Randomised controlled trials are the best research design for decisions about the effect of different interventions but randomisation does not, of itself, promote the applicability of a trial's results to situations other than the precise one in which the trial was done. While methodologists and trialists have rightly paid great attention to internal validity, much less has been given to applicability.},
	number = {1},
	urldate = {2021-08-09},
	journal = {Trials},
	author = {Treweek, Shaun and Zwarenstein, Merrick},
	month = jun,
	year = {2009},
	keywords = {Chronic Obstructive Pulmonary Disease, Directly Observe Treatment, Explanatory Trial, Pragmatic Trial, Rofecoxib},
	pages = {37},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/TVJQI7CF/Treweek and Zwarenstein - 2009 - Making trials matter pragmatic and explanatory tr.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/TH787I75/1745-6215-10-37.html:text/html},
}

@article{thorlund2018,
	title = {Key design considerations for adaptive clinical trials: a primer for clinicians},
	volume = {360},
	copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions. This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
	issn = {0959-8138, 1756-1833},
	shorttitle = {Key design considerations for adaptive clinical trials},
	url = {https://www.bmj.com/content/360/bmj.k698},
	doi = {10.1136/bmj.k698},
	abstract = {{\textless}p{\textgreater}This article reviews important considerations for researchers who are designing adaptive clinical trials. These differ from conventional clinical trials because they allow and even enforce continual modifications to key components of trial design while data are being collected. This innovative approach has the potential to reduce resource use, decrease time to trial completion, limit allocation of participants to inferior interventions, and improve the likelihood that trial results will be scientifically or clinically relevant. Adaptive designs have mostly been used in trials evaluating drugs, but their use is spreading. The US Food and Drug Administration recently issued guidance on adaptive trial designs, which highlighted general principles and different types of adaptive clinical trials but did not provide concrete guidance about important considerations in designing such trials. Decisions to adapt a trial are not arbitrary; they are based on decision rules that have been rigorously examined via statistical simulations before the first trial participant is enrolled. The authors review important characteristics of adaptive trials and common types of study modifications and provide a practical guide, illustrated with a case study, to aid investigators who are planning an adaptive clinical trial{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-08-09},
	journal = {BMJ},
	author = {Thorlund, Kristian and Haggstrom, Jonas and Park, Jay JH and Mills, Edward J.},
	month = mar,
	year = {2018},
	pmid = {29519932},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research Methods \&amp; Reporting},
	pages = {k698},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/ZWTMQRBK/bmj.html:text/html;Full Text PDF:/Users/dorothybishop/Zotero/storage/NQ8YUESV/Thorlund et al. - 2018 - Key design considerations for adaptive clinical tr.pdf:application/pdf},
}

@article{sibbald1998,
	title = {Understanding controlled trials {Crossover} trials},
	volume = {316},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1113275/},
	number = {7146},
	urldate = {2021-08-10},
	journal = {BMJ : British Medical Journal},
	author = {Sibbald, Bonnie and Roberts, Chris},
	month = jun,
	year = {1998},
	pmid = {9614025},
	pmcid = {PMC1113275},
	pages = {1719--1720},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/9P5C9G3Z/Sibbald and Roberts - 1998 - Understanding controlled trials Crossover trials.pdf:application/pdf},
}

@misc{westrick,
	title = {{LibGuides}: {Systematic} {Reviews}: {Systematic} {Review} or {Literature} {Review}?},
	copyright = {Copyright Rush University Medical Center 2021},
	shorttitle = {{LibGuides}},
	url = {https://rushu.libguides.com/c.php?g=595495&p=4585490},
	abstract = {LibGuides: Systematic Reviews: Systematic Review or Literature Review?},
	language = {en},
	urldate = {2021-08-10},
	author = {Westrick, Jennifer},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/DRJR49EB/c.html:text/html},
}

@article{baek2013,
	title = {Multilevel models for multiple-baseline data: modeling across-participant variation in autocorrelation and residual variance},
	volume = {45},
	issn = {1554-3528},
	shorttitle = {Multilevel models for multiple-baseline data},
	url = {https://doi.org/10.3758/s13428-012-0231-z},
	doi = {10.3758/s13428-012-0231-z},
	abstract = {Multilevel models (MLM) have been used as a method for analyzing multiple-baseline single-case data. However, some concerns can be raised because the models that have been used assume that the Level-1 error covariance matrix is the same for all participants. The purpose of this study was to extend the application of MLM of single-case data in order to accommodate across-participant variation in the Level-1 residual variance and autocorrelation. This more general model was then used in the analysis of single-case data sets to illustrate the method, to estimate the degree to which the autocorrelation and residual variances differed across participants, and to examine whether inferences about treatment effects were sensitive to whether or not the Level-1 error covariance matrix was allowed to vary across participants. The results from the analyses of five published studies showed that when the Level-1 error covariance matrix was allowed to vary across participants, some relatively large differences in autocorrelation estimates and error variance estimates emerged. The changes in modeling the variance structure did not change the conclusions about which fixed effects were statistically significant in most of the studies, but there was one exception. The fit indices did not consistently support selecting either the more complex covariance structure, which allowed the covariance parameters to vary across participants, or the simpler covariance structure. Given the uncertainty in model specification that may arise when modeling single-case data, researchers should consider conducting sensitivity analyses to examine the degree to which their conclusions are sensitive to modeling choices.},
	language = {en},
	number = {1},
	urldate = {2021-08-10},
	journal = {Behavior Research Methods},
	author = {Baek, Eun Kyeng and Ferron, John M.},
	month = mar,
	year = {2013},
	pages = {65--74},
	file = {Springer Full Text PDF:/Users/dorothybishop/Zotero/storage/4XJWW897/Baek and Ferron - 2013 - Multilevel models for multiple-baseline data mode.pdf:application/pdf},
}

@article{rabbitt2004,
	title = {Practice and drop-out effects during a 17-year longitudinal study of cognitive aging},
	volume = {59},
	issn = {1079-5014},
	doi = {10.1093/geronb/59.2.p84},
	abstract = {Interpretations of longitudinal studies of cognitive aging are misleading unless effects of practice and selective drop-out are considered. A random effects model taking practice and drop-out into account analyzed data from four successive presentations of each of two intelligence tests, two vocabulary tests, and two verbal memory tests during a 17-year longitudinal study of 5,899 community residents whose ages ranged from 49 to 92 years. On intelligence tests, substantial practice effects counteracted true declines observed over 3 to 5 years of aging and remained significant even with intervals of 7 years between successive assessments. Adjustment for practice and drop-out revealed accelerating declines in fluid intelligence and cumulative learning, linear declines in verbal free recall, and no substantial change in vocabulary. Socioeconomic status and basal levels of general fluid ability did not affect rates of decline. After further adjustment for demographics, variability between individuals was seen to increase as the sample aged.},
	language = {eng},
	number = {2},
	journal = {The Journals of Gerontology. Series B, Psychological Sciences and Social Sciences},
	author = {Rabbitt, Patrick and Diggle, Peter and Holland, Fiona and McInnes, Lynn},
	month = mar,
	year = {2004},
	pmid = {15014091},
	keywords = {Female, Humans, Male, Middle Aged, Learning, Aging, Aged, Aged, 80 and over, Neuropsychological Tests, Bias, Practice, Psychological, Cohort Studies, Cognition, Longitudinal Studies, Intelligence, Mental Recall, Models, Statistical, Patient Dropouts, Verbal Learning, Vocabulary, Wechsler Scales},
	pages = {P84--97},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/3WU4NKFT/Rabbitt et al. - 2004 - Practice and drop-out effects during a 17-year lon.pdf:application/pdf},
}

@article{zhang2003,
	title = {Explaining and controlling regression to the mean in longitudinal research designs},
	volume = {46},
	issn = {1092-4388},
	doi = {10.1044/1092-4388(2003/104)},
	abstract = {This tutorial is concerned with examining how regression to the mean influences research findings in longitudinal studies of clinical populations. In such studies participants are often obtained because of performance that deviates systematically from the population mean and are then subsequently studied with respect to change in the trait used for this selection. It is shown that in such research there is a potential for the estimates of change to be erroneous due to the effect of regression to the mean. The source of the regression effect is shown to arise from measurement error and a sampling bias of this measurement error in the process of selecting on extreme scores. It is also shown that regression effects are greater with measures that are less reliable and with samples that are selected with more extreme scores. Furthermore, it is shown that regression effects are particularly prominent when measures of change are based on changes in dichotomous states formed from quantitative, normally distributed traits. In addition to a formal analysis of the regression to the mean, the features of regression to the mean are demonstrated via a simulation.},
	language = {eng},
	number = {6},
	journal = {Journal of speech, language, and hearing research: JSLHR},
	author = {Zhang, Xuyang and Tomblin, J. Bruce},
	month = dec,
	year = {2003},
	pmid = {14700359},
	keywords = {Humans, Reproducibility of Results, Language Disorders, Longitudinal Studies, Research Design, Normal Distribution, Regression Analysis},
	pages = {1340--1351},
}

@article{simonsohn2014,
	title = {p-{Curve} and {Effect} {Size}: {Correcting} for {Publication} {Bias} {Using} {Only} {Significant} {Results}},
	volume = {9},
	issn = {1745-6916},
	shorttitle = {p-{Curve} and {Effect} {Size}},
	url = {https://doi.org/10.1177/1745691614553988},
	doi = {10.1177/1745691614553988},
	abstract = {Journals tend to publish only statistically significant evidence, creating a scientific record that markedly overstates the size of effects. We provide a new tool that corrects for this bias without requiring access to nonsignificant results. It capitalizes on the fact that the distribution of significant p values, p-curve, is a function of the true underlying effect. Researchers armed only with sample sizes and test results of the published findings can correct for publication bias. We validate the technique with simulations and by reanalyzing data from the Many-Labs Replication project. We demonstrate that p-curve can arrive at conclusions opposite that of existing tools by reanalyzing the meta-analysis of the “choice overload” literature.},
	language = {en},
	number = {6},
	urldate = {2021-08-12},
	journal = {Perspectives on Psychological Science},
	author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
	month = nov,
	year = {2014},
	note = {Publisher: SAGE Publications Inc},
	keywords = {publication bias, p-curve, p-hacking},
	pages = {666--681},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/F7EZW93E/Simonsohn et al. - 2014 - p-Curve and Effect Size Correcting for Publicatio.pdf:application/pdf},
}

@article{simonsohn2014a,
	title = {P-curve: a key to the file-drawer},
	volume = {143},
	issn = {1939-2222},
	shorttitle = {P-curve},
	doi = {10.1037/a0033242},
	abstract = {Because scientists tend to report only studies (publication bias) or analyses (p-hacking) that "work," readers must ask, "Are these effects true, or do they merely reflect selective reporting?" We introduce p-curve as a way to answer this question. P-curve is the distribution of statistically significant p values for a set of studies (ps {\textless} .05). Because only true effects are expected to generate right-skewed p-curves-containing more low (.01s) than high (.04s) significant p values--only right-skewed p--curves are diagnostic of evidential value. By telling us whether we can rule out selective reporting as the sole explanation for a set of findings, p-curve offers a solution to the age-old inferential problems caused by file-drawers of failed studies and analyses.},
	language = {eng},
	number = {2},
	journal = {Journal of Experimental Psychology. General},
	author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
	month = apr,
	year = {2014},
	pmid = {23855496},
	keywords = {Humans, Reproducibility of Results, Statistics as Topic, Data Interpretation, Statistical, Models, Statistical, Psychology, Experimental, Publication Bias},
	pages = {534--547},
}

@article{pico,
	title = {Interventions {Designed} to {Improve} {Narrative} {Language} in {School}-{Age} {Children}: {A} {Systematic} {Review} {With} {Meta}-{Analyses}},
	shorttitle = {Interventions {Designed} to {Improve} {Narrative} {Language} in {School}-{Age} {Children}},
	url = {https://pubs.asha.org/doi/10.1044/2021_LSHSS-20-00160},
	doi = {10.1044/2021_LSHSS-20-00160},
	abstract = {Purpose

The purpose of this systematic review with meta-analyses was to examine interventions that aimed to improve narrative language outcomes for preschool and elementary school–age children in the United States. Our goal was to examine peer-reviewed publications to describe the characteristics of these interventions and synthesize their overall effectiveness on narrative comprehension and production via meta-analysis.

Method

We searched electronic databases, examined previously published reviews, and consulted experts in the field to identify published studies that employed robust experimental and quasi-experimental designs. We included randomized controlled trials, studies with nonrandomized comparison groups, and single-case design (SCD) studies. We completed a qualitative synthesis of study factors for all identified studies and calculated meta-analyses for the studies that had sufficient data. All included studies were analyzed for risk of bias.

Results

Our systematic search yielded 40 studies that included one or more narrative language outcomes as part of their assessment battery. Twenty-four of the included studies were group design studies, including randomized controlled trials and quasi-experimental designs, and the other 16 were SCD studies. Effect sizes were analyzed based on narrative production and comprehension outcomes. The meta-analyses of 26 studies indicated overall positive effects of the interventions, with effect sizes of d = 0.51 and 0.54 in the group design studies and d = 1.24 in the SCD studies.

Conclusions

A variety of effective interventions were found that improve narrative production and comprehension outcomes in children with diverse learner characteristics. Some common characteristics across these interventions include manualized curricula, opportunities to produce narrative language, verbal and visual supports, direct instruction of story grammar, and use of authentic children's literature.

Supplemental Material

https://doi.org/10.23641/asha.15079173},
	urldate = {2021-08-12},
	journal = {Language, Speech, and Hearing Services in Schools},
	author = {Pico, Danielle L. and Hessling, Prahl Alison and Biel, Christa Haring and Peterson, Amy K. and Biel, Eric J. and Woods, Christine and Contesse, Valentina A.},
	note = {Publisher: American Speech-Language-Hearing Association},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/33PE8ZAK/Pico et al. - Interventions Designed to Improve Narrative Langua.pdf:application/pdf},
}

@misc{burgoyne2016,
	title = {Reading and language intervention for children with {Down} syndrome: {Experimental} data [data collection]},
	shorttitle = {Reading and language intervention},
	url = {http://doi.org/10.5255/UKDA-SN-852291},
	abstract = {BACKGROUND: This study evaluates the effects of a language and literacy intervention for children with Down syndrome.
METHODS: Teaching assistants (TAs) were trained to deliver a reading and language intervention to children in individual daily 40-min sessions. We used a waiting list control design, in which half the sample received the intervention immediately, whereas the remaining children received the treatment after a 20-week delay. Fifty-seven children with Down syndrome in mainstream primary schools in two U.K. locations (Yorkshire and Hampshire) were randomly allocated to intervention (40 weeks of intervention) and waiting control (20 weeks of intervention) groups. Assessments were conducted at three time points: pre-intervention, after 20 weeks of intervention, and after 40 weeks of intervention.
RESULTS: After 20 weeks of intervention, the intervention group showed significantly greater progress than the waiting control group on measures of single word reading, letter-sound knowledge, phoneme blending and taught expressive vocabulary. Effects did not transfer to other skills (nonword reading, spelling, standardised expressive and receptive vocabulary, expressive information and grammar). After 40 weeks of intervention, the intervention group remained numerically ahead of the control group on most key outcome measures; but these differences were not significant. Children who were younger, attended more intervention sessions, and had better initial receptive language skills made greater progress during the course of the intervention.
CONCLUSIONS: A TA-delivered intervention produced improvements in the reading and language skills of children with Down syndrome. Gains were largest in skills directly taught with little evidence of generalization to skills not directly taught in the intervention.},
	language = {eng},
	author = {Burgoyne, Kelly and Duff, Fiona J. and Clarke, Paula J. and Buckley, Sue and Snowling, Margaret J. and Hulme, Charles},
	year = {2016},
	keywords = {Female, Humans, Male, Language, Child, Dyslexia, Language Development Disorders, Treatment Outcome, Reading, Child, Preschool, Language Therapy, Phonetics, Early Intervention, Educational, United Kingdom, Vocabulary, Down Syndrome, Remedial Teaching},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/ARWU5W8Z/Burgoyne et al. - 2012 - Efficacy of a reading and language intervention fo.pdf:application/pdf},
}

@article{burgoyne2012,
	title = {Efficacy of a reading and language intervention for children with {Down} syndrome: a randomized controlled trial},
	volume = {53},
	issn = {0021-9630},
	shorttitle = {Efficacy of a reading and language intervention for children with {Down} syndrome},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3470928/},
	doi = {10.1111/j.1469-7610.2012.02557.x},
	abstract = {Background
This study evaluates the effects of a language and literacy intervention for children with Down syndrome.

Methods
Teaching assistants (TAs) were trained to deliver a reading and language intervention to children in individual daily 40-min sessions. We used a waiting list control design, in which half the sample received the intervention immediately, whereas the remaining children received the treatment after a 20-week delay. Fifty-seven children with Down syndrome in mainstream primary schools in two UK locations (Yorkshire and Hampshire) were randomly allocated to intervention (40 weeks of intervention) and waiting control (20 weeks of intervention) groups. Assessments were conducted at three time points: pre-intervention, after 20 weeks of intervention, and after 40 weeks of intervention.

Results
After 20 weeks of intervention, the intervention group showed significantly greater progress than the waiting control group on measures of single word reading, letter-sound knowledge, phoneme blending and taught expressive vocabulary. Effects did not transfer to other skills (nonword reading, spelling, standardised expressive and receptive vocabulary, expressive information and grammar). After 40 weeks of intervention, the intervention group remained numerically ahead of the control group on most key outcome measures; but these differences were not significant. Children who were younger, attended more intervention sessions, and had better initial receptive language skills made greater progress during the course of the intervention.

Conclusions
A TA-delivered intervention produced improvements in the reading and language skills of children with Down syndrome. Gains were largest in skills directly taught with little evidence of generalization to skills not directly taught in the intervention.},
	number = {10},
	urldate = {2021-08-12},
	journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},
	author = {Burgoyne, Kelly and Duff, Fiona J and Clarke, Paula J and Buckley, Sue and Snowling, Margaret J and Hulme, Charles},
	month = oct,
	year = {2012},
	pmid = {22533801},
	pmcid = {PMC3470928},
	pages = {1044--1053},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/TVFEQVKH/Burgoyne et al. - 2012 - Efficacy of a reading and language intervention fo.pdf:application/pdf},
}

@article{j2018,
	title = {Different ways to estimate treatment effects in randomised controlled trials},
	volume = {10},
	issn = {2451-8654},
	url = {https://www.sciencedirect.com/science/article/pii/S2451865417301849},
	doi = {10.1016/j.conctc.2018.03.008},
	abstract = {Background
Regarding the analysis of RCT data there is a debate going on whether an adjustment for the baseline value of the outcome variable should be made. When an adjustment is made, there is a lot of misunderstanding regarding the way this should be done. Therefore, the aims of this educational paper are: 1) to explain different methods used to estimate treatment effects in RCTs, 2) to illustrate the different methods with a real life example and 3) to give an advise on how to analyse RCT data.
Methods
Longitudinal analysis of covariance, repeated measures analysis in which also the baseline value is used as outcome and the analysis of changes were theoretically explained and applied to an example dataset investigating a systolic blood pressure lowering treatment.
Results
It was shown that differences at baseline should be taken into account and that regular repeated measures analysis and regular analysis of changes did not adjust for the baseline differences between the groups and therefore lead to biased estimates of the treatment effect. In the real life example, due to the differences at baseline between the treatment and control group, the different methods lead to different estimates of the treatment effect.
Conclusion
Regarding the analysis of RCT data, it is advised to use longitudinal analysis of covariance or a repeated measures analysis without the treatment variable, but with the interaction between treatment and time in the model.},
	language = {en},
	urldate = {2021-08-12},
	journal = {Contemporary Clinical Trials Communications},
	author = {J, Twisk and L, Bosman and T, Hoekstra and J, Rijnhart and M, Welten and M, Heymans},
	month = jun,
	year = {2018},
	keywords = {Analysis of changes, Longitudinal of covariance, Randomised controlled trials, Regression to the mean, Repeated measures},
	pages = {80--85},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/EHVCCZPV/J et al. - 2018 - Different ways to estimate treatment effects in ra.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/9JG9PCRX/S2451865417301849.html:text/html},
}

@article{oconnell2017,
	title = {Methods for {Analysis} of {Pre}-{Post} {Data} in {Clinical} {Research}: {A} {Comparison} of {Five} {Common} {Methods}},
	volume = {8},
	issn = {2155-6180},
	shorttitle = {Methods for {Analysis} of {Pre}-{Post} {Data} in {Clinical} {Research}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6290914/},
	doi = {10.4172/2155-6180.1000334},
	abstract = {Often repeated measures data are summarized into pre-post-treatment measurements. Various methods exist in the literature for estimating and testing treatment effect, including ANOVA, analysis of covariance (ANCOVA), and linear mixed modeling (LMM). Under the first two methods, outcomes can either be modeled as the post treatment measurement (ANOVA-POST or ANCOVA-POST), or a change score between pre and post measurements (ANOVA-CHANGE, ANCOVA-CHANGE). In LMM, the outcome is modeled as a vector of responses with or without Kenward-Rogers adjustment. We consider five methods common in the literature, and discuss them in terms of supporting simulations and theoretical derivations of variance. Consistent with existing literature, our results demonstrate that each method leads to unbiased treatment effect estimates, and based on precision of estimates, 95\% coverage probability, and power, ANCOVA modeling of either change scores or post-treatment score as the outcome, prove to be the most effective. We further demonstrate each method in terms of a real data example to exemplify comparisons in real clinical context.},
	number = {1},
	urldate = {2021-08-13},
	journal = {Journal of biometrics \& biostatistics},
	author = {O'Connell, Nathaniel S. and Dai, Lin and Jiang, Yunyun and Speiser, Jaime L. and Ward, Ralph and Wei, Wei and Carroll, Rachel and Gebregziabher, Mulugeta},
	month = feb,
	year = {2017},
	pmid = {30555734},
	pmcid = {PMC6290914},
	pages = {1--8},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/5ZJBHGPB/O'Connell et al. - 2017 - Methods for Analysis of Pre-Post Data in Clinical .pdf:application/pdf},
}

@article{patsopoulos2011,
	title = {A pragmatic view on pragmatic trials},
	volume = {13},
	issn = {1294-8322},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3181997/},
	abstract = {Clinical trials have been the main tool used by the health sciences community to test and evaluate interventions. Trials can fall into two broad categories: pragmatic and explanatory. Pragmatic trials are designed to evaluate the effectiveness of interventions in real-life routine practice conditions, whereas explanatory trials aim to test whether an intervention works under optimal situations. Pragmatic trials produce results that can be generalized and applied in routine practice settings. Since most results from exploratory trials fail to be broadly generalizable, the “pragmatic design” has gained momentum. This review describes the concept of pragmatism, and explains in particular that there is a continuum between pragmatic and explanatory trials, rather than a dichotomy. Special focus is put on the limitations of the pragmatic trials, while recognizing the importance for and impact of this design on medical practice.},
	number = {2},
	urldate = {2021-08-13},
	journal = {Dialogues in Clinical Neuroscience},
	author = {Patsopoulos, Nikolaos A.},
	month = jun,
	year = {2011},
	pmid = {21842619},
	pmcid = {PMC3181997},
	pages = {217--224},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/CE7YNSBC/Patsopoulos - 2011 - A pragmatic view on pragmatic trials.pdf:application/pdf},
}

@article{porzsolt2015,
	title = {Efficacy and effectiveness trials have different goals, use different tools, and generate different messages},
	volume = {6},
	issn = {1179-7266},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5045025/},
	doi = {10.2147/POR.S89946},
	abstract = {The discussion about the optimal design of clinical trials reflects the perspectives of theory-based scientists and practice-based clinicians. Scientists compare the theory with published results. They observe a continuum from explanatory to pragmatic trials. Clinicians compare the problem they want to solve by completing a clinical trial with the results they can read in the literature. They observe a mixture of what they want and what they get. None of them can solve the problem without the support of the other. Here, we summarize the results of discussions with scientists and clinicians. All participants were interested to understand and analyze the arguments of the other side. As a result of this process, we conclude that scientists tell what they see, a continuum from clear explanatory to clear pragmatic trials. Clinicians tell what they want to see, a clear explanatory trial to describe the expected effects under ideal study conditions and a clear pragmatic trial to describe the observed effects under real-world conditions. Following this discussion, the solution was not too difficult. When we accept what we see, we will not get what we want. If we discuss a necessary change of management, we will end up with the conclusion that two types of studies are necessary to demonstrate efficacy and effectiveness. Efficacy can be demonstrated in an explanatory, ie, a randomized controlled trial (RCT) completed under ideal study conditions. Effectiveness can be demonstrated in an observational, ie, a pragmatic controlled trial (PCT) completed under real-world conditions. It is impossible to design a trial which can detect efficacy and effectiveness simultaneously. The RCTs describe what we may expect in health care, while the PCTs describe what we really observe.},
	urldate = {2021-08-13},
	journal = {Pragmatic and Observational Research},
	author = {Porzsolt, Franz and Rocha, Natália Galito and Toledo-Arruda, Alessandra C and Thomaz, Tania G and Moraes, Cristiane and Bessa-Guerra, Thais R and Leão, Mauricio and Migowski, Arn and Araujo da Silva, André R and Weiss, Christel},
	month = nov,
	year = {2015},
	pmid = {27774032},
	pmcid = {PMC5045025},
	pages = {47--54},
	file = {PubMed Central Full Text PDF:/Users/dorothybishop/Zotero/storage/9R4NJAW3/Porzsolt et al. - 2015 - Efficacy and effectiveness trials have different g.pdf:application/pdf},
}

@article{pallmann2018,
	title = {Adaptive designs in clinical trials: why use them, and how to run and report them},
	volume = {16},
	issn = {1741-7015},
	shorttitle = {Adaptive designs in clinical trials},
	url = {https://doi.org/10.1186/s12916-018-1017-7},
	doi = {10.1186/s12916-018-1017-7},
	abstract = {Adaptive designs can make clinical trials more flexible by utilising results accumulating in the trial to modify the trial’s course in accordance with pre-specified rules. Trials with an adaptive design are often more efficient, informative and ethical than trials with a traditional fixed design since they often make better use of resources such as time and money, and might require fewer participants. Adaptive designs can be applied across all phases of clinical research, from early-phase dose escalation to confirmatory trials. The pace of the uptake of adaptive designs in clinical research, however, has remained well behind that of the statistical literature introducing new methods and highlighting their potential advantages. We speculate that one factor contributing to this is that the full range of adaptations available to trial designs, as well as their goals, advantages and limitations, remains unfamiliar to many parts of the clinical community. Additionally, the term adaptive design has been misleadingly used as an all-encompassing label to refer to certain methods that could be deemed controversial or that have been inadequately implemented.},
	number = {1},
	urldate = {2021-08-14},
	journal = {BMC Medicine},
	author = {Pallmann, Philip and Bedding, Alun W. and Choodari-Oskooei, Babak and Dimairo, Munyaradzi and Flight, Laura and Hampson, Lisa V. and Holmes, Jane and Mander, Adrian P. and Odondi, Lang’o and Sydes, Matthew R. and Villar, Sofía S. and Wason, James M. S. and Weir, Christopher J. and Wheeler, Graham M. and Yap, Christina and Jaki, Thomas},
	month = feb,
	year = {2018},
	keywords = {Adaptive design, Design modification, Flexible design, Interim analysis, Seamless design, Statistical methods},
	pages = {29},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/LMB6U8GL/Pallmann et al. - 2018 - Adaptive designs in clinical trials why use them,.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/BTBTXBMI/s12916-018-1017-7.html:text/html},
}

@misc{ludlow2013,
	title = {Need for {Adaptive} {Research} {Designs} in {Speech}-{Language} {Pathology}},
	url = {https://academy.pubs.asha.org/2013/11/need-for-adaptive-research-designs-in-speech-language-pathology/},
	abstract = {This presentation was delivered as part of a workshop session on the application of adaptive design principles to clinical trials in speech-language pathology. For an overview of adaptive designs, see Adaptive Trial Designs for the Development of Treatment Parameters. The ... Read More},
	language = {en-US},
	urldate = {2021-08-14},
	journal = {ASHA Journals Academy},
	author = {Ludlow, C},
	month = nov,
	year = {2013},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/KVI8BBEW/need-for-adaptive-research-designs-in-speech-language-pathology.html:text/html},
}

@article{kasari2018,
	title = {{SMARTer} {Approach} to {Personalizing} {Intervention} for {Children} {With} {Autism} {Spectrum} {Disorder}},
	volume = {61},
	url = {https://pubs.asha.org/doi/full/10.1044/2018_JSLHR-L-RSAUT-18-0029},
	doi = {10.1044/2018_JSLHR-L-RSAUT-18-0029},
	abstract = {Purpose

This review article introduces research methods for personalization of intervention. Our goals are to review evidence-based practices for improving social communication impairment in children with autism spectrum disorder generally and then how these practices can be systematized in ways that personalize intervention, especially for children who respond slowly to an initial evidence-based practice.

Method

The narrative reflects on the current status of modular and targeted interventions on social communication outcomes in the field of autism research. Questions are introduced regarding personalization of interventions that can be addressed through research methods. These research methods include adaptive treatment designs and the Sequential Multiple Assignment Randomized Trial. Examples of empirical studies using research designs are presented to answer questions of personalization.

Conclusion

Bridging the gap between research studies and clinical practice can be advanced by research that attempts to answer questions pertinent to the broad heterogeneity in children with autism spectrum disorder, their response to interventions, and the fact that a single intervention is not effective for all children.

Presentation Video

https://doi.org/10.23641/asha.7298021},
	number = {11},
	urldate = {2021-08-14},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Kasari, Connie and Sturm, Alexandra and Shih, Wendy},
	month = nov,
	year = {2018},
	note = {Publisher: American Speech-Language-Hearing Association},
	pages = {2629--2640},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/QHFGISSJ/Kasari et al. - 2018 - SMARTer Approach to Personalizing Intervention for.pdf:application/pdf},
}

@article{wilcox2020,
	title = {Preschoolers with developmental speech and/or language impairment: {Efficacy} of the {Teaching} {Early} {Literacy} and {Language} ({TELL}) curriculum},
	volume = {51},
	issn = {0885-2006},
	shorttitle = {Preschoolers with developmental speech and/or language impairment},
	url = {https://www.sciencedirect.com/science/article/pii/S0885200619301292},
	doi = {10.1016/j.ecresq.2019.10.005},
	abstract = {Young children with developmental speech and/or language impairment (DSLI) often fail to develop oral language and early literacy skills that are foundational for subsequent schooling and reading success. The purpose of this investigation was to examine the efficacy of the Teaching Early Literacy and Language (TELL) curriculum and associated evidence-based teaching practices. Participants included 91 preschool classroom teachers and 202 male and 87 female preschoolers with DSLI who were enrolled in their classes. Children ranged in age from 43 to 63 months. In this cluster RCT, classroom teachers were randomly assigned to implement the TELL curriculum or to continue with their business-as-usual (BAU) curriculum. Proximal outcomes were assessed with investigator developed curriculum-based measures (CBMs) administered six times over the school year. Distal tests (pre-post) of oral language and early literacy skills included an investigator-developed pre-post expressive and receptive vocabulary test, two additional standardized measures (Clinical Evaluation of Language Fundamentals-Preschool 2nd Edition, the Test of Preschool Early Literacy). A benchmarked early literacy assessment, the Phonological Awareness and Literacy Screening PreK, was also administered. Results indicated a significant TELL effect for all CBMs at later measurement points with Cohen's ds in the medium (0.43) to very large (1.25) range. TELL effects were also noted for the distal vocabulary measure with small to medium between-group effect sizes (Cohen’s f{\textasciicircum}2 range from 0.02 to 0.44). There were no significant TELL effects for the standardized distal measures. Based on progress measures, the TELL curriculum was effective for improving the oral language and early literacy skills of young children with DSLI.},
	language = {en},
	urldate = {2021-08-14},
	journal = {Early Childhood Research Quarterly},
	author = {Wilcox, M. Jeanne and Gray, Shelley and Reiser, Mark},
	month = apr,
	year = {2020},
	keywords = {Early literacy skills, Oral language, Preschool curriculum efficacy, Speech \& language impairment},
	pages = {124--143},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/IZUNRSBP/Wilcox et al. - 2020 - Preschoolers with developmental speech andor lang.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/AND34VZP/S0885200619301292.html:text/html},
}

@article{neuman2011,
	title = {Educational effects of a vocabulary intervention on preschoolers word knowledge and conceptual development: {A} cluster-randomized trial},
	volume = {46},
	issn = {0034-0553},
	shorttitle = {Educational effects of a vocabulary intervention on preschoolers word knowledge and conceptual development},
	url = {https://nyuscholars.nyu.edu/en/publications/educational-effects-of-a-vocabulary-intervention-on-preschoolers-},
	doi = {10.1598/RRQ.46.3.3},
	language = {English (US)},
	number = {3},
	urldate = {2021-08-14},
	journal = {Reading Research Quarterly},
	author = {Neuman, Susan B. and Newman, Ellen H. and Dwyer, Julie},
	month = jul,
	year = {2011},
	note = {Publisher: International Reading Association},
	pages = {249--272},
	file = {Snapshot:/Users/dorothybishop/Zotero/storage/KVIKLI5F/educational-effects-of-a-vocabulary-intervention-on-preschoolers-.html:text/html},
}

@article{mallick2018,
	title = {A cluster randomised trial of a classroom communication resource program to change peer attitudes towards children who stutter among grade 7 students},
	volume = {19},
	issn = {1745-6215},
	url = {https://doi.org/10.1186/s13063-018-3043-3},
	doi = {10.1186/s13063-018-3043-3},
	abstract = {Classroom-based stuttering intervention addressing negative peer attitudes, perceptions, teasing and bullying of children who stutter (CWS) is required as part of holistic stuttering management because of its occurrence in primary school. This study was conducted in 2017, in 10 primary schools in the Western Cape, South Africa within lower (second and third) and higher (fourth and fifth) quintiles.},
	number = {1},
	urldate = {2021-08-14},
	journal = {Trials},
	author = {Mallick, Rizwana and Kathard, Harsha and Borhan, A. S. M. and Pillay, Mershen and Thabane, Lehana},
	month = nov,
	year = {2018},
	keywords = {Peer Attitudes, Quintile Groups, School Clusters, Significant Subgroup Effect, Subgroup Objects},
	pages = {664},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/4R3TJ9EH/Mallick et al. - 2018 - A cluster randomised trial of a classroom communic.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/NA7LD3PU/s13063-018-3043-3.html:text/html},
}

@techreport{nahum-shani2019,
	title = {An {Introduction} to {Adaptive} {Interventions} and {SMART} {Designs} in {Education}},
	abstract = {Education practice often requires teachers and other school personnel to adapt interventions over time in order to address between-student heterogeneity in response to intervention (e.g., what works for one student may not work for the other) or within-student heterogeneity (e.g., what works now may not work in the future for the same student). An adaptive intervention allows education practitioners to do this in a prespecified, systematic, and replicable way through a sequence of decision rules that guides whether, how, and when to modify interventions. In an adaptive intervention, the practitioner modifies the dosage or type of intervention, or the mode of delivery to meet the unique and changing needs of students as they progress over time. The sequential, multiple assignment, randomized trial (SMART) is one type of multistage, experimental design that can help education researchers build high-quality adaptive interventions. Despite the critical role adaptive interventions can play in various domains of education, research about adaptive interventions and about the use of SMART designs to develop effective adaptive interventions in education is in its infancy. This paper defines an adaptive intervention and reviews the components of this design, discusses the key features of the SMART, and introduces common research questions for which SMARTs may be appropriate.},
	language = {en},
	institution = {US Department of Education: Institute of Education Sciences},
	author = {Nahum-Shani, Inbal and Almirall, Daniel and Buckley, Jacquelyn},
	year = {2019},
	pages = {45},
	file = {Nahum-Shani et al. - An Introduction to Adaptive Interventions and SMAR.pdf:/Users/dorothybishop/Zotero/storage/R87CFJFE/Nahum-Shani et al. - An Introduction to Adaptive Interventions and SMAR.pdf:application/pdf},
}

@article{manolov2017,
	title = {How {Can} {Single}-{Case} {Data} {Be} {Analyzed}? {Software} {Resources}, {Tutorial}, and {Reflections} on {Analysis}},
	volume = {41},
	issn = {0145-4455},
	shorttitle = {How {Can} {Single}-{Case} {Data} {Be} {Analyzed}?},
	url = {https://doi.org/10.1177/0145445516664307},
	doi = {10.1177/0145445516664307},
	abstract = {The present article aims to present a series of software developments in the quantitative analysis of data obtained via single-case experimental designs (SCEDs), as well as the tutorial describing these developments. The tutorial focuses on software implementations based on freely available platforms such as R and aims to bring statistical advances closer to applied researchers and help them become autonomous agents in the data analysis stage of a study. The range of analyses dealt with in the tutorial is illustrated on a typical single-case dataset, relying heavily on graphical data representations. We illustrate how visual and quantitative analyses can be used jointly, giving complementary information and helping the researcher decide whether there is an intervention effect, how large it is, and whether it is practically significant. To help applied researchers in the use of the analyses, we have organized the data in the different ways required by the different analytical procedures and made these data available online. We also provide Internet links to all free software available, as well as all the main references to the analytical techniques. Finally, we suggest that appropriate and informative data analysis is likely to be a step forward in documenting and communicating results and also for increasing the scientific credibility of SCEDs.},
	language = {en},
	number = {2},
	urldate = {2021-08-14},
	journal = {Behavior Modification},
	author = {Manolov, Rumen and Moeyaert, Mariola},
	month = mar,
	year = {2017},
	note = {Publisher: SAGE Publications Inc},
	keywords = {effect size, data analysis, single-case designs, software, tutorial},
	pages = {179--228},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/QM9IIIIZ/Manolov and Moeyaert - 2017 - How Can Single-Case Data Be Analyzed Software Res.pdf:application/pdf},
}

@article{pustejovsky2019,
	title = {An {Examination} of {Measurement} {Procedures} and {Characteristics} of {Baseline} {Outcome} {Data} in {Single}-{Case} {Research}},
	issn = {0145-4455},
	url = {https://doi.org/10.1177/0145445519864264},
	doi = {10.1177/0145445519864264},
	abstract = {There has been growing interest in using statistical methods to analyze data and estimate effect size indices from studies that use single-case designs (SCDs), as a complement to traditional visual inspection methods. The validity of a statistical method rests on whether its assumptions are plausible representations of the process by which the data were collected, yet there is evidence that some assumptions—particularly regarding normality of error distributions—may be inappropriate for single-case data. To develop more appropriate modeling assumptions and statistical methods, researchers must attend to the features of real SCD data. In this study, we examine several features of SCDs with behavioral outcome measures in order to inform development of statistical methods. Drawing on a corpus of over 300 studies, including approximately 1,800 cases, from seven systematic reviews that cover a range of interventions and outcome constructs, we report the distribution of study designs, distribution of outcome measurement procedures, and features of baseline outcome data distributions for the most common types of measurements used in single-case research. We discuss implications for the development of more realistic assumptions regarding outcome distributions in SCD studies, as well as the design of Monte Carlo simulation studies evaluating the performance of statistical analysis techniques for SCD data.},
	language = {en},
	urldate = {2021-08-15},
	journal = {Behavior Modification},
	author = {Pustejovsky, James E. and Swan, Daniel M. and English, Kyle W.},
	month = aug,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {systematic review, alternating renewal process, behavioral observation, single-case research},
	pages = {0145445519864264},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/JTJDRGQK/Pustejovsky et al. - 2019 - An Examination of Measurement Procedures and Chara.pdf:application/pdf},
}

@article{senn2004,
	title = {Controversies concerning randomization and additivity in clinical trials},
	volume = {23},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2074},
	doi = {10.1002/sim.2074},
	abstract = {‘As ye randomise so shall ye analyse’, is one way of describing Fisher's defence of randomization. Yet, when it comes to clinical trials we nearly always randomize but we rarely analyse the way we randomize and Fisher himself was no exception. Two controversies involving Fisher in the 1930s are discussed: one with Neyman concerning additivity and the other with Student concerning randomization. Their relevance today is considered, as is whether randomization inference in clinical trials is dead and whether modelling rules the day, whether minimization is an acceptable procedure and to what extent trialists confuse experiments with surveys. It will be maintained that a number of different possible purposes of clinical trials have been confused because in the case of the general linear model, under strong additivity, they can all be satisfied by a single analysis. More generally, however, this is not the case. Copyright © 2004 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {24},
	urldate = {2021-08-15},
	journal = {Statistics in Medicine},
	author = {Senn, Stephen},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2074},
	keywords = {additivity, clinical trails, history of statistics, randomisation, unit-treatment interaction},
	pages = {3729--3753},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/27L2V8FP/Senn - 2004 - Controversies concerning randomization and additiv.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/FU7GI8UA/sim.html:text/html},
}

@book{chatfield2004,
	address = {Boca Raton},
	title = {The {Analysis} of {Time} {Series}: {An} {Introduction}},
	publisher = {Chapman and Hall},
	author = {Chatfield, C},
	year = {2004},
}

@techreport{foliano2019,
	title = {Changing mindsets: {Effectiveness} trial},
	url = {https://educationendowmentfoundation.org.uk/public/files/Projects/Evaluation_Reports/Changing_Mindsets.pdf},
	abstract = {Pupils in schools that received the intervention did not make any additional progress in literacy nor numeracy—as measured 
by the national Key Stage 2 tests in reading, grammar, punctuation, and spelling (GPS), and maths—compared to pupils 
in the control group. This finding has high security.
 This  evaluation  also  examined  four  measures  of  non-cognitive  skills:  intrinsic  value, self-efficacy,  test  anxiety,  and self-
regulation. The evaluation did not find evidence of an impact on these measures for pupils in schools that received Changing 
Mindsets. A positive impact was found for the intrinsic value measure, but the impact was small and was not statistically 
significant.   
3. Among pupils eligible for free school meals (‘FSM pupils’), those in schools that received the intervention did not make any 
additional progress in literacy nor numeracy—as measured by the national Key Stage 2 tests in reading, GPS, and maths—
compared to FSM pupils in schools that did not receive the intervention.  
4. One explanation for the absence of a measurable impact on pupil attainment is the widespread use of the growth mindset 
theory. Most teachers in the comparison schools (that did not receive the intervention) were familiar with this, and over a 
third reported that they had attended training days based on the growth mindset approach.},
	author = {Foliano, F and Rolfe, H. and Buzzeo, J and Runge, J and Wilkinson, D},
	year = {2019},
}

@article{varley2016,
	title = {Self-{Administered} {Computer} {Therapy} for {Apraxia} of {Speech}},
	volume = {47},
	url = {https://www.ahajournals.org/doi/epub/10.1161/STROKEAHA.115.011939},
	doi = {https://doi.org/10.1161/STROKEAHA.115.011939},
	number = {3},
	urldate = {2021-08-15},
	journal = {Stroke},
	author = {Varley, R and Cowell, P and Dyson, L and Inglis, L and Roper, A and Whiteside, S. P.},
	year = {2016},
	doi = {10.1161/STROKEAHA.115.011939},
	pages = {822--828},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/U6UDUNLJ/Self-Administered Computer Therapy for Apraxia of .pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/S9VFEEAG/STROKEAHA.115.html:text/html},
}

@article{elliott2002,
	title = {What are we doing to waiting list controls?},
	volume = {40},
	issn = {0005-7967},
	doi = {10.1016/s0005-7967(01)00082-1},
	abstract = {For ethical reasons waiting list controls have been preferred to no treatment controls, provided the wait is still shorter than that for routine services. However, could significant differences arise from the wait being detrimental rather than the intervention being beneficial? Despite the number of studies employing this design, few have analysed intervention trials from the perspective of the waiting list controls rather than the experimental group. A Full Day Stress Management Workshop programme which had run successfully in Birmingham, was repeated in three areas in the South East of England. The data from the four areas were reanalysed to assess progress within the control group and to compare the final assessment points for the two groups. The control group did not show any significant deterioration during the three month wait for their workshop. Three months after their respective workshops, scores in the control groups did not differ significantly from those of the experimental group.},
	language = {eng},
	number = {9},
	journal = {Behaviour Research and Therapy},
	author = {Elliott, S. A. and Brown, J. S. L.},
	month = sep,
	year = {2002},
	pmid = {12296489},
	keywords = {Adult, Humans, Cognitive Behavioral Therapy, Ethics, Clinical, Follow-Up Studies, Psychotherapy, Group, Stress, Psychological, Waiting Lists},
	pages = {1047--1052},
}

@article{boyes2021,
	title = {Piloting ‘{Clever} {Kids}’: {A} randomized-controlled trial assessing feasibility, efficacy, and acceptability of a socioemotional well-being programme for children with dyslexia},
	volume = {91},
	issn = {2044-8279},
	shorttitle = {Piloting ‘{Clever} {Kids}’},
	url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/bjep.12401},
	doi = {10.1111/bjep.12401},
	abstract = {Children with dyslexia are at elevated risk of internalizing (emotional) and externalizing (behavioural) problems. Clever Kids is a nine-week socioemotional well-being programme developed specifically for upper primary school children with dyslexia. In a small randomized-controlled trial, we tested the feasibility, efficacy, and acceptability of the Clever Kids programme.‘Forty children (Mage = 10.45 years, 65\% male) with clinically diagnosed dyslexia too part in the study. Children were randomized to either attend Clever Kids (n = 20) or to a wait-list control condition (n = 20). Coping skills, self-esteem, resilience, emotion regulation, and internalizing and externalizing symptoms were measured at pre-programme, post-programme, and at three-month follow-up. Recruitment and retention rates indicate high feasibility for further evaluation of the programme. There was a significant interaction between intervention condition and time for non-productive coping [F(2, 76) = 4.29, p = 0.017, f2 = 0.11]. Children who attended Clever Kids significantly reduced their use of non-productive coping strategies, and this was maintained at three-month follow-up assessment. For all other outcomes, the interactions between intervention condition and time were non-significant. The programme appears acceptable to children with dyslexia and their families, but may be improved by further reducing the number of activities involving reading and writing. Clever Kids improved the coping skills of children with dyslexia; however, a larger trial is needed to replicate this finding and investigate whether programme attendance is associated with additional improvements in children’s socioemotional well-being.},
	language = {en},
	number = {3},
	urldate = {2021-08-16},
	journal = {British Journal of Educational Psychology},
	author = {Boyes, Mark E. and Leitão, Suze and Claessen, Mary and Dzidic, Peta and Badcock, Nicholas A. and Nayton, Mandy},
	year = {2021},
	note = {\_eprint: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/bjep.12401},
	keywords = {dyslexia, coping, mental health, RCT, reading difficulties, self-esteem},
	pages = {e12401},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/IXZPAM2N/Boyes et al. - 2021 - Piloting ‘Clever Kids’ A randomized-controlled tr.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/7CRZL32R/bjep.html:text/html},
}

@article{savenkov2015,
	title = {Testing for {Efficacy} in {Single}-{Subject} {Trials} with {Intervention} {Analysis}},
	url = {http://arxiv.org/abs/1403.4309},
	abstract = {Single subject or n-of-1 research designs have been widely used to evaluate treatment interventions. Many statistical procedures such as split-middle trend lines, regression trend line, Shewart-chart trend line, binomial tests, randomization tests and Tryon C-statistics have been used to analyze single-subject data, but they fail to control Type I error due to serially-dependent time-series observations. The interrupted time series analysis maintains Type I error but assumes that the intervention effect to be a linear trend change from baseline. In this paper, we consider an improved intervention analysis model (Box and Tiao, 1975) for dynamic characteristics of an intervention effect in a short series of single-subject data. The maximum likelihood estimates are derived and a hypothesis testing procedure is proposed. The method is illustrated with a real clinical trial on constraint induced language therapy for aphasia patients.},
	urldate = {2021-08-22},
	journal = {arXiv:1403.4309 [stat]},
	author = {Savenkov, A. and Wu, S. and Neal, D.},
	month = jun,
	year = {2015},
	note = {arXiv: 1403.4309},
	keywords = {Statistics - Applications},
	file = {arXiv.org Snapshot:/Users/dorothybishop/Zotero/storage/2IRS7R54/1403.html:text/html},
}

@book{ledford2018,
	title = {Single {Case} {Research} {Methodology} {Applications} in {Special} {Education} and {Behavioral} {Sciences}, 3rd edition},
	publisher = {Routledge},
	editor = {Ledford, J. R. and Gast, D. L.},
	year = {2018},
}

@article{ledford2019,
	title = {A {Primer} on {Single}-{Case} {Research} {Designs}: {Contemporary} {Use} and {Analysis}},
	volume = {124},
	copyright = {Copyright American Association of Intellectual \& Developmental Disabilities Jan 2019},
	issn = {19447515},
	shorttitle = {A {Primer} on {Single}-{Case} {Research} {Designs}},
	url = {https://www.proquest.com/docview/2165596002/abstract/421065290C53417EPQ/1},
	doi = {http://dx.doi.org/10.1352/1944-7558-124.1.35},
	abstract = {The overarching purpose of this article is to provide an introduction to the use of rigorous single-case research designs (SCRDs) in special education and related fields. Authors first discuss basic design types and research questions that can be answered with SCRDs, examine threats to internal validity and potential ways to control for and detect common threats, and provide guidelines for selection of specific designs. Following, contemporary standards regarding rigor, measurement, description, and outcomes are presented. Then, authors discuss data analytic techniques, differentiating rigor, positive outcomes, functional relations, and magnitude of effects.
Alternate abstract:
Le but principal de cet article est de fournir une introduction a l'utilisation de devis de recherche rigoureux a cas unique en education specialisee et dans des domaines connexes. Les auteures abordent d'abord les types de conception de base et les questions de recherche pouvant etre resolues avec des devis de recherche a cas unique, examinent les menaces a la validite interne et les moyens potentiels de controler et de détecter les menaces courantes, puis fournissent des directives pour la selection de conceptions specifiques. Les normes contemporaines concernant la rigueur, la mesure, la description et les resultats sont presentees. Finalement, les auteures discutent des techniques d'analyse des donnees, de la differenciation de la rigueur, des resultats positifs, des relations fonctionnelles et de l'ampleur des effets.
Alternate abstract:
El objetivo general de este artíículo es proporcionar una introducción al uso de diseños rigurosos de investigación de caso unico (DRICu) en educación especial y campos relacionados. Los autores primero discuten los tipos de diseño basico y las preguntas de investigacioí n que pueden responderse con DRICu, examinan las amenazas a la validez interna y las posibles formas de controlar y detectar amenazas comunes, y proporcionan pautas para la selección de diseños específicos. A continuación, se presentan los estaíndares contemporaíneos con respecto al rigor, la medición, la descripción y los resultados. Luego, los autores discuten tecnicas analíticas de datos, rigor de diferenciación, resultados positivos, relaciones funcionales y magnitud de los efectos.},
	language = {English},
	number = {1},
	urldate = {2021-08-24},
	journal = {American Journal on Intellectual and Developmental Disabilities},
	author = {Ledford, Jennifer R. and Barton, Erin E. and Severini, Katherine E. and Zimmerman, Kathleen N.},
	month = jan,
	year = {2019},
	note = {Num Pages: 35
Place: Washington, United States
Publisher: American Association of Intellectual \& Developmental Disabilities},
	keywords = {Behavior, Civil rights, Developmental disabilities, Intervention, Medical Sciences--Psychiatry And Neurology, Research methodology, Special education, Standards, Validity},
	pages = {35},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/NIMCUUII/Ledford et al. - 2019 - A Primer on Single-Case Research Designs Contempo.pdf:application/pdf},
}

@article{manolov2017a,
	title = {How {Can} {Single}-{Case} {Data} {Be} {Analyzed}? {Software} {Resources}, {Tutorial}, and {Reflections} on {Analysis}},
	volume = {41},
	issn = {0145-4455},
	shorttitle = {How {Can} {Single}-{Case} {Data} {Be} {Analyzed}?},
	url = {https://doi.org/10.1177/0145445516664307},
	doi = {10.1177/0145445516664307},
	abstract = {The present article aims to present a series of software developments in the quantitative analysis of data obtained via single-case experimental designs (SCEDs), as well as the tutorial describing these developments. The tutorial focuses on software implementations based on freely available platforms such as R and aims to bring statistical advances closer to applied researchers and help them become autonomous agents in the data analysis stage of a study. The range of analyses dealt with in the tutorial is illustrated on a typical single-case dataset, relying heavily on graphical data representations. We illustrate how visual and quantitative analyses can be used jointly, giving complementary information and helping the researcher decide whether there is an intervention effect, how large it is, and whether it is practically significant. To help applied researchers in the use of the analyses, we have organized the data in the different ways required by the different analytical procedures and made these data available online. We also provide Internet links to all free software available, as well as all the main references to the analytical techniques. Finally, we suggest that appropriate and informative data analysis is likely to be a step forward in documenting and communicating results and also for increasing the scientific credibility of SCEDs.},
	language = {en},
	number = {2},
	urldate = {2021-08-24},
	journal = {Behavior Modification},
	author = {Manolov, Rumen and Moeyaert, Mariola},
	month = mar,
	year = {2017},
	note = {Publisher: SAGE Publications Inc},
	keywords = {data analysis, effect size, single-case designs, software, tutorial},
	pages = {179--228},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/3D8CZFYG/Manolov and Moeyaert - 2017 - How Can Single-Case Data Be Analyzed Software Res.pdf:application/pdf},
}

@article{manolov2017b,
	title = {Recommendations for {Choosing} {Single}-{Case} {Data} {Analytical} {Techniques}},
	volume = {48},
	issn = {0005-7894},
	url = {https://www.sciencedirect.com/science/article/pii/S0005789416300284},
	doi = {10.1016/j.beth.2016.04.008},
	abstract = {The current paper responds to the need to provide guidance to applied single-case researchers regarding the possibilities of data analysis. The amount of available single-case data analytical techniques has been growing during recent years and a general overview, comparing the possibilities of these techniques, is missing. Such an overview is provided that refers to techniques that yield results in terms of a raw or standardized difference and procedures related to regression analysis, as well as nonoverlap and percentage change indices. The comparison is provided in terms of the type of quantification provided, data features taken into account, conditions in which the techniques are appropriate, possibilities for meta-analysis, and evidence available on their performance. Moreover, we provide a set of recommendations for choosing appropriate analysis techniques, pointing at specific situations (aims, types of data, researchers’ resources) and the data analytical techniques that are most appropriate in these situations. The recommendations are contextualized using a variety of published single-case data sets in order to illustrate a range of realistic situations that researchers have faced and may face in their investigations.},
	language = {en},
	number = {1},
	urldate = {2021-08-24},
	journal = {Behavior Therapy},
	author = {Manolov, Rumen and Moeyaert, Mariola},
	month = jan,
	year = {2017},
	keywords = {data analysis, recommendations, single-case designs},
	pages = {97--114},
	file = {ScienceDirect Full Text PDF:/Users/dorothybishop/Zotero/storage/ZHGIYUT6/Manolov and Moeyaert - 2017 - Recommendations for Choosing Single-Case Data Anal.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/CCLSMHEJ/S0005789416300284.html:text/html},
}

@article{chen2015,
	title = {Computing tools for implementing standards for single-case designs},
	volume = {39},
	issn = {1552-4167},
	doi = {10.1177/0145445515603706},
	abstract = {In the single-case design (SCD) literature, five sets of standards have been formulated and distinguished: design standards, assessment standards, analysis standards, reporting standards, and research synthesis standards. This article reviews computing tools that can assist researchers and practitioners in meeting the analysis standards recommended by the What Works Clearinghouse: Procedures and Standards Handbook-the WWC standards. These tools consist of specialized web-based calculators or downloadable software for SCD data, and algorithms or programs written in Excel, SAS procedures, SPSS commands/Macros, or the R programming language. We aligned these tools with the WWC standards and evaluated them for accuracy and treatment of missing data, using two published data sets. All tools were tested to be accurate. When missing data were present, most tools either gave an error message or conducted analysis based on the available data. Only one program used a single imputation method. This article concludes with suggestions for an inclusive computing tool or environment, additional research on the treatment of missing data, and reasonable and flexible interpretations of the WWC standards.},
	language = {eng},
	number = {6},
	journal = {Behavior Modification},
	author = {Chen, Li-Ting and Peng, Chao-Ying Joanne and Chen, Ming-E.},
	month = nov,
	year = {2015},
	pmid = {26358925},
	keywords = {computing, effect, Humans, intervention, Research Design, single-case design, software, Software, standards, Statistics as Topic, WWC},
	pages = {835--869},
}

@article{chen2015a,
	title = {Computing {Tools} for {Implementing} {Standards} for {Single}-{Case} {Designs}},
	volume = {39},
	issn = {0145-4455, 1552-4167},
	url = {http://journals.sagepub.com/doi/10.1177/0145445515603706},
	doi = {10.1177/0145445515603706},
	abstract = {In the single-case design (SCD) literature, five sets of standards have been formulated and distinguished: design standards, assessment standards, analysis standards, reporting standards, and research synthesis standards. This article reviews computing tools that can assist researchers and practitioners in meeting the analysis standards recommended by the What Works Clearinghouse: Procedures and Standards Handbook—the WWC standards. These tools consist of specialized web-based calculators or downloadable software for SCD data, and algorithms or programs written in Excel, SAS procedures, SPSS commands/Macros, or the R programming language. We aligned these tools with the WWC standards and evaluated them for accuracy and treatment of missing data, using two published data sets. All tools were tested to be accurate. When missing data were present, most tools either gave an error message or conducted analysis based on the available data. Only one program used a single imputation method. This article concludes with suggestions for an inclusive computing tool or environment, additional research on the treatment of missing data, and reasonable and flexible interpretations of the WWC standards.},
	language = {en},
	number = {6},
	urldate = {2021-08-24},
	journal = {Behavior Modification},
	author = {Chen, Li-Ting and Peng, Chao-Ying Joanne and Chen, Ming-E},
	month = nov,
	year = {2015},
	pages = {835--869},
	file = {Chen et al. - 2015 - Computing Tools for Implementing Standards for Sin.pdf:/Users/dorothybishop/Zotero/storage/QV52C5SH/Chen et al. - 2015 - Computing Tools for Implementing Standards for Sin.pdf:application/pdf},
}

@article{moeyaert2014,
	title = {The {Influence} of the {Design} {Matrix} on {Treatment} {Effect} {Estimates} in the {Quantitative} {Analyses} of {Single}-{Subject} {Experimental} {Design} {Research}},
	volume = {38},
	issn = {0145-4455},
	url = {https://doi.org/10.1177/0145445514535243},
	doi = {10.1177/0145445514535243},
	abstract = {The quantitative methods for analyzing single-subject experimental data have expanded during the last decade, including the use of regression models to statistically analyze the data, but still a lot of questions remain. One question is how to specify predictors in a regression model to account for the specifics of the design and estimate the effect size of interest. These quantitative effect sizes are used in retrospective analyses and allow synthesis of single-subject experimental study results which is informative for evidence-based decision making, research and theory building, and policy discussions. We discuss different design matrices that can be used for the most common single-subject experimental designs (SSEDs), namely, the multiple-baseline designs, reversal designs, and alternating treatment designs, and provide empirical illustrations. The purpose of this article is to guide single-subject experimental data analysts interested in analyzing and meta-analyzing SSED data.},
	language = {en},
	number = {5},
	urldate = {2021-08-24},
	journal = {Behavior Modification},
	author = {Moeyaert, Mariola and Ugille, Maaike and Ferron, John M. and Beretvas, S. Natasha and Van den Noortgate, Wim},
	month = sep,
	year = {2014},
	note = {Publisher: SAGE Publications Inc},
	keywords = {alternating treatment design, design matrix, multiple-baseline design, piecewise regression equation, reversal design, single-subject experimental design},
	pages = {665--704},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/KIH2XW3Y/Moeyaert et al. - 2014 - The Influence of the Design Matrix on Treatment Ef.pdf:application/pdf},
}

@article{manolov2018,
	title = {Analyzing data from single-case alternating treatments designs},
	volume = {23},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	doi = {10.1037/met0000133},
	abstract = {Alternating treatments designs (ATDs) have received comparatively less attention than other single-case experimental designs in terms of data analysis, as most analytical proposals and illustrations have been made in the context of designs including phases with several consecutive measurements in the same condition. One of the specific features of ATDs is the rapid (and usually randomly determined) alternation of conditions, which requires adapting the analytical techniques. First, we review the methodologically desirable features of ATDs, as well as the characteristics of the published single-case research using an ATD, which are relevant for data analysis. Second, we review several existing options for ATD data analysis. Third, we propose 2 new procedures, suggested as alternatives improving some of the limitations of extant analytical techniques. Fourth, we illustrate the application of existing techniques and the new proposals in order to discuss their differences and similarities. We advocate for the use of the new proposals in ATDs, because they entail meaningful comparisons between the conditions without assumptions about the design or the data pattern. We provide R code for all computations and for the graphical representation of the comparisons involved. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
	number = {3},
	journal = {Psychological Methods},
	author = {Manolov, Rumen and Onghena, Patrick},
	year = {2018},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Experimental Design, Graphical Displays, Statistical Analysis, Statistical Regression, Test Construction, Trends},
	pages = {480--504},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/7235E2VE/Manolov and Onghena - 2018 - Analyzing data from single-case alternating treatm.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/FYSC95P9/2017-12026-001.html:text/html},
}

@article{koutsoftas2009,
	title = {The effect of {Tier} 2 intervention for phonemic awareness in a response-to-intervention model in low-income preschool classrooms},
	volume = {40},
	issn = {0161-1461},
	doi = {10.1044/0161-1461(2008/07-0101)},
	abstract = {PURPOSE: This study assessed the effectiveness of a Tier 2 intervention that was designed to increase the phonemic awareness skills of low-income preschoolers who were enrolled in Early Reading First classrooms.
METHOD: Thirty-four preschoolers participated in a multiple baseline across participants treatment design. Tier 2 intervention for beginning sound awareness was provided twice weekly in small groups over 6 weeks by trained teachers and speech-language pathologists (SLPs).
RESULTS: The intervention was successful for 71\% of the children, as indicated by medium to large effect sizes. Comparisons between children who did and did not qualify for intervention suggest that Tier 2 intervention helped narrow the gap in beginning sound awareness that had begun to emerge before treatment. Although children receiving special education and those learning English as a second language were enrolled in the classrooms, they were not overrepresented in the group qualifying for Tier 2 intervention, and most who did qualify demonstrated a positive response to intervention.
CONCLUSION: In a relatively short period of time, preschoolers' phonemic awareness skills were increased through small-group Tier 2 intervention provided by teachers and SLPs. Findings indicate the potential of Tier 2 interventions to positively impact the future reading skills of children who are at risk for later reading difficulties.},
	language = {eng},
	number = {2},
	journal = {Language, Speech, and Hearing Services in Schools},
	author = {Koutsoftas, Anthony D. and Harmon, Mary Towle and Gray, Shelley},
	month = apr,
	year = {2009},
	pmid = {18952818},
	keywords = {Child, Preschool, Early Intervention, Educational, Education, Special, Female, Humans, Language Tests, Male, Phonetics, Poverty, Schools, Speech Therapy},
	pages = {116--130},
	file = {Koutsoftas et al. - 2009 - The Effect of Tier 2 Intervention for Phonemic Awa.pdf:/Users/dorothybishop/Zotero/storage/F4Q35TAQ/Koutsoftas et al. - 2009 - The Effect of Tier 2 Intervention for Phonemic Awa.pdf:application/pdf},
}

@article{swain2020,
	title = {Speech and language therapy for adolescents in youth justice: {A} series of empirical single-case studies},
	volume = {55},
	issn = {1460-6984},
	shorttitle = {Speech and language therapy for adolescents in youth justice},
	doi = {10.1111/1460-6984.12529},
	abstract = {BACKGROUND: Adolescents in contact with youth justice are a vulnerable and marginalized group at high risk of developmental language disorder (DLD) and other communication difficulties. Though preliminary studies have demonstrated the benefits of speech and language therapy (SLT) services in youth justice, limited research has empirically tested the efficacy of intervention in these settings.
AIMS: To evaluate the extent to which intensive, one-to-one language intervention improved the communication skills of incarcerated adolescents with below-average ({\textgreater} 1 SD below the mean) language and/or literacy skills.
METHODS \& PROCEDURES: A series of four empirical single case studies was conducted, using multiple baseline intervention design. Individualized intervention programmes were administered, and progress on outcome measures (probes) was evaluated throughout the baseline, intervention and maintenance phases using Tau-U, a non-parametric distribution-free statistic. Additional measures were used as secondary outcomes of the intervention, including standardized language subtests, subjective rating tools by participants and their teachers collected pre- and post-intervention, and a brief structured participant interview, independently administered by youth justice staff.
OUTCOMES \& RESULTS: Medium-to-large effect sizes, the majority of which were statistically significant, were detected on the primary outcome measure across the four cases, indicating improvements in the targeted communication skills. Positive results were also evident in comparisons of pre- and post-measures on standardized language subtests, subjective self- and teacher ratings of communication, and the participants' impressions of the interventions. For those participants who could be followed up, gains in language skills were generally maintained at 1 month post-intervention.
CONCLUSIONS \& IMPLICATIONS: This study provides further evidence of the efficacy of one-to-one SLT intervention for adolescents in youth justice in order to address language and literacy difficulties. These findings inform future SLT service provision for adolescents in these settings, with clear policy and practice implications. Future research should investigate the wider benefits to individuals' engagement in youth justice intervention and recidivism, as well as assessing maintenance of gains over a longer period. What this paper adds What is already known on this subject The high rates of DLD in youth justice is well known, with difficulties spanning multiple areas of language and literacy. SLTs are increasingly working in community and custodial youth justice settings, and a few preliminary studies have demonstrated the effectiveness of such work. What this paper adds to existing knowledge This study extends the evidence base of the efficacy of SLT for language and literacy difficulties in youth justice, using a series of four empirical single case studies. It is also argued that SLT should be more actively considered in planning multidisciplinary interventions for young people in custody. What are the potential or actual clinical implications of this work? The results of this research support current moves to include SLT services in youth justice systems, and illustrate for clinicians currently working in this sector a way of structuring and measuring the impact of intervention services.},
	language = {eng},
	number = {4},
	journal = {International Journal of Language \& Communication Disorders},
	author = {Swain, Nathaniel R. and Eadie, Patricia A. and Snow, Pamela C.},
	month = jul,
	year = {2020},
	pmid = {32196891},
	keywords = {adolescents, developmental language disorder, intervention, language, literacy, service delivery, speech and language therapy},
	pages = {458--479},
	file = {Swain et al. - 2020 - Speech and language therapy for adolescents in you.pdf:/Users/dorothybishop/Zotero/storage/HR5VHWEX/Swain et al. - 2020 - Speech and language therapy for adolescents in you.pdf:application/pdf},
}

@article{armson1998,
	title = {Effect of {Extended} {Exposure} to {Frequency}-{Altered} {Feedback} on {Stuttering} {During} {Reading} and {Monologue}},
	volume = {41},
	url = {https://pubs.asha.org/doi/10.1044/jslhr.4103.479},
	doi = {10.1044/jslhr.4103.479},
	abstract = {An ABA time series design was used to examine the effect of extended, continuous exposure to frequency-altered auditory feedback (FAF) during an oral reading and monologue task on stuttering frequency and speech rate. Twelve adults who stutter participated. A statistically significant decrease in number of stuttering events, an increase in number of syllables produced, and a decrease in percent stuttering was observed during the experimental segment relative to baseline segments for the oral reading task. In the monologue task, there were no statistically significant differences for the number of stuttering events, number of syllables produced, or percent stuttering between the experimental and baseline segments. Varying individual patterns of response to FAF were evident during the experimental segment of the reading task: a large consistent reduction in stuttering, an initial reduction followed by fluctuations in amount of stuttering, and essentially no change in stuttering frequency. Ten of 12 participants showed no reduction in stuttering frequency during the experimental segment of the monologue task. These findings have ramifications both for the clinical utilization of FAF and for theoretical explanations of fluency-enhancement.},
	number = {3},
	urldate = {2021-09-06},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Armson, Joy and Stuart, Andrew},
	month = jun,
	year = {1998},
	note = {Publisher: American Speech-Language-Hearing Association},
	keywords = {extended exposure to FAF, fluency-enhancement, frequency-altered feedback, stuttering},
	pages = {479--490},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/VP4GEQC3/Armson and Stuart - 1998 - Effect of Extended Exposure to Frequency-Altered F.pdf:application/pdf},
}

@article{best2013a,
	title = {Aphasia rehabilitation: {Does} generalisation from anomia therapy occur and is it predictable? {A} case series study},
	volume = {49},
	issn = {0010-9452},
	shorttitle = {Aphasia rehabilitation},
	url = {https://www.sciencedirect.com/science/article/pii/S0010945213000087},
	doi = {10.1016/j.cortex.2013.01.005},
	abstract = {Introduction
The majority of adults with acquired aphasia have anomia which can respond to rehabilitation with cues. However, the literature and clinical consensus suggest change is usually limited to treated items. We investigated the effect of an experimentally controlled intervention using progressive cues in the rehabilitation of noun retrieval/production in 16 participants with chronic aphasia.
Method
Participants were sub-divided relative to the group according to performance on semantic tasks (spoken/written word to picture matching) and phonological output processing (presence/absence of word length effect and proportion of phonological errors in picture naming) in order to investigate outcome in relation to language profile. Cueing therapy took place weekly for 8 weeks.
Results
Intervention resulted in significant improvement on naming treated items for 15/16 participants, with stable performance on control tasks. Change occurred at the point of intervention and not during pre-therapy assessments. We predicted particular patterns of generalisation which were upheld. Only participants classified as having relatively less of a semantic difficulty and more of a phonological output deficit demonstrated generalisation to untreated items. Outcome did not relate to traditional aphasia classification.
Conclusion
A cueing hierarchy can improve word retrieval/production for adults with aphasia. In some cases generalisation to untreated items also occurs. The study demonstrates that the results of behavioural testing can be used to guide predictions of recovery with intervention.},
	language = {en},
	number = {9},
	urldate = {2021-09-06},
	journal = {Cortex},
	author = {Best, Wendy and Greenwood, Alison and Grassly, Jennie and Herbert, Ruth and Hickin, Julie and Howard, David},
	month = oct,
	year = {2013},
	keywords = {Anomia, Aphasia, Generalisation, Rehabilitation, Therapy},
	pages = {2345--2357},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/W5KA79EE/Best et al. - 2013 - Aphasia rehabilitation Does generalisation from a.pdf:application/pdf;ScienceDirect Snapshot:/Users/dorothybishop/Zotero/storage/AL7BZJHV/S0010945213000087.html:text/html},
}

@book{senn2004a,
	address = {West Sussex},
	title = {Statistical {Issues} in {Drug} {Development}},
	publisher = {John Wiley and Sons},
	author = {Senn, S},
	year = {2004},
}

@misc{zotero-1598,
	title = {The {Single}-{Case} {Reporting} {Guideline} {In} {BEhavioural} {Interventions} ({SCRIBE}) 2016: {Explanation} and elaboration.},
	url = {https://psycnet.apa.org/fulltext/2016-17384-001.html},
	urldate = {2021-09-09},
	file = {The Single-Case Reporting Guideline In BEhavioural Interventions (SCRIBE) 2016\: Explanation and elaboration.:/Users/dorothybishop/Zotero/storage/8EF92LND/2016-17384-001.html:text/html},
}

@article{tate2016a,
	title = {The {Single}-{Case} {Reporting} {Guideline} {In} {BEhavioural} {Interventions} ({SCRIBE}) 2016 {Statement}},
	volume = {96},
	issn = {1538-6724},
	doi = {10.2522/ptj.2016.96.7.e1},
	abstract = {We developed a reporting guideline to provide authors with guidance about what should be reported when writing a paper for publication in a scientific journal using a particular type of research design: the single-case experimental design. This report describes the methods used to develop the Single-Case Reporting guideline In BEhavioural interventions (SCRIBE) 2016. As a result of 2 online surveys and a 2-day meeting of experts, the SCRIBE 2016 checklist was developed, which is a set of 26 items that authors need to address when writing about single-case research. This article complements the more detailed SCRIBE 2016 Explanation and Elaboration article (Tate et al., 2016) that provides a rationale for each of the items and examples of adequate reporting from the literature. Both these resources will assist authors to prepare reports of single-case research with clarity, completeness, accuracy, and transparency. They will also provide journal reviewers and editors with a practical checklist against which such reports may be critically evaluated. We recommend that the SCRIBE 2016 is used by authors preparing manuscripts describing single-case research for publication, as well as journal reviewers and editors who are evaluating such manuscripts.
SCIENTIFIC ABSTRACT: Reporting guidelines, such as the Consolidated Standards of Reporting Trials (CONSORT) Statement, improve the reporting of research in the medical literature (Turner et al., 2012). Many such guidelines exist and the CONSORT Extension to Nonpharmacological Trials (Boutron et al., 2008) provides suitable guidance for reporting between-groups intervention studies in the behavioral sciences. The CONSORT Extension for N-of-1 Trials (CENT 2015) was developed for multiple crossover trials with single individuals in the medical sciences (Shamseer et al., 2015; Vohra et al., 2015), but there is no reporting guideline in the CONSORT tradition for single-case research used in the behavioral sciences. We developed the Single-Case Reporting guideline In BEhavioural interventions (SCRIBE) 2016 to meet this need. This Statement article describes the methodology of the development of the SCRIBE 2016, along with the outcome of 2 Delphi surveys and a consensus meeting of experts. We present the resulting 26-item SCRIBE 2016 checklist. The article complements the more detailed SCRIBE 2016 Explanation and Elaboration article (Tate et al., 2016) that provides a rationale for each of the items and examples of adequate reporting from the literature. Both these resources will assist authors to prepare reports of single-case research with clarity, completeness, accuracy, and transparency. They will also provide journal reviewers and editors with a practical checklist against which such reports may be critically evaluated.},
	language = {eng},
	number = {7},
	journal = {Physical Therapy},
	author = {Tate, Robyn L. and Perdices, Michael and Rosenkoetter, Ulrike and Shadish, William and Vohra, Sunita and Barlow, David H. and Horner, Robert and Kazdin, Alan and Kratochwill, Thomas and McDonald, Skye and Sampson, Margaret and Shamseer, Larissa and Togher, Leanne and Albin, Richard and Backman, Catherine and Douglas, Jacinta and Evans, Jonathan J. and Gast, David and Manolov, Rumen and Mitchell, Geoffrey and Nickels, Lyndsey and Nikles, Jane and Ownsworth, Tamara and Rose, Miranda and Schmid, Christopher H. and Wilson, Barbara},
	month = jul,
	year = {2016},
	pmid = {27371692},
	keywords = {Behavior Therapy, Checklist, Delphi Technique, Guidelines as Topic, Humans, methodology, Peer Review, Research, publication standardsSupplemental materials: http://dx.doi.org/10.1037/arc0000026.supp., reporting guidelines, Research Design, Research Report, single-case design},
	pages = {e1--e10},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/LNIKGYTV/Tate et al. - 2016 - The Single-Case Reporting Guideline In BEhavioural.pdf:application/pdf},
}

@article{tate2016b,
	title = {The {Single}-{Case} {Reporting} {Guideline} {In} {BEhavioural} {Interventions} ({SCRIBE}) 2016: {Explanation} and elaboration.},
	volume = {4},
	issn = {2169-3269},
	shorttitle = {The {Single}-{Case} {Reporting} {Guideline} {In} {BEhavioural} {Interventions} ({SCRIBE}) 2016},
	url = {https://psycnet.apa.org/fulltext/2016-17384-001.pdf},
	doi = {10.1037/arc0000027},
	number = {1},
	urldate = {2021-09-09},
	journal = {Archives of Scientific Psychology},
	author = {Tate, Robyn L. and Perdices, Michael and Rosenkoetter, Ulrike and McDonald, Skye and Togher, Leanne and Shadish, William and Horner, Robert and Kratochwill, Thomas and Barlow, David H. and Kazdin, Alan and Sampson, Margaret and Shamseer, Larissa and Vohra, Sunita},
	year = {2016},
	note = {Publisher: US: American Psychological Association},
	pages = {10},
	file = {Submitted Version:/Users/dorothybishop/Zotero/storage/ZGK539TK/Tate et al. - The Single-Case Reporting Guideline In BEhavioural.pdf:application/pdf;Snapshot:/Users/dorothybishop/Zotero/storage/LNLWA6K9/2016-17384-001.html:text/html},
}

@article{calder2018,
	title = {Combining implicit and explicit intervention approaches to target grammar in young children with {Developmental} {Language} {Disorder}},
	volume = {34},
	issn = {0265-6590},
	url = {https://doi.org/10.1177/0265659017735392},
	doi = {10.1177/0265659017735392},
	abstract = {Children with Developmental Language Disorder are likely to experience difficulties with morphosyntax, especially regular past tense marking. Few studies have evaluated the effectiveness of intervention to improve morphosyntax in young school-aged children with DLD. This study investigated the efficacy of combined explicit and implicit intervention techniques delivered by a speech pathologist to improve receptive and expressive grammar, including the use of past tense morphosyntax, using a multiple baseline single case experimental design. Participants were aged six to seven years and received two 1:1 45 minute sessions per week for five weeks (total 7.5 hours) using Shape Coding intervention techniques combined with implicit approaches. Two of the three participants made statistically significant gains on standardized tests of general receptive and expressive grammar. Two of the three children made statistically significant improvement on measures of expressive morphosyntax, with one participant continuing to improve five weeks post treatment. Findings suggest that this approach was efficacious. These findings warrant further investigation using larger group comparison research studies.},
	language = {en},
	number = {2},
	urldate = {2021-09-10},
	journal = {Child Language Teaching and Therapy},
	author = {Calder, Samuel D and Claessen, Mary and Leitão, Suze},
	month = jun,
	year = {2018},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {developmental language disorder, grammar, intervention, morphosyntax, shape coding},
	pages = {171--189},
	file = {SAGE PDF Full Text:/Users/dorothybishop/Zotero/storage/2KTJ3383/Calder et al. - 2018 - Combining implicit and explicit intervention appro.pdf:application/pdf},
}

@article{calder2021,
	title = {The {Efficacy} of an {Explicit} {Intervention} {Approach} to {Improve} {Past} {Tense} {Marking} for {Early} {School}-{Age} {Children} {With} {Developmental} {Language} {Disorder}},
	volume = {64},
	url = {https://pubs.asha.org/doi/10.1044/2020_JSLHR-20-00132},
	doi = {10.1044/2020_JSLHR-20-00132},
	abstract = {Purpose

The aim of the study was to evaluate the efficacy of a theoretically motivated explicit intervention approach to improve regular past tense marking for early school-age children with developmental language disorder (DLD).

Method

Twenty-one children with DLD (ages 5;9–6;9 [years;months]) were included in a crossover randomized controlled trial (intervention, n = 10; waiting control, n = 11). Intervention included once-weekly sessions over 10 weeks using the SHAPE CODING system, in combination with a systematic cueing hierarchy to teach past tense marking. Once the first group completed intervention, the waiting control group crossed over to the intervention condition. The primary outcome was criterion-referenced measures of past tense marking with standardized measures of expressive and receptive grammar as the secondary outcome. Ancillary analyses on extension and behavioral control measures of morphosyntax were also conducted.

Results

There was a significant Time × Group interaction (p {\textless} .001) with a significant difference in pre–post intervention improvement in favor of the intervention group (p {\textless} .001, d = 3.03). Further analysis once both groups had received the intervention revealed no improvement for either group on past tense production during the 5-week pre-intervention period, significant improvement pre–post intervention (p {\textless} .001, d = 1.22), with gains maintained for 5 weeks postintervention. No significant differences were found on pre- to postintervention standardized measures of grammar, or on extension or control measures.

Conclusions

The efficacy of the theoretically motivated explicit grammar intervention was demonstrated. Results contribute to the evidence base supporting this intervention to improve past tense production in early school-age children with DLD, suggesting it is a viable option for clinicians to select when treating morphosyntactic difficulties for this population.

Supplemental Material

https://doi.org/10.23641/asha.13345202},
	number = {1},
	urldate = {2021-09-10},
	journal = {Journal of Speech, Language, and Hearing Research},
	author = {Calder, Samuel D. and Claessen, Mary and Ebbels, Susan and Leit, ão Suze},
	month = jan,
	year = {2021},
	note = {Publisher: American Speech-Language-Hearing Association},
	pages = {91--104},
	file = {Full Text PDF:/Users/dorothybishop/Zotero/storage/GVW434HD/Calder et al. - 2021 - The Efficacy of an Explicit Intervention Approach .pdf:application/pdf},
}
